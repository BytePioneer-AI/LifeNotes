[{"title":"Claude Code 实战指南","path":"/技术/AI/ai_claude_code/","content":"Claude Code 实战指南基础命令启动与配置 命令 作用 示例 claude 启动交互会话 claude claude -p &quot;提示词&quot; 非交互模式输出 claude -p &quot;分析这个文件&quot; claude --permission-mode plan 规划模式启动 claude --permission-mode plan claude --permission-mode acceptEdits 自动接受编辑模式 claude --permission-mode acceptEdits claude -c 继续最近对话 claude -c claude -r 恢复指定对话 claude -r claude --dangerously-skip-permissions 免授权模式 claude --dangerously-skip-permissions 配置管理 命令 作用 示例 —— —— —— claude config list 查看所有配置 claude config list claude config get &lt;key&gt; 获取配置值 claude config get theme claude config set &lt;key&gt; &lt;value&gt; 设置配置值 claude config set theme dark claude config remove &lt;key&gt; 删除配置项 claude config remove theme MCP 服务管理 命令 作用 示例 claude mcp list 列出 MCP 服务 claude mcp list claude mcp add &lt;name&gt; &lt;command&gt; 添加 MCP 服务 claude mcp add playwright npx -y @playwright/mcp@latest claude mcp remove &lt;name&gt; 删除 MCP 服务 claude mcp remove playwright 会话命令上下文管理 命令 作用 使用场景 /clear 清理当前会话上下文 完成功能模块后，开始新任务前 /compact 压缩会话内容 上下文过长时 /memory 设置全局提示词 需要AI具备特定思维模式时 @文件路径 引用特定文件 需要AI分析具体文件时 历史与撤销 命令 作用 使用场景 ESC x 2 调出历史指令 快速复用之前的复杂指令 回滚 &#x2F; 撤销 撤销AI在当前会话的修改 AI操作出错时 自定义命令 命令 作用 配置位置 /命令名 执行自定义 Slash 命令 .claude/commands/命令名.md 工作流技巧核心配置 技巧 配置位置 CLAUDE.md 项目根目录 全局提示词 /memory Git 版本控制 项目初始化 交互模式选择 模式 启动方式 适用场景 规划模式 --permission-mode plan 需求分析、架构设计 自动接受 --permission-mode acceptEdits 批量代码生成 默认模式 claude 调试、精细修改 强制思考模式 关键词 效果 使用场景 think 基础思考 简单任务规划 think hard 深度思考 复杂功能设计 ultrathink 超深度思考 系统级架构规划 模型与成本管理 命令 作用 说明 /model 切换AI模型 在Claude Opus与Sonnet 4之间切换 /cost 查看当前会话消耗 显示当前会话已花费金额 ccusage 详细使用统计 需要单独安装：npm install -g ccusage 记忆文件系统 类型 文件位置 用途 项目记忆（共享） ./CLAUDE.md 项目团队共享的指令、架构、规范 用户记忆（全局） ~/.claude/CLAUDE.md 所有项目的个人偏好设置 项目记忆（本地） ./CLAUDE.local.md 项目个人偏好设置（已废弃） Output Styles 功能详解核心概念：Output styles 允许您把Claude Code「变身」为不同类型的智能体（Agent），同时保留其核心能力（运行本地脚本、读写文件、跟踪TODO等）。它通过直接修改Claude Code的系统提示词（system prompt）来改变行为与交流方式。 内置Output Styles：官方提供3种内置风格： 风格名称 特点 使用场景 Default 面向高效软件工程协作的默认系统提示 日常开发、高效编码 Explanatory（讲解型） 在完成任务的同时插入教学式的「Insights」，解释实现选择与代码库模式 代码审查、知识分享、团队学习 Learning（学习&#x2F;带教型） 更像结对编程教练；边做边教，在代码中插入TODO(human)让用户亲自补全，随后给反馈 新人培训、技能传授、TDD开发 快速使用命令 1234567891011121314# 进入风格菜单/output-style# 直接切换到讲解型/output-style explanatory# 直接切换到学习型/output-style learning# 新建自定义风格（自然语言描述）/output-style:new 我想要一个安全审计风格：偏严格、先threat modeling、产出修复建议与自动化检测脚本# 查看或修改配置/config 配置管理 配置项 位置 说明 生效范围 项目本地级别（local project level） 设置保存到 .claude/settings.local.json 用户级自定义风格 ~/.claude/output-styles 个人专用风格定义 项目级自定义风格 .claude/output-styles 团队共享风格定义 实战应用场景 1. 遗留代码库分析（Explanatory风格） 选择风格：/output-style explanatory 典型指令：「请为 services/order/ 目录做系统性走查，按模块输出架构图要点与常见反模式，并给我 3 条重构路线图。」 产出预期：边输出改动建议，边穿插「Insights」解释为什么、涉及哪些设计权衡 加分技巧：在每个建议后链接到具体文件&#x2F;行号并生成小型PoC提交 2. 团队新人入职带教（Learning风格） 选择风格：/output-style learning 典型指令：「我们要给 UserService 增加批量导入，按 TDD 来：请先写失败用例，然后在实现里留下 TODO(human) 让我完成关键片段。」 产出预期：测试先行，Claude插入TODO(human)让新人补全，随后自动点评与改进建议 加分技巧：录成屏幕录像作为团队教材，形成标准化学习路径 3. 安全审计官（自定义风格） 创建风格：/output-style:new 我想要严格的安全审计风格：先威胁建模，再静态/依赖/配置审计，输出CWE映射、修复PR草案与本地脚本 典型指令：「审计 auth/ 和 infra/terraform/，列出高/中/低风险清单；为高风险生成修复PR diff和/scripts下的自动化检查脚本。」 产出预期：威胁清单（含CWE&#x2F;CVE引用）、修复策略、脚本原型 加分技巧：把风格文件放进项目级.claude/output-styles/security.md，全队共享同一”口味” 4. 产品经理评审（自定义风格） 创建风格：/output-style:new 我想要偏PM的风格：强调用户故事、影响评估、成功指标、边界用例与回滚预案，产出简洁评审结论 典型指令：「评审这个重构PR：补全用户故事、指标、风险与灰度策略；给出放行/阻塞结论。」 产出预期：结构化评审单，能直接贴到PR讨论 5. 数据科学记事本（自定义风格） 创建风格：/output-style:new 我想要数据科学记事本风格：偏探索、每步都写动机/假设/结果/后续问题，附可复现实验脚本 典型指令：「对 notebooks/churn.ipynb 做特征淘洗与对照实验，记录每一步实验日志与结论。」 产出预期：每步都带”为什么”的研究日志 + 可复现脚本 6. 测试驱动修复（自定义风格） 创建风格：/output-style:new 测试驱动修复：先复现bug的最小失败用例，再最小化修复，最后回归影响评估与监控告警建议 典型指令：「这个issue #342在Edge上报JS报错，按风格走：给出最小复现、修复diff、补充监控。」 产出预期：最小可验证的失败→修复闭环，附监控&#x2F;报警 7. 合规与许可证检查（自定义风格） 创建风格：/output-style:new 合规风格：扫描依赖许可证与第三方片段，输出风险矩阵、替代建议与自动标注脚本 典型指令：「审计 package.json、NOTICE、third_party/，生成合规矩阵与修复脚本。」 产出预期：可追踪、可执行的合规整改单与脚本 关键区别对比 特性 Output Styles CLAUDE.md &#x2F; -append-system-prompt Agents（子代理） 工作原理 替换&#x2F;关闭默认工程化system prompt 追加用户消息 &#x2F; 附加到默认system prompt 可指定模型、工具、触发场景 影响范围 主循环行为 仅追加指令 完整子代理 适用场景 角色扮演、风格转换 补充说明、追加约束 专业任务、自动化流程 自定义风格文件格式 12345678910111213141516171819---name: 自定义风格名称description: 详细描述这个风格的用途和特点---# 自定义风格指令你的具体行为规范和说明...## 关注领域- 专注点1- 专注点2## 方法- 工作方式1- 工作方式2## 输出内容- 产出格式1- 产出格式2 手动创建Output Style示例 12345# 进入风格目录cd ~/.claude/output-styles# 创建自定义风格文件nano security-auditor.md 团队协作建议 风格沉淀：将常用风格沉淀到.claude/output-styles/，形成”标准化智能体角色库” 经验固化：把团队经验固化为可执行的系统提示 版本控制：将自定义风格文件纳入Git版本控制 定期优化：根据实际使用效果持续优化风格定义 输出格式配合 12345# 仅导出纯文本claude -p &#x27;summarize this data&#x27; --output-format text &gt; summary.txt# 导出为JSONclaude -p &#x27;analyze this code for bugs&#x27; --output-format json &gt; analysis.json 最佳实践 风格选择：根据具体任务场景选择合适的内置或自定义风格 渐进使用：先从内置风格开始，逐步创建自定义风格 团队标准化：在团队内推广统一的风格定义，提高协作效率 持续优化：根据使用反馈不断调整和完善风格定义","tags":["AI","CC"],"categories":["技术"]},{"title":"一种通过结构化提问，与LLM共创高质量PRD核心的实用指南","path":"/技术/AI/ai-llm-canpin-prompt/","content":"一种通过结构化提问，与LLM共创高质量PRD核心的实用指南 你是否在用错误的方式使用LLM？ 对于产品经理来说，大语言模型（LLM）的出现仿佛是一个福音。我们尝试让它“写一份关于XX的PRD”，期待它能瞬间变出一个完美文档。但结果往往不尽人意——我们得到的，通常是一份充满通用模板、缺乏灵魂和深度思考的“需求复读机”式文档。它能描述“做什么”（What），却完全无法回答“为什么做”（Why）。 问题出在哪里？我们把LLM当成了一个执行者，一个快速但没有思想的实习生。 然而，LLM的真正潜力在于成为一名思考伙伴，一个能挑战我们、引导我们、与我们一同拨开迷雾的“产品教练”。本文将为你介绍一种全新的工作流，通过为LLM设定一个“善于质疑的资深产品经理”角色，引导它运用第一性原理和苏格拉底式提问法，与你共同打磨出产品的核心价值和PRD的坚实骨架。 核心理念：从“执行者”到“挑战者”的角色转变 成功的关键第一步，是改变你与LLM的互动模式。我们不能只给它模糊指令，而是要通过一个精心设计的Prompt，赋予它一个全新的角色——Pioneer，一位经验丰富、善于运用第一性原理的资深产品搭档。 这个角色的核心任务不是记录和执行，而是挑战、深挖和共创。 一个有效的“产品教练”LLM Prompt应包含以下要素： 清晰的角色定义：明确告知LLM，它是一位“善于运用第一性原理和苏格拉底式提问法的资深产品经理”，其职责是“挑战每一个假设”。 结构化的工作流程：定义一个清晰的、分阶段的提问框架，确保讨论的焦点和深度。 明确的互动规则：规定LLM的行为模式，如“一次只问一个关键问题”、“总结并确认”、“持续质疑而非直接给予答案”。 💡 关键提示： 这份初始Prompt是整个工作流的基石。它将LLM从一个被动的文本生成器，转变为一个主动的、有逻辑的对话伙伴。 三步结构化思辨法：与你的LLM教练一起“炼”出产品真金 在设定好角色后，你就可以引导LLM，按照以下三个阶段与你展开深度对话。这个过程，就是将一个初步想法，系统化地打磨成PRD核心要素的过程。 第一阶段：定义问题空间 (Problem Space) - 我们为什么要做？ 这是最重要也最容易被忽视的一步。一个强大的产品，始于对一个真实、有价值问题的深刻理解。在这个阶段，你的LLM教练会像一位刨根问底的侦探，不断挑战你，确保你们没有在“用一个解决方案去伪装问题”。 它会提出的核心问题包括： 根本问题是什么？ (并使用“5个为什么”连续追问，直至找到根源) 这是谁的问题？ (清晰地定义目标用户、场景和痛点) 这个痛点有多痛？ (是“维生素”还是“止痛药”？) 用户现在是怎么解决的？ (现有方案的缺陷，就是我们的机会) 产出成果： 在这个阶段结束时，你将对产品的存在价值有一个清晰、深刻的共识，例如：“我们要解决的核心问题是，因AI应用迭代速度慢，导致产品体验落后于竞品，最终引发用户流失的商业风险。” 第二阶段：构思解决方案 (Solution Space) - 我们做什么？ 当“为什么”足够清晰后，“做什么”自然会浮出水面。在这个阶段，LLM教练会帮助你抵制功能堆砌的诱惑，聚焦于为用户创造最核心的价值。 它会引导你思考： 核心价值主张是什么？ (用一句话向用户说明，我们提供的核心价值) MVP（最小可行产品）的范围是什么？ (通过用户故事格式，定义最核心的功能，并无情地砍掉非必要项) 我们的差异化和护城河是什么？ (我们与竞品有何本质不同？如何防止被轻易复制？) 产出成果： 这个阶段将产出清晰的产品定义和范围。例如，从一个宽泛的“AI中台”概念，聚焦到一个具体的MVP——“模型评测中心”，并明确了其核心价值主张：“帮助开发者告别繁琐的手动测试，一键对比方案在真实业务场景下的表现，快速找到最优解。” 第三阶段：衡量与迭代 (Measurement &amp; Iteration) - 我们如何知道是否成功？ 一个没有衡量标准的产品，就像一艘没有罗盘的船。在交付开发之前，定义成功至关重要。你的LLM教练会确保你的产品不仅“能用”，而且“有效”。 它会和你探讨： 北极星指标是什么？ (如果产品上线，看哪个唯一关键指标来判断它是否成功？) 最大的风险和假设是什么？ (如果我们的核心假设是错的，会发生什么？) 如何验证假设？ (我们需要追踪哪些过程数据来验证风险？) 产出成果： 你将获得清晰的成功衡量标准和风险应对策略。例如，确定北极星指标为“从发起评测到找到最优解的平均时长”，并识别出最大风险是“配置流程的复杂性可能导致用户放弃”，从而提前规划需要监控的过程数据。 从“战略共识”到“详细PRD”的无缝衔接 经过以上三个阶段的思辨，你和LLM共同产出的不是一份完整的PRD，而是比它更重要的东西——一份PRD的核心要素清单。 这份清单逻辑严密、共识清晰，包含了“The Why, The What, The How”的全部精髓。它确保了团队中的每一个人，都对产品的方向和价值有着高度一致的理解。 在此基础上，你可以再次转换LLM的角色，让它从一个“质疑者”变成一个严谨的PRD撰写专家，并指令它：“现在，请基于我们达成的核心要素，为我详细撰写‘功能详述’这一章节，从‘数据集管理’功能开始。” 这时，由于所有的核心战略问题都已解决，LLM撰写具体功能点的工作将变得无比高效和精准。 重新定义你与AI的协作关系停止将LLM视为一个简单的“写手”。通过为其精心设计一个“产品教练”的角色，并采用结构化的提问框架，你可以将它升级为你的“外置大脑”和“思考搭档”。 这种方法不仅能帮你产出逻辑更严密、价值更清晰的PRD，更重要的是，它能强迫你进行更深层次的产品思考，最终让你成为一名更优秀的产品经理。 下次启动新项目时，不妨试试这个方法。 DemoDemo 完整Prompt资深产品经理（质疑与引导型）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# 角色：资深产品经理（质疑与引导型）你现在是一位经验丰富、善于运用第一性原理和苏格拉底式提问法的资深产品经理。你的名字叫 Pioneer。你的核心价值不是记录和执行，而是**挑战、深挖和共创**。---## 核心任务我的核心任务不是直接为你撰写 PRD，而是通过结构化的提问框架，**挑战你的每一个假设**，引导你深度思考，与你一同打磨产品思路。最终，我们将协作产出一份逻辑严密、用户价值清晰、商业上可行的产品需求文档（PRD）的**核心要素**。---## 工作流程与提问框架我将引导你按照以下三个核心阶段进行思考。在每个阶段，我都会提出关键的、有时甚至是尖锐的质疑性问题。**第一阶段：定义问题空间 (Problem Space) - 我们为什么要做？**1. **核心问题 (The Core Problem):** * “你要解决的**根本问题**是什么？” * （在我回答后）“这真的是问题吗？还是只是一个解决方案的伪装？我们用‘5个为什么’再深挖一下。”2. **目标用户 (The User):** * “这个问题的**典型用户**是谁？你能用三句话描述一下他的特征、场景和痛点吗？” * “我们为什么选择服务**他们**，而不是其他人？” * “这个痛点对他们来说有多痛？是‘维生素’（有了更好）还是‘止痛药’（没有不行）？”3. **现状与机会 (The Status Quo):** * “用户现在是如何解决这个问题的？（即使是用很笨的办法）” * “现有解决方案（竞品）的**最大缺陷**是什么？我们的切入点在哪里？”**第二阶段：构思解决方案 (Solution Space) - 我们做什么？**1. **核心价值主张 (Core Value Proposition):** * “我们的产品/功能，用一句话向用户说明，提供的**核心价值**是什么？” * “凭什么让用户放弃现有的习惯或方案，来使用我们的？”2. **功能与范围 (Features &amp; Scope):** * “为了实现这个核心价值，最**核心的功能**（MVP）是什么？请用‘用户故事’（As a [用户角色], I want to [做某事], so that [实现价值]）的格式描述。” * （在我描述功能后）“这个功能真的**必要**吗？如果去掉它，核心价值是否还成立？” * “我们是否有更简单、成本更低的方式来验证这个价值？”3. **差异化与护城河 (Differentiation):** * “这个解决方案最大的**亮点**是什么？它与竞品相比，有何本质不同？” * “我们如何防止其他人快速复制我们的想法？”**第三阶段：衡量与迭代 (Measurement &amp; Iteration) - 我们如何知道是否成功？**1. **成功指标 (Success Metrics):** * “如果产品上线了，我们看哪个**唯一关键指标（北极星指标）**来判断它是否成功？” * “为了衡量这个指标，我们需要追踪哪些过程数据？”2. **风险与假设 (Risks &amp; Assumptions):** * “这个产品方案背后，最大的**假设**是什么？如果这个假设是错的，会发生什么？” * “我们面临的技术、市场或运营上的**最大风险**是什么？”---## 互动规则1. **一次只问一个关键问题**：我会聚焦于当前阶段的核心问题，避免信息过载。2. **总结并确认**：在你回答后，我会先用自己的话总结你的观点，并向你确认理解是否正确。3. **持续质疑**：即使你的想法听起来不错，我也会尝试从反面或不同角度提出挑战，这是我的核心职责。4. **引导而非给予**：我不会直接给出答案，而是通过提问引导你自己找到答案。5. **阶段性总结**：在每个阶段结束时，我会进行一次小结，并询问你是否可以进入下一个阶段的讨论。---## 开场白现在，我已经准备好了。你好！我是你的产品搭档 Pioneer。我不会轻易同意你的观点，但我会通过不断提问，帮助我们拨开迷雾，找到产品的真正价值。**准备好接受挑战了吗？请告诉我，你初步的产品思路或想要解决的问题是什么？** 资深产品文档（PRD）撰写专家12345678910111213141516171819202122232425262728293031Pioneer，非常感谢你！我们第一阶段的战略思辨工作已经出色地完成了。这份“核心要素”为我们指明了方向。现在，项目需要进入第二阶段：**详细的PRD撰写**。为此，我需要你进行一次角色转换。请忘记“Pioneer”这个质疑者的身份，你的新角色是一位严谨、细致的**“资深产品文档（PRD）撰写专家”**。以下是你的新角色设定和任务指令：---# 角色：资深产品文档（PRD）撰写专家你是一位经验丰富的产品经理，非常擅长撰写清晰、详尽、无歧义的产品需求文档（PRD）。## 核心任务你的任务是根据我们之前共同讨论并总结出的“产品需求核心要素”，将其扩展为一份完整的、可供开发和设计团队直接使用的PRD。## 输入信息（核心要素）（这部分内容LLM已经知道了，因为它就在我们的对话上下文中，无需重复粘贴）## 工作流程现在，请你基于我们已经确定的所有信息，帮我逐一完成PRD的详细章节。我们一次专注于一个部分。请先从 **“功能详述 (Functional Specifications)”** 开始。将MVP的第一个核心功能 **“支持用户上传自定义的业务数据集”**，拆解成具体的【用户故事 (User Stories)】和【功能需求点 (Requirements)】。准备好后，请开始你的新工作吧。","tags":["AI"],"categories":["技术","AI"]},{"title":"【训练】大模型微调技术基础(转发)","path":"/技术/AI/ai_train/","content":"原文：https://mp.weixin.qq.com/s/xJ29Uh3AHTQRA2n6IxeHYw 文章总结大模型微调技术综合概述本文全面介绍了大型语言模型（LLM）微调的基础知识、核心技术、应用场景、主流工具、评估方法、环境要求以及数据集准备的全过程。 第一部分：微调基础概念文章首先定义了大模型微调，即在预训练模型的基础上，使用特定领域的标注数据进行再训练，以优化模型在特定任务上的表现，从而实现能力的“永久”性提升。 微调主要分为两大类： 全量微调 (Full Fine-Tuning)：更新模型的所有参数，对模型的改造最彻底，但算力消耗巨大。 高效微调 (Parameter-Efficient Fine-Tuning, PEFT)：仅修改模型一小部分参数，以“四两拨千斤”的方式调整模型能力，显著降低了资源消耗。 微调的主要优势在于能永久性地改变模型能力，而劣势则在于可能引发“灾难性遗忘”，即模型在学习新知识时丢失了原有的通用能力，因此需要谨慎设计训练流程。 第二部分：高效微调核心技术：LoRA 与 QLoRA在众多高效微调方法中，LoRA (低秩适配) 是当前的主流技术。 LoRA 的核心原理是冻结预训练模型的绝大部分权重，仅在模型的特定层（如注意力层）中引入并训练两个小型的、低秩的矩阵（适配器）。这两个矩阵的乘积近似于全量微调时的权重更新，从而用极少的参数量（约为原始模型的0.01%-1%）实现高效训练 。其优势在于显著优化了显存占用和计算效率。 QLoRA (量化低秩适配) 是LoRA的进一步优化。它将未参与训练的基础模型权重量化为更低的数据类型（通常是4-bit），同时对插入的LoRA适配器进行训练。这种方法结合了量化和低秩适配的优点，极大地降低了显存需求，使得在消费级GPU上微调超大规模模型成为可能 。 总的来说，QLoRA在LoRA的基础上通过量化技术实现了更高的显存效率，适用于资源极度受限的场景，而LoRA则在设备性能较好的情况下表现出色 。 第三部分：高效微调的四大应用场景高效微调在实际应用中主要体现在以下四个方面： 对话风格微调：调整模型的语气、风格和应答方式，以适应客服、虚拟助手等特定场景的需求 。 知识灌注：将特定领域的专业知识（如医疗、法律）注入模型，提升其在专业问答场景下的准确性 。 推理能力提升：通过在包含逻辑步骤的数据集上进行微调，增强模型处理复杂问题（如数学计算、代码生成）时的逻辑推理能力。 Agent 能力提升：优化模型调用外部工具（API）、与其他系统交互的能力，使其在自动化任务中表现更智能、更高效。 第四部分：主流微调工具介绍文章推荐了四款封装程度较高、适合初学者的微调框架： unsloth：专注于提升微调速度和降低显存占用，通过手写GPU内核实现2倍以上的速度提升和70%-80%的显存节省，并与HuggingFace生态兼容。 LLaMA-Factory：一个统一高效的微调框架，支持超过100种LLM和VLM，集成了多种高效微调方法，并提供Web UI界面，无需编码即可完成定制。 ms-SWIFT：由ModelScope社区开发，提供一站式解决方案，支持超过550种LLM和150多种多模态模型，集成了丰富的训练技术和轻量级微调方法。 ColossalAI：一个旨在最大化训练效率、最小化成本的分布式AI训练系统，提供自动并行、大规模优化库等前沿技术。 第五部分：模型性能评估框架：EvalScopeEvalScope 是由ModelScope社区推出的开源模型评估框架，其核心功能包括： 丰富的评测基准：内置MMLU、GSM8K等权威数据集。 多样的评估模式：支持单模型评估、与基线模型对比等多种模式。 高度自动化：实现评测任务全自动执行和报告生成。 无缝集成：与ms-swift等训练框架紧密结合，提供端到端的开发支持。 第六部分：软硬件环境要求微调对硬件有一定要求，特别是显存（VRAM）。文章提供了详细的参考表格，列出了不同尺寸模型（从7B到110B）在不同微调方法（如FP16 LoRA、INT4 QLoRA）下所需的显存，并给出了推荐的GPU配置（如RTX 4090、A100等）。此外，还专门提供了Qwen3系列模型在不同量化微调下的显存占用情况。 第七部分：准备微调数据集数据集的质量直接决定了微调效果。核心要点包括： 理解底层原理：模型通过&lt;|im_start|&gt;等特殊标记来识别对话结构，因此数据集必须遵循目标模型的格式规范。 常见数据集格式： Alpaca风格：包含instruction、input、output字段，适用于基础问答任务 。 Function Calling格式：包含系统提示和&lt;tools&gt;标签，用于定义和调用外部函数 。 带思考过程的格式：包含&lt;think&gt;等标签，展示模型的中间推理步骤，以提升逻辑能力。 数据集构造与获取：可以通过混合不同类型的开源数据集（如对话和推理）、根据任务目标调整配比、并进行格式统一和清洗来构造高质量数据集。数据集可从Hugging Face、ModelScope等平台获取，也可针对特定领域手动创建。 一、微调基础概念1.1. 什么是大模型微调？大模型微调指在已有的大规模预训练模型基础上，通过对标注数据进行训练，进一步优化模型的表现，以适应特定任务或场景的需求。与 RAG 或者 Agent 技术通过搭建工作流来优化模型表现不同，微调是通过修改模型参数来优化模型能力，是一种能够让模型 “永久” 掌握某种能力的方法。 1.2 全量微调与高效微调的区别从方法大类划分，微调可分为全量微调与高效微调： 全量微调：带入全部数据进行微调，算力消耗更大，但对模型的能力改造更为彻底。 高效微调：只带入部分数据进行微调，更类似 “四两拨千斤” 的方法，通过修改模型部分参数，来调整模型整体能力。 1.3 模型微调的优劣势分析 优势：能够通过修改模型参数的方式，永久地修改模型的能力。 劣势：若处理不当，很可能造成模型原始能力的灾难性遗忘，即导致模型原始能力丢失，对于复杂模型尤其如此。因此需要小心谨慎地设计模型微调数据集和微调训练流程，并经过反复多次训练验证，得到最佳模型。 二、高效微调核心技术：LoRA 与 QLoRA 简介尽管全量微调可以深度改造模型能力，但需消耗大量算力且有一定技术门槛。在绝大多数场景中，若只想提升模型某个具体领域的能力，高效微调会更加合适，而目前适用于大模型的最主流高效微调方法是 LoRA。 2.1 LoRA：低秩适配的高效微调方法LoRA（Low-Rank Adaptation）微调是一种参数高效的微调方法，旨在通过引入低秩矩阵来减少微调时需要调整的参数数量，从而显著降低显存和计算资源的消耗。具体来说，LoRA 微调并不直接调整原始模型的所有参数，而是通过在某些层中插入低秩的适配器（Adapter）层来进行训练。 原理：在标准微调中，会修改模型的所有权重，而在 LoRA 中，只有某些低秩矩阵（适配器）被训练和调整。原始模型的参数保持不变，只是通过少量的新参数来调整模型的输出。低秩矩阵的引入能在显存和计算能力有限的情况下，有效对大型预训练模型进行微调，成为显存较小设备上的理想选择。 优势： 显存优化：只需要调整少量的参数（适配器），显著减少了显存需求，适合显存有限的 GPU。 计算效率：微调过程中的计算负担更轻，因为减少了需要调整的参数量。 灵活性：可以与现有的预训练模型轻松结合使用，适用于多种任务，如文本生成、分类、问答等。 2.2 QLoRA：量化与低秩结合的优化方案QLoRA（Quantized Low-Rank Adaptation）是 LoRA 的扩展版本，它结合了 LoRA 的低秩适配器和量化技术。QLoRA 进一步优化了计算效率和存储需求，特别是在极端显存受限的环境下。与 LoRA 不同的是，QLoRA 会将插入的低秩适配器层的部分权重进行量化（通常是量化为 INT4 或 INT8），在保持性能的同时显著降低模型的存储和计算需求。 核心思想：在 LoRA 的基础上加入量化技术，减少权重表示的位数，从而降低显存和计算需求。QLoRA 结合了低秩适配器和量化的优点，能够在显存有限的设备上进行更高效的微调。 量化作用：通过将模型权重量化为低精度（如 INT4），减少内存占用，并提高推理和训练速度。 优势：在显存非常有限的情况下仍能进行微调；可以处理更大规模的模型；适合用于边缘设备和需要低延迟推理的场景。 2.3 LoRA 与 QLoRA 对比 特性 LoRA QLoRA 核心技术 低秩适配器 (Low-Rank Adapters) 低秩适配器 + 量化技术 (Low-Rank Adapters + Quantization) 适用场景 显存受限，但设备性能较好 极限显存受限或需要快速推理的设备 计算效率 提高计算效率，减少调整的参数数量 进一步提升效率，减少内存使用并加快推理速度 量化技术 无量化 将权重量化为低精度 (如 INT4 或 INT8) 内存消耗 较低，但不如 QLoRA 低 显著降低内存消耗，适合更小的设备 训练复杂度 较简单，适用于大多数微调场景 需要更多的量化和适配工作，但适合超大模型和设备受限场景 注意：大模型微调的 LoRA 与 QLoRa，二者相差一个字母的大小写，是完全两种不同的技术；LoRA 除了可以用于微调大语言模型（LLM）外，目前在围绕 diffusion models（扩散模型）进行微调，及图片任务中也表现惊艳。 三、高效微调的四大应用场景在实际大模型应用场景中，高效微调主要用于以下四个方面： 3.1 对话风格微调高效微调可以用于根据特定需求调整模型的对话风格。例如，针对客服系统、虚拟助理等场景，模型可以通过微调来适应不同的语气、礼貌程度或回答方式，从而在与用户互动时提供更符合要求的对话体验。通过微调少量的参数（例如对话生成的策略、情感表达等），可以使模型表现出更具针对性和个性化的风格。 3.2 知识灌注知识灌注是指将外部知识或领域特定的信息快速集成到已有的预训练模型中。通过高效微调，模型可以更好地学习新领域的专有知识，而无需重新从头开始训练。例如，对于法律、医疗等专业领域，可以使用少量的标注数据对预训练模型进行微调，帮助模型理解特定行业的术语、规则和知识，进而提升专业领域的问答能力。 3.3 推理能力提升高效微调还可以用于提升大模型的推理能力，尤其是在处理更复杂推理任务时。通过微调，模型能够更加高效地理解长文本、推理隐含信息，或者从数据中提取逻辑关系，进而在多轮推理任务中提供更准确的答案。这种微调方式可以帮助模型在解答复杂问题时，提高推理准确性并减少错误。 3.4 Agent 能力提升在多任务协作或功能调用场景中，高效微调能够显著提升模型的 Agent 能力，使得模型能够有效地与其他系统进行交互、调用外部 API 或执行特定任务。通过针对性微调，模型可以学会更精准的功能调用策略、参数解析和操作指令，从而在自动化服务、智能助手或机器人控制等领域表现得更加高效和智能。 四、主流微调工具介绍在入手学习大模型微调时，首先推荐功能层次封装层次较高的微调四套工具：unsloth、LlamaFactory、ms-SWIFT 和 ColossalAI。除此之外，也可以借助更加底层的库，如 peft、LoRA、transformer 等实现高效微调。对于初学者来说，首先使用现成工具来进行微调更为合适。 4.1 unslothunsloth 是一个专为大型语言模型（LLM）设计的动态量化与微调框架，旨在提高微调效率并减少显存占用。它通过手动推导计算密集型数学步骤并手写 GPU 内核，实现了无需硬件更改即可显著加快训练速度。 GitHub 主页：https://github.com/unslothai/unsloth23。 性能表现：支持 Qwen3、Llama 4、Gemma 3 等多种模型，微调速度提升 2 倍，显存使用减少 70%-80% 等。 兼容性：与 HuggingFace 生态兼容，可以很容易地与 transformers、peft、trl 等库结合，以实现模型的监督微调（SFT）和直接偏好优化（DPO），仅需修改模型的加载方式，无需对现有训练代码进行修改。 核心优势：显著提升微调效率，采用独家 4bit 动态量化技术，节省时间成本；降低硬件要求，用户可在显存较小的 GPU 上进行大模型微调；开源免费，用户可在 Google Colab 或 Kaggle Notebooks 上免费试用。 4.2 LLama-FactoryLLaMA-Factory 是一个统一且高效的微调框架，旨在为超过 100 种大型语言模型（LLMs）和视觉语言模型（VLMs）提供便捷的微调支持。用户能够灵活地定制模型以适应各种下游任务。 GitHub 主页：https://github.com/hiyouga/LLaMA-Factory30。 主要功能和特点：支持对 100 多 LLMs 和 VLMs 进行微调，包括最新模型版本；集成多种高效微调方法，提高训练速度并减少显存占用；支持音频识别、音频理解等多模态任务；提供丰富的实验监控工具；框架提供类似 OpenAI 风格的 API、Gradio UI 和命令行界面，结合 vLLM worker 实现高效推理能力。 4.3 ms-SWIFTms-swift（Scalable lightWeight Infrastructure for Fine-Tuning）是由魔搭社区（ModelScope）开发的高效微调和部署框架，旨在为研究人员和开发者提供一站式的大模型与多模态大模型的训练、推理、评测、量化和部署解决方案。 GitHub 项目主页：https://github.com/modelscope/swift37。 模型支持：支持超过 450 种大型模型（LLMs）和 150 多种多模态大模型（MLLMs）的训练和部署，包括最新模型版本及多模态模型等。 技术特点：集成多种训练技术，满足不同微调需求；支持多种轻量级微调方法，降低显存和计算资源消耗；支持分布式训练技术，提升推理加速；提供多种量化方法，支持多种模态型训练；提供基于 Gradio 的 Web 界面，简化大模型全链路流程。 4.4 ColossalAIColossal-AI 是一个高效的分布式人工智能训练系统，旨在最大化提升人工智能训练效率，同时最小化训练成本。作为深度学习框架的内核，提供自动超高维并行、大规模优化库等前沿技术。 GitHub 项目主页：https://github.com/hpcaitech/ColossalAI42。 优势表现：与英伟达的 Megatron-LM 相比，仅需一半数量的 GPU 即可完成 GPT-3 训练，半小时内预训练 ViT-Base&#x2F;32，并在两天内训练完 15 亿参数的 GPT 模型。提供多种并行技术，如数据并行、流水线并行和张量并行，以加速模型训练。 特色：支持 DeepSeek R1 非量化模型高效微调，仅需 4 个节点、8 卡 A100 服务器即可完成 DeepSeek R1 高效微调44。 若是强化学习训练，则推荐veRL和OpenRLHF等框架。 4.5 其他微调框架 五、模型性能评估框架：EvalScope项目地址：https://github.com/modelscope/evalscope45 EvalScope 是由阿里巴巴魔搭社区（ModelScope）推出的一款开源模型评估框架，旨在为大语言模型（LLM）和多模态模型提供统一、系统化的性能评估方案。该框架具备高度的自动化和可扩展性，适用于研究机构、工业界以及模型开发者在模型验证与性能对比场景中的广泛需求。 核心功能和特点 丰富的评测基准覆盖：内置多种权威评测数据集，涵盖中英文通用知识问答、数学推理、常识判断、代码生成等多个方向，支持多维度评估47。 多样的评估模式支持：提供单模型评估模式（Single）、基于基线的两两对比模式（Pairwise-Baseline）、全模型两两对比模式（Pairwise-All），满足不同使用场景。 统一的模型接入接口：对不同类型的模型提供统一调用方式，兼容 HuggingFace、本地部署模型及 API 远程调用，降低模型集成复杂度。 评估流程高度自动化：实现评测任务全自动执行，包括客观题自动打分、复杂问题使用评审模型辅助判定结果等，支持批量评估与日志记录。 完善的可视化工具：支持生成详细评估报告和图表，展示模型在不同任务维度下的表现，便于横向对比和性能分析。 多后端与评测能力扩展：可集成多个评测后端，支持从单模态到多模态、从语言建模到 RAG 端到端评测的全链路能力。 支持部署性能测试：提供服务端推理性能测试工具，涵盖吞吐量、响应时延等关键指标，帮助评估模型部署实用性。 六、微调所需软硬件环境说明大模型微调属于大模型进阶类技术，不同于普通的模型对话或搭建基础应用，微调往往需要一定的软硬件条件支持。 6.1 硬件要求不同尺寸模型、不同精度微调时所需显存不同，以下是相关参考： 模型尺寸 Freeze (FP16) 显存需求 (GB) LoRA (FP16) 显存需求 (GB) QLORA (INT8) 显存需求 (GB) QLORA (INT4) 显存需求 (GB) 推荐硬件配置 7B 20 16 10 6 RTX4090、RTX4080、RTX3060 13B 40 32 20 12-13 RTX 4090&#x2F;A100 (40GB)、L40(48GB) 30B 80 64 40 24 A100 (80GB)、RTX4090 70B 200 160 80 48 H100 (80GB)、L40(48GB) 110B 360 240 140 72 H100(80GB)*5、H100(80GB)*2、A10 (24GB)*3 其中 RTX4090 可等价替换为 RTX3090；A100 可替换为 A800（国内特供）；L40 可替换为 L20（国内特供）56575859。 6.2 Qwen3 系列模型微调显存占用 模型名称 参数量 FP16 微调显存占用 4-bit 动态量化微调显存占用 备注 Qwen3-0.6B 0.6B ~1.2 GB ~0.5 GB 可在低端 GPU 或 CPU 上运行 Qwen3-1.7B 1.7B ~3.4 GB ~1.5 GB 适合入门级部署 Qwen3-4B 4B ~8.0 GB ~3.5 GB 适合中等规模任务 Qwen3-8B 8B ~16.0 GB ~7.0 GB 需要高端消费级 GPU Qwen3-14B 14B ~28.0 GB ~12.0 GB 可在单张 RTX 4090 上微调 Qwen3-30B- A3B (MoE) 激活参数约 3B ~85.0 GB 暂不支持 激活部分专家参数，资源需求较高 Qwen3-32B 32B ~65.0 GB ~32.0 GB 需要 A100&#x2F;H100 或多卡并行 Qwen3-235B- A22B (MoE) 激活参数约 22B ~600 GB 暂不支持 超大模型，适合企业级部署，需高端服务器支持 注 1：CPU 不能进行微调； 注 2：目前 MoE 模型只支持 4bit 普通量化微调，暂不支持动态量化微调。 七、准备微调数据集在大模型微调流程中，数据集的质量直接决定微调效果。尤其是当模型需要具备复杂功能（如 Function calling、混合推理）或特定领域知识时，手动创建或优化数据集至关重要。以下是基于 Qwen3 模型微调的数据集准备方法： 7.1 理解数据集构造的底层原理模型通过特殊字符标记识别输入类型、系统提示和输出边界，因此数据集需遵循模型的格式规范。以 Qwen3 为例，其核心特殊标记如下： &lt;|im_start|&gt;：标记文本开始，后跟角色（如user&#x2F;assistant&#x2F;system） &lt;|im_end|&gt;：标记文本结束 例如，简单对话的实际输入输出格式为： 1234&lt;|im_start|&gt;user 你好！&lt;|im_end|&gt; &lt;|im_start|&gt;assistant 你好呀，很高兴见到你！&lt;|im_end|&gt; 这些标记可在模型的tokenizer_config.json文件中查看完整定义。 7.2 常见微调数据集格式详解7.2.1 基础问答格式（Alpaca 风格）适用于简单指令微调，包含instruction（指令）、input（输入）和output（输出）三个核心字段。例如： 12345&#123; &quot;instruction&quot;: &quot;识别并解释给定的科学理论&quot;, &quot;input&quot;: &quot;细胞理论&quot;, &quot;output&quot;: &quot;细胞理论是生物科学的基础理论，认为所有生命体由细胞构成，细胞是生物的基本结构和功能单位。&quot;&#125; 微调时，脚本会自动将其转换为 Qwen3 兼容的标记格式： 1234&lt;|im_start|&gt;user 识别并解释给定的科学理论：细胞理论&lt;|im_end|&gt; &lt;|im_start|&gt;assistant 细胞理论是生物科学的基础理论...&lt;|im_end|&gt; 7.2.2 带系统提示和 Function calling 的格式若需提升模型的工具调用能力，数据集需包含系统提示、工具定义和调用示例。例如：系统提示：明确工具调用规则工具定义：通过&lt;tools&gt;标签描述函数参数对话示例： 12345678&lt;|im_start|&gt;system 你是天气助手，查询天气时需调用get_weather函数。 &lt;tools&gt;[&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;parameters&quot;:&#123;&quot;location&quot;:&quot;城市名称&quot;&#125;&#125;]&lt;/tools&gt; &lt;|im_end|&gt; &lt;|im_start|&gt;user 北京天气如何？&lt;|im_end|&gt; &lt;|im_start|&gt;assistant &lt;tool_call&gt;&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;arguments&quot;:&#123;&quot;location&quot;:&quot;北京&quot;&#125;&#125;&lt;/tool_call&gt;&lt;|im_end|&gt; 需注意：高效微调仅能优化现有 Function calling 能力，无法让模型从无到有学会该功能。 7.2.3 带思考过程的格式为提升模型推理能力（如数学解题、逻辑分析），数据集需包含中间思考步骤，用特殊标记（如&lt;|think|&gt;）分隔思考过程与最终输出。例如： 12345678&lt;|im_start|&gt;system 你是天气助手，查询天气时需调用get_weather函数。 &lt;tools&gt;[&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;parameters&quot;:&#123;&quot;location&quot;:&quot;城市名称&quot;&#125;&#125;]&lt;/tools&gt; &lt;|im_end|&gt; &lt;|im_start|&gt;user 北京天气如何？&lt;|im_end|&gt; &lt;|im_start|&gt;assistant &lt;tool_call&gt;&#123;&quot;name&quot;:&quot;get_weather&quot;,&quot;arguments&quot;:&#123;&quot;location&quot;:&quot;北京&quot;&#125;&#125;&lt;/tool_call&gt;&lt;|im_end|&gt; 模型会通过学习思考过程与最终答案的关联，提升推理逻辑性。 7.3 Qwen3 混合推理模型的数据集构造方法为确保 Qwen3 在微调后保留混合推理能力，需采用 “多数据集拼接” 策略，核心步骤如下： 7.3.1. 选择基础数据集 普通对话数据：如FineTome-100k（含 10 万条多轮对话，ShareGPT 风格），用于保留模型的自然交互能力。 推理类数据：如OpenMathReasoning（含 54 万道数学题及详细解题步骤），用于强化逻辑推理能力。 7.3.2 数据集配比调整需根据微调目标平衡不同类型数据的比例： 若侧重数学推理：可按 7:3 比例混合OpenMathReasoning与FineTome-100k 若需均衡能力：建议按 5:5 比例混合，避免模型过度偏向单一任务。 7.3.3 格式统一与清洗 确保所有数据转换为 Qwen3 兼容的标记格式（含&lt;|im_start|&gt;``&lt;|im_end|&gt;等）。 过滤重复样本、错误标注和低质量内容，避免模型学习噪声数据。 7.4 数据集获取与组装渠道开源数据集 直接从 Hugging Face、ModelScope 下载，如： mlabonne/FineTome-100k（通用对话） nvidia/OpenMathReasoning（数学推理） 手动创建 针对特定领域（如法律、医疗），可结合专业文档编写问答对，确保知识准确性。 格式转换 使用工具将原始数据转换为目标格式，例如用 Python 脚本批量添加 Qwen3 的特殊标记。 通过以上方法构建的数据集，能让 Qwen3 在微调后既保留原有能力，又针对性提升目标任务性能。","tags":["AI","训练"],"categories":["技术","AI"]},{"title":"交互式Agent系统的设计","path":"/技术/AI/ai-alibaba-agent/","content":"一篇阿里博文引发的思考和探索。 基于大语言模型的智能Agent系统1. 系统核心思想核心思想是构建一个以大语言模型（LLM）为“大脑”的智能代理（Agent），旨在解决将人类的自然语言指令高效、准确地转化为机器可执行的自动化任务。系统通过LLM + RAG (检索增强生成) + Tools的组合，让用户仅需通过一句话，即可驱动系统完成原本需要跨多个应用、执行多个步骤的复杂操作，实现“所想即所得”。更通顺的说，以对话的交互方式代替之前复杂ERP系统的流程交互。 ERP系统人力流程样例： 流程图 2. 核心组件定义系统主要由三大核心组件构成，分别扮演“大脑”、“记忆”和“双手”的角色。 2.1. 大语言模型 (LLM) - “大脑” 定义: 系统的中央处理器和决策核心。它负责理解用户的模糊意图、进行逻辑推理、制定行动计划、并以人性化的方式反馈结果。 2.2. 知识库 (Knowledge Base) - “记忆” 定义: LLM的外部知识源，通过RAG技术为LLM提供决策所需的、实时的、精确的上下文信息。它包含两个关键部分： 2.2.1. 原子能力工具库 (Atomic Tool Library) 定义: 一份关于“所有可用工具”的详细说明书。它精确定义了每一个独立的、最小颗粒度的功能（即“原子工具”），包括其功能描述、所需参数、使用范例等。它回答了“我有什么具体能力？”的问题。 2.2.2. 工具调用规则库 (Tool Call Rule Library) 定义: 一本关于“如何完成复杂任务”的流程蓝图（菜谱）。它定义了各种业务场景下，需要按什么顺序、组合调用哪些原子工具来完成任务。它回答了“要达成一个大目标，分几步走？”的问题。 2.3. 执行引擎 (Execution Engine) - “双手” 定义: 一个确定性的、非AI的程序。它负责接收并严格执行由LLM大脑规划好的行动计划，调用原子工具，并管理任务状态。 3. 核心流程实现系统的工作流程可以分解为以下五个关键步骤： 意图理解 (Intent Understanding) 用户通过自然语言界面输入指令。LLM接收到指令后，进行初步的语义分析，理解用户的核心意图和提取关键参数。 RAG检索 (RAG Retrieval) LLM带着用户的意图，并行地在原子能力工具库和工具调用规则库中进行向量相似度检索，找出与当前任务最相关的“工具说明”和“流程蓝图”。 动态规划 (Dynamic Planning) LLM综合“用户原始指令”和“RAG检索到的上下文”，生成一个结构化的、包含完整执行步骤和参数映射的行动计划（DAG）。此阶段能灵活应对三种情况： 单点任务: 若用户指令只对应单个原子工具，则直接生成调用该工具的计划。 复杂任务: 若用户指令匹配到工具调用规则库中的某个流程，则以此为模板生成计划。 动态任务: 若用户指令介于两者之间（如执行某个流程的一部分），LLM能基于对工具的理解，动态编排出一个新的、裁剪过的执行计划。 计划执行 (Plan Execution) 执行引擎接管LLM生成的计划，并严格按照计划中定义的顺序和依赖关系，依次调用原子工具层的API接口，完成与后端系统的实际交互。 结果反馈 (Result Feedback) 执行引擎将最终的执行结果返回。LLM可以（可选地）对技术性的结果进行总结，以通俗易懂的自然语言向用户汇报任务成果。 4. 数据结构样例以下是两大知识库的核心数据结构及其JSON样例。 4.1. 原子能力工具库 (Atomic Tool Library) 作用: 定义“零件”的规格。 样例: 定义“创建员工档案”工具。 1234567891011121314151617181920212223242526272829303132333435363738394041&#123; &quot;tool_name&quot;: &quot;create_employee_record&quot;, &quot;description&quot;: &quot;用于在人力资源系统中为一名新员工创建基础的个人档案。成功执行后会返回新创建员工的唯一ID（employee_id）。&quot;, &quot;parameters&quot;: [ &#123; &quot;name&quot;: &quot;full_name&quot;, &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;员工的法定全名&quot;, &quot;required&quot;: true &#125;, &#123; &quot;name&quot;: &quot;national_id&quot;, &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;员工的身份证号码&quot;, &quot;required&quot;: true &#125; ]&#125;# 数据结构 (Data Structure)&#123; &quot;tool_name&quot;: &quot;string&quot;, // 工具的唯一标识符，像函数名一样 &quot;description&quot;: &quot;string&quot;, // 详细描述工具的功能、用途和适用场景，写给LLM看 &quot;parameters&quot;: [ // 工具所需的参数列表 &#123; &quot;name&quot;: &quot;string&quot;, // 参数名 &quot;type&quot;: &quot;string&quot;, // 参数类型 (e.g., &#x27;string&#x27;, &#x27;integer&#x27;, &#x27;boolean&#x27;) &quot;description&quot;: &quot;string&quot;, // 参数的详细描述 &quot;required&quot;: &quot;boolean&quot; // 该参数是否为必填项 &#125; ], &quot;examples&quot;: [ // (可选但推荐) 调用该工具的用户提问示例 &#123; &quot;user_query&quot;: &quot;string&quot;, &quot;extracted_params&quot;: &#123; &quot;param_name&quot;: &quot;value&quot; &#125; &#125; ]&#125; 4.2. 工具调用规则库 (Tool Call Rule Library) 作用: 提供“组装图纸”。 样例: 定义“新员工入职流程”。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#123; &quot;rule_name&quot;: &quot;new_hire_onboarding_process&quot;, &quot;description&quot;: &quot;一个完整的新员工入职流程，涵盖了从创建档案到分配部门的全过程。&quot;, &quot;dag_definition&quot;: [ &#123; &quot;step_id&quot;: 1, &quot;tool_name&quot;: &quot;create_employee_record&quot;, &quot;description&quot;: &quot;第一步：为新员工创建个人档案。&quot;, &quot;dependencies&quot;: [], &quot;parameter_mapping&quot;: &#123; &quot;full_name&quot;: &#123; &quot;source&quot;: &quot;initial_query&quot;, &quot;value&quot;: &quot;full_name&quot; &#125;, &quot;national_id&quot;: &#123; &quot;source&quot;: &quot;initial_query&quot;, &quot;value&quot;: &quot;national_id&quot; &#125; &#125; &#125;, &#123; &quot;step_id&quot;: 2, &quot;tool_name&quot;: &quot;assign_department&quot;, &quot;description&quot;: &quot;第二步：为新员工分配部门和职位。&quot;, &quot;dependencies&quot;: [1], &quot;parameter_mapping&quot;: &#123; &quot;employee_id&quot;: &#123; &quot;source&quot;: &quot;step_output&quot;, &quot;step_id&quot;: 1, &quot;value&quot;: &quot;employee_id&quot; &#125;, &quot;department&quot;: &#123; &quot;source&quot;: &quot;initial_query&quot;, &quot;value&quot;: &quot;department&quot; &#125; &#125; &#125; ]&#125;# 数据结构 (Data Structure)&#123; &quot;rule_name&quot;: &quot;string&quot;, // 规则的唯一标识符，代表一个完整的业务流程 &quot;description&quot;: &quot;string&quot;, // 对整个业务流程的宏观描述 &quot;trigger_phrases&quot;: [ // (可选但推荐) 可能会触发此规则的用户常用短语 &quot;string&quot; ], &quot;dag_definition&quot;: [ // 定义工作流的有向无环图 (DAG) &#123; &quot;step_id&quot;: &quot;integer&quot;, // 步骤的唯一ID &quot;tool_name&quot;: &quot;string&quot;, // 此步骤需要调用的原子工具名称 (必须与工具库中的tool_name对应) &quot;description&quot;: &quot;string&quot;, // 对这一步骤的人性化描述 &quot;dependencies&quot;: [ // 此步骤依赖的前置步骤的step_id列表，为空则代表是起始步骤 &quot;integer&quot; ], &quot;parameter_mapping&quot;: &#123; // 定义此步骤工具的参数来源 &quot;param_name&quot;: &#123; &quot;source&quot;: &quot;string&quot;, // 来源类型: &#x27;initial_query&#x27; (来自用户原始提问), &#x27;step_output&#x27; (来自前置步骤的输出) &quot;value&quot;: &quot;string&quot; // 如果来源是&#x27;initial_query&#x27;，这里是参数名；如果是&#x27;step_output&#x27;，这里是来源步骤的输出键名 (e.g., &#x27;employee_id&#x27;) &#125; &#125; &#125; ]&#125; 【转发】别再手搓测试数据了！AE测试数据智造系统揭秘本文介绍如何通过构建基于大语言模型的测试数据智造Agent，解决AliExpress跨境电商测试中数据构造复杂、低效的问题，推动测试效率提升与智能化转型。 引言 在AliExpress跨境电商的复杂业务场景下，复杂业务模式（例如跨境、本地）、多类型物流方式、分国家运营策略、多币种、多语言等各因子叠加，测试经常面临测试数据构造复杂且困难、学习成本高、耗时长等问题。测试用例的初衷是验证业务逻辑，却被数据构造的“脏活累活”绑架了。 如今，大语言模型与原子工具库的结合，可以重新定义测试数据构造的工作模式。我们构建的测试数据智造助手，让”生成一个命中单品补贴的pop待评价订单”这样的复杂需求，只需一句自然语言描述即可自动完成全链路数据构造。 一、核心痛点以构造一个包含业务类型、组合营销优惠、物流线路等多种条件的测试数据为例：测试往往需要辗转于测试商家后台、营销运营工作台、各业务域的测试工具平台等多个系统，记忆各种参数规则，耗时费力地拼接出一个完整的测试场景。 随着业务的快速扩张，测试数据的复杂性和多样性持续增长，更加暴露出了传统的数据构造模式存在以下痛点： 多域依赖：测试数据构造依赖交易、支付、营销等多个业务域，工具分散于不同平台，操作链路冗长； 协作成本高：跨域工具使用需多团队协调，理解成本和重复工作量巨大； 效率瓶颈：人工构造复杂场景（如各状态订单、组合优惠等）耗时高达小时级，增加了测试执行的时间。 二、破局思路通过引入AI智能聚合编排测试数据构造能力，构建统一调度中台，可以有效解决这些问题，提高测试数据构造的效率和质量。 核心思想：通过LLM大模型+RAG技术实现自然语言驱动，结合多业务域原子工具单点调用和链式调用，实现全链路测试数据”所想即所得”。 三、目标从0-1建设AE测试数据智造Agent，统一测试工具AI接入方式，聚合多业务域测试原子能力，解决测试数据构成本高、造耗时长等问题，实现“提效”、“降本”、“提升覆盖率”，在自动化场景中实际运用。 提效：将复杂场景（如跨境订单、组合优惠）的测试数据构造耗时从小时级缩短至分钟级。 降本：减少开发&amp;测试时在数据构造的理解成本和重复工作量。 覆盖率：覆盖订单生命周期，支持多个核心业务域的复杂场景。 四、智造Agent实现方案4.1设计思路 用户以自然语言提出询问时，Agent 会依据用户输入的内容，在 RAG 测试工具知识库中进行信息检索。RAG技术能帮助 Agent 精准匹配到与用户问题相关的信息。 Agent 将用户提出的问题以及从知识库中检索到的信息，一同输入到 LLM 大语言模型中。大语言模型凭借其强大的语言理解能力，对用户的意图进行识别和分析，并将用户意图分为测试信息查询、原子数据构造和链路数据构造这几类。 基于识别出的用户意图，Agent 会匹配相应的一个或多个原子工具，以及链路调用工具的规则。这些原子工具是实现数据构造的基础组件，各自具备特定的数据处理功能。同时，Agent 会从用户问题里提取出原子工具必要的关键参数。 依据知识库中的业务规则、数据模板和相关知识，使用提取出来的参数调用工具库中的原子能力生成符合用户需求的测试数据。最后，Agent 将生成的测试数据进行合理组装，以清晰、易懂的格式回复给用户，完成整个测试数据生成与反馈的流程。 举个🌰 用户指令：给商品id为123456（示例ID，非真实数据）的商品生成一笔退货退款的订单。 Agent处理流程： 1.使用用户的问题去匹配知识库中的场景，与“退货退款”链路的背景内容关联度最高。 2.将用户问题和知识库匹配结果共同传入大模型，识别用户意图为通过退货退款链路构造测试数据，该链路涉及的原子工具及调用顺序规则为：下单—&gt;支付—&gt;发货—&gt;确认收货—&gt;申请退货退款—&gt;同意退货—&gt;退货—&gt;同意退款。 3.提取必要参数商品id：123456（示例ID，非真实数据），将其作为入参传给下单原子工具。然后将下单工具生成的订单id传给支付工具，之后按照按照顺序调用原子工具。 4.将状态推进成功的订单回复给用户。 4.2Agent架构设计 前端交互：提供自然语言输入界面，用户通过描述需求（如“构造一个使用平台券的pop商品订单”）触发流程。 **语**义解析：**结合RAG从知识库中匹配工具链规则信息和原子工具信息，再通过LLM大模型解析用户意图。 原子工具调度：根据工具链规则信息和原子工具信息调用原子工具服务（HSF&#x2F;HTTP请求），实现原子工具间的依赖关系与参数传递，生成用户想要的测试数据。 因此可以抽象为三层系统架构，具体如下： 4.2.1规则抽象层通过构建《原子能力工具库》、《工具调用规则库》的知识库实现。 原子能力工具库：每个原子工具定义工具描述、提问示例、参数说明以及原子工具维度的参数映射规则。 工具调用规则库：将业务场景抽象成原子工具调用规则，再通过DAG有向无环图的方式进行规则的定义。 4.2.2执行调度层工具链调用：编写数据智造prompt提示词使大模型能够根据规则生成对应的执行计划。 参数透传：在工具链上的规则输出的结果会根据参数语义透传给后续工具，不需要人工进行干预。 失败重试策略：工具调用失败自动触发重试，重试超过5次触发断点，需要人工确认。 4.2.3原子工具层通过AI应用开发平台的工具箱能力执行原子工具的真实调用，从而实现测试数据的自动构造。 4.3关键实现模块解析4.3.1AI应用开发平台基于AI应用开发平台进行对话型AI智能体设计，在Agent中调用RAG知识库、LLM大语言模型、自定义工具等能力实现AE测试工具构造功能。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Role: AE测试数据构造助手——全链路测试数据生成专家## Profile- **Author**: AE测试团队- **Version**: V0.1.1- **Language**: 中文 - **Description**: 专注通过自然语言交互，自动化生成覆盖交易、支付、营销等全业务域的复杂测试数据，实现&quot;所想即所得&quot;。## 核心原则1. **三源数据优先级** `用户输入参数 &gt; 常用测试数据 &gt; 原子工具默认值2. **文档引用规范** - 链路流程 → 《工具调用规则库》 - 工具定义 → 《原子能力工具库》 - 默认数据 → 《常用测试数据》## Core Capabilities1. **意图精准识别** - 支持识别7大场景类型： `基础订单生成 | 营销活动构造 | 逆向流程推进 | 跨境场景模拟 | 用户资产管理 | 数据状态查询 | 异常场景构造` 2. **参数深度提取** - **常规参数**：商品ID、用户ID、订单ID - **场景扩展参数**： &#123; &quot;营销活动&quot;: [&quot;活动类型&quot;, &quot;优惠门槛&quot;, &quot;叠加规则&quot;], &quot;逆向流程&quot;: [&quot;纠纷类型&quot;, &quot;退款原因&quot;, &quot;风控等级&quot;], &quot;跨境场景&quot;: [&quot;关税模式&quot;, &quot;物流渠道&quot;, &quot;货币类型&quot;] &#125;3. **动态链路生成** 基于目标状态自动裁剪工具链（如&quot;已支付&quot;状态仅调用创建+支付工具）A[输入解析] --&gt; B&#123;是否跨域?&#125; B --&gt;|是| C[组合规则引擎] B --&gt;|否| D[单域规则匹配] C &amp; D --&gt; E[工具链执行] E --&gt; F[结果聚合]## Workflow (严格遵循)1.**提取请求参数**...2. **工具调度阶段** 环境适配 → 根据用户输入的环境特征选择对应工具版本链式执行 → 按《工具调用规则库》定义的工具顺序执行参数桥接 → 自动将上游工具出参映射为下游工具入参状态演进 → 每个工具执行后必须推进业务状态到目标阶段3. **异常处理机制** ...## Output Format(强制规范)... 4.3.2原子能力工具库构建梳理研发测试过程中测试数据构造&amp;测试数据查询的原子操作进行封装和抽象，并在AI应用开发平台的工具空间对工具封装成API。 4.3.3测试工具知识库建设为了让 AI 智能体能够精准识别用户意图，并使用正确参数调用工具组件，因此通过结构化工具描述文档搭建 RAG 测试工具知识库。该知识库是 AI 智能体理解用户需求和执行任务的关键基础。 需要维护的测试工具知识库涵盖两大部分： 原子测试工具描述文档：将原子测试工具的使用背景、使用说明以及使用范例整理后录入知识库。AI 智能体在识别到具体业务场景时，就能快速匹配到对应的原子工具，进而实现数据构造和数据查询。 1234工具名称：请填写工具名称。工具描述：请填写工具描述、使用场景，方便大模型理解工具。提问示例：请填写提问相关的示例，支持多条。参数说明：参数名称-参数描述（是否必填）以及参数枚举 数据构造链路描述文档：把数据构造链路的背景信息、原子工具的调度链路以及具体原子工具名称都输出到知识库中。如此，AI 智能体在面对特定业务场景时，便能准确对应到具体的数据构造链路，然后依照链路顺序调用原子工具，完成数据构造任务。 123链路名称：退货退款链路链路背景：售后退货退款是指买家在下单支付完成，货物确认收货后买家申请退货退款，卖家同意退款的链路。用户用淘宝账号购买指定itemId的商品并且支付生成淘宝订单号orderId。在买家确认收货后的时候买家提交退货退款申请，生成退款单，退款单号disputeid,然后卖家同意退货，买家退货，最后卖家同意退款申请。链路信息：下单—&gt;支付—&gt;发货—&gt;确认收货—&gt;申请退货退款—&gt;同意退货—&gt;退货—&gt;同意退款 五、Agent应用实践AE测试数据智造Agent应用场景是多方面的。目前已接入钉钉答疑群和个人助手，以问答的方式作为业务日常测试的测试助手；也可以作为自动化测试（如接口自动化、用例自动化、压测等）的测试数据提供方，以HSF的接入方式对外提供数据构造基础能力。 针对对外提供的数据构造基础能力，我们做了以下的系统架构设计来保障数据构造的准确性和稳定性。 5.1外部接入架构设计 5.1.1漏桶算法限流由于LLM大模型存在token、QPM限制，而上游平台会批量调用触发限流，所以需要做限流方案。 为了解决这一问题，需要对流量整形，限制对AE测试数据智造Agent的请求频率，避免触发LLM服务端限流，保障系统的稳定性。 限流算法选型：漏桶算法 实现思路：将请求视为水流，将其放入一个“漏桶”中，桶的出口以固定速率流出请求，从而实现对流量的平滑控制，从而以恒定的速率请求AE测试数据智造Agent。 漏桶容量 &#x3D; 预估峰值流量 * 1.2) 漏水速率 &#x3D; LLM每分钟限制 &#x2F; 60 * 安全系数（如0.8） 5.1.2标准化输出（1）业务错误场景处理 测试数据无法构造的场景对于AE测试数据智造Agent来说并不是系统错误，是属于业务层面的错误，直接请求不会返回错误码和错误信息。 因此在接口适配层识别这些业务错误的场景，返回对应的业务错误码和错误信息。 （2）标准化错误码 AI应用开发平台构建的Agent在系统错误时返回的错误码不符合AE的规范，因此在接口适配层按照AE的标准规范进行错误码的转换。 （3）输出结果标准化处理 由于上游对数据输出的格式要求严格，如果输出格式只写在AI规则里的话容易因为AI的幻觉导致输出的格式不符合规范。 JSON Schema校验：定义严格的响应结构模板，自动修复或拒绝非法格式（如字段类型错误、多余字段）。 5.1.3日志+监控通过日志的方式，记录执行链路中的关键数据，并进行监控，分析大模型的执行结果，提供可监控、可分析的稳定性保障能力。 日志：场景+问题入参+Agent响应+标准化后输出结果+traceId，通过traceId串联从外部请求到Agent调用的全链路日志。 基础监控：Agent的RT和接口成功率。 业务监控：监控无法构造出测试数据的场景等。 执行分析：对无法构造出测试数据场景进行记录和分析，进行后续测试数据构造功能的迭代。 5.1.4缓存目的：减少重复调用Agent的token开销，提升批量用例执行效率，减少耗时。 缓存键设计：对用户输入参数（如场景描述、业务参数）计算唯一哈希值，作为缓存主键。 缓存策略：成功结果缓存30分钟，失败结果缓存2分钟（防穿透）。 六、结果 当前Agent已完成8500+次问答（含调试）。简单测试数据构造场景，人工构造预估需要5分钟，AI可降至1-3分钟，提效约50%；复杂场景（如涉及长链路工具），人工构造预估1小时，AI可降至10-15分钟，提效约70%。 当前已完成的核心能力如下： 原子工具调用：共接入85+原子工具，覆盖交易下单、购物车、订单、营销、支付、逆向、商家、商品、招商等核心场景诉求。 链式数据构造：打通交易、营销、逆向跨域链式规则执行，实现各类订单状态数据、营销订单数据等的一键全流程构造。 业务域接入友好：各业务域原子工具和数据链路构造规则可以按照规范直接完成接入，无需感知Agent内部逻辑。 多环境支持能力：实现环境感知路由机制，支持根据用户需求动态切换线上&#x2F;预发&#x2F;项目隔离环境。 七、未来展望 测试数据构造正在经历从”手工操作”到”智能服务”的转型。当各业务域的测试工具完成原子化改造，当大语言模型真正理解业务语义，我们距离”所想即所得”的终极目标将越来越近。未来的测试工程师可以更专注于场景设计而非数据准备，用创造力推动质量保障体系的持续进化。 这种智能化改造的价值不仅限于测试领域，其背后构建的业务语义理解能力和跨域协作机制，为整个研发体系的效能提升提供了新的可能性。或许在不远的将来，我们今天构建的智能助手，将成为新一代研发基础设施的重要组成部分。 流程图原始代码 %%{ init: { \"theme\": \"base\", \"themeVariables\": { \"primaryColor\": \"#F8F9FA\", \"primaryTextColor\": \"#333\", \"primaryBorderColor\": \"#A9A9A9\", \"lineColor\": \"#666\", \"secondaryColor\": \"#E9ECEF\", \"tertiaryColor\": \"#fff\" }, \"fontFamily\": \"sans-serif\" } }%% graph TD %% 定义不同角色的样式 classDef userStyle fill:#E6F4EA,stroke:#1D6F42,stroke-width:2px,color:#1D6F42 classDef llmStyle fill:#E3F2FD,stroke:#0B5B8D,stroke-width:2px,color:#0B5B8D classDef execStyle fill:#FEF4E3,stroke:#8A5300,stroke-width:2px,color:#8A5300 classDef systemStyle fill:#F8F9FA,stroke:#343A40,stroke-width:2px,color:#343A40 classDef artifactStyle fill:#FBEAEB,stroke:#721c24,stroke-width:1px,stroke-dasharray: 4 4,color:#721c24 %% 流程图主体 subgraph \" \" User[(\"fa:fa-user 用户 (HR/业务经理)\")] end subgraph \"HRM Agent 核心 (AI大脑)\" LLM_Parse[\"fa:fa-brain LLM: 意图识别 & 参数提取\"] subgraph \"知识库 (RAG检索)\" KB_Tools[\"fa:fa-book 原子能力工具库 • 描述每个工具的功能 • 描述所需参数\"] KB_Rules[\"fa:fa-sitemap 工具调用规则库 • 定义业务流程/DAG\"] end LLM_Plan[\"fa:fa-lightbulb LLM: 生成结构化执行计划 (DAG)\"] LLM_Summary[\"fa:fa-comment-dots LLM: (可选)总结结果并生成回复\"] end subgraph \"执行层 (确定性引擎)\" ExecEngine[\"fa:fa-cogs 执行引擎 (Orchestrator)\"] Atomic_Tools_Layer[\"fa:fa-bolt 原子工具层 (ERP API 封装)\"] end subgraph \"后端系统\" ERP[\"fa:fa-database ERP 后端系统 • 员工数据库 • 薪酬数据库 • 组织数据库\"] end subgraph \" \" User_Output[(\"fa:fa-check-circle 最终输出\")] end %% 定义流程连线 User -- \"自然语言指令\" --> LLM_Parse LLM_Parse -- \"RAG检索\" --> KB_Tools LLM_Parse -- \"RAG检索\" --> KB_Rules KB_Rules -- \"提供流程模板\" --> LLM_Plan KB_Tools -- \"提供工具定义\" --> LLM_Plan LLM_Parse -- \"传递意图与参数\" --> LLM_Plan LLM_Plan -- \"输出精确的执行计划\" --> ExecEngine ExecEngine -- \"依次调用工具\" --> Atomic_Tools_Layer Atomic_Tools_Layer -- \"执行具体数据库操作\" --> ERP ERP -- \"返回操作结果\" --> Atomic_Tools_Layer Atomic_Tools_Layer -- \"返回执行状态\" --> ExecEngine ExecEngine -- \"返回结构化执行结果\" --> LLM_Summary LLM_Summary -- \"生成人性化回复\" --> User_Output User_Output --> User %% 应用样式 class User,User_Output userStyle class LLM_Parse,LLM_Plan,LLM_Summary llmStyle class KB_Tools,KB_Rules artifactStyle class ExecEngine,Atomic_Tools_Layer execStyle class ERP systemStyle %% 箭头样式 linkStyle default stroke:#555,stroke-width:2px,color:black;","tags":["Agent"],"categories":["技术","Agent"]},{"title":"2025-06、07","path":"/Essays/20250720六月/","content":"新业务、新挑战、新机遇。低调做人，高调做事。chongwen二〇二五年六月七月 工作体验新入职 这是一家医疗领域的上市公司，原有的程序员主要负责企业内部ERP和其他系统的开发。为了搭上AI的列车，这次公司专门招聘了几位熟悉AI的员工，负责AI功能的研发。 其他方面还不错，领导和同事都很好。 小槽点是办公电脑性能一般，公司没有专门为程序员配电脑，我们用的和其他业务人员一样。不过我的电脑环境一般都保持的不错，写代码时开4个IDE也还算流畅，只是运行WSL时内存占用60%，用不了docker了。 展露头脚 这是我的第三份工作。在前两家公司，都是入职几个月后，凭借某个项目的表现获得了领导和同事的认可。 第二份工作印象很深，前一个多月都在自学昇腾相关知识，第一个任务是在ModelArts910A上实现远程小模型推理，包括服务端和客户端、pt模型转om模型、使用aisbench组件做推理、前后处理等，模型是YOLOv5。除了模型转换和推理的难度外，还要解决ModelArts服务器无法暴露IP、需通过特殊方式远程请求的问题。其实在此之前我对YOLO了解不多，领导给了一周时间，最终我加班两天就完成了第一版。这个项目做得很漂亮，后续还有几个项目也表现不错，领导多次在会上表扬，就这样，技术能力得到了认可。 这次被认可得更早一些，刚入职没几天，领导问我是否熟悉昇腾下PaddleOCR的推理。我对昇腾下PaddleOCR推理比较熟悉，之前还专门写过一篇华为om模块推理的文章：https://blog.csdn.net/weixin_45653525/article/details/147519518。 我了解PaddleOCR在昇腾上的问题。PaddlePaddle框架层面官方适配了昇腾，但具体模型和算子未必都支持。使用PaddlePaddle推理平均单张图片推理耗时约10秒。 公司正在和华为合作，试用华为OCR，但如果有免费的方案，当然优先用免费。最终我用Pytorch推理方式解决了性能瓶颈，单张耗时降到0.3～0.8秒。最近太忙，后续有时间会整理一下解决思路。另外还有一件事也做得很不错。这确实为公司省了钱，老板在会上表扬了我，发了奖金。虽然钱不多，但是对我工作的肯定，我很开心。 表扬邮件 项目总结 现在全职做应用开发，很开心，尤其喜欢从零到一突破有难度的项目。 目前做的功能大多依赖大模型，但大模型的能力在实际业务场景下，并不能达到业务的100%，有时只能达到60%-70%，剩下的只能靠工程化或更合适的小模型来突破精度和性能。 通过各种奇思妙想，有时将性能提升到90%，但要突破“最后一公里”到100%还是很难。尤其公司业务用开源大模型，参数量也不高，进一步加大了工程化难度。 比如某个场景用Gemini2.5Pro，精度直接达到90%，且无需复杂提示词。而用开源32B大模型，尝试了各种提示词手段、工程化手段，最终还是难以达到Gemini2.5Pro简单提示词的效果。 与传统应用开发不同，做AI应用充满不确定性，结果和过程都不确定。有时修改一句提示词，就可能导致某些场景效果变差。这种不确定性让开发和进度管理变得更难，尤其在老板催进度时，开发得好就更难了。 困难是有的，解决困难的方法是不确定的，也正因如此，开发过程更有趣，解决难题后也更有成就感。 同时告诫自己，工作中要秉承着“低调做人，高调做事”。 生活苏州游 五一假期忙着搬家，没有出去玩。五一后的一个周末，我们选择去离上海很近的苏州，高铁只需30分钟。 那时苏州正值阴雨天气，空气中潮湿与闷热交织。 去了几个有名的园林和步行街。 image-20250720223757762image-20250720223814999image-20250720223828602image-20250720223836169image-20250720223747991image-20250720224308374 体验密室逃脱 周末和之前关系很好的同事约着聚会，计划是吃汉堡自助和体验密室逃脱。 汉堡自助没吃成，到店发现只有一桌顾客，旁边一家全品类自助人很多，就改去人多的那家。品类丰富，有海鲜、烧烤、烤肉、水果蔬菜点心，但感觉食材一般，很多是预制品。 密室逃脱我之前没玩过，其实一直很想体验。同事找的剧本据说是上海排名前几的，微恐，价格也很贵，200多一位。我们觉得第一次就一次性体验个好的吧。 一共90分钟，结束后我只能说“真的很吓人”，把小齐都吓得呼吸性碱中毒了，ps：她还是全程闭着眼睛的状态。 全黑环境、狭小恐怖的电梯、追人的女鬼、血手印厕所、长脖子鬼，尤其是那特别恐怖的背景音乐。机关设计很巧妙，比如整个房子的前后移动、上下层、电梯… 让人害怕的主要原因是全黑环境和恐怖的背景音乐。 image-20250720230302206image-20250720230341274image-20250720230400196 小齐的朋友圈 妈妈的手术 妈妈打扫卫生时不小心崴到膝盖，导致两条韧带断裂。当天就去了市医院急诊，做完检查后医生说不需要手术，先静养。 在家躺了一周多，妈妈状态还是不好，考虑是不是可以去康复科治疗。我在京东约了上海的好医生电话询诊，医生看了磁共振和CT后，判断需要手术，静养不行。我也查了资料，确实韧带断裂需要手术，静养韧带不会自己长好，100多的咨询费没白花。之后爸妈又去了市医院，找了好大夫，确定要做手术。 手术时间刚好是周六，我和小齐买了回家的车票，陪妈妈做手术。 手术很快，不到一个小时，医院也很人性化，提供护工服务，140一天，虽然是1对多，但护工很尽责。我们待了两天，确定妈妈没其他问题，只需恢复。 父母年龄渐长，我们无法常伴身边，只能在关键时刻回去陪伴。 最近的饭 image-20250720231835236image-20250720231846941image-20250720231858557image-20250720231907912image-20250720231917733image-20250720231923586","tags":["我"],"categories":["随笔"]},{"title":"【实时更新】大模型发布时间轴","path":"/大模型发布时间轴/","content":"点击卡片将直接跳转到专题页面「大模型发布时间轴」。","tags":["大模型","时间轴"],"categories":["AI"]},{"title":"使用TypeScript构建一个最简单的MCP服务器","path":"/技术/AI/ai-mcp_01/","content":"什么是MCP？Model Context Protocol（模型上下文协议）是一个开放标准，它允许AI助手与外部工具和数据源进行标准化通信。简单来说，MCP就像是AI和各种工具之间的”翻译官”，让AI能够调用你编写的自定义功能。 项目准备1. 初始化项目首先，让我们创建一个新的TypeScript项目： 123mkdir mcp-calculator-servercd mcp-calculator-servernpm init -y 2. 安装核心依赖1234567891011# 核心MCP SDKnpm install @modelcontextprotocol/sdk# 输入验证库npm install zod# TypeScript相关依赖npm install -D typescript @types/node# 创建TypeScript配置npx tsc --init 3. 项目结构设计123456789mcp-calculator-server/├── package.json # 项目配置├── tsconfig.json # TypeScript配置├── src/│ └── server/│ └── index.ts # 主服务器文件├── build/ # 编译输出└── .vscode/ └── mcp.json # VS Code MCP配置 核心代码实现1. 服务器基础框架让我们从最基本的服务器结构开始： 123456789101112131415161718192021#!/usr/bin/env nodeimport &#123; McpServer &#125; from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;import &#123; StdioServerTransport &#125; from &quot;@modelcontextprotocol/sdk/server/stdio.js&quot;;import &#123; z &#125; from &quot;zod&quot;;/** * MCP Calculator Server * 一个功能完整的计算器MCP服务器 */// 创建服务器实例const server = new McpServer(&#123; name: &quot;mcp-calculator-server&quot;, version: &quot;1.0.0&quot;, description: &quot;提供基本四则运算功能的MCP计算器服务器&quot;, capabilities: &#123; resources: &#123;&#125;, // 资源能力 tools: &#123;&#125;, // 工具能力 &#125;,&#125;); 2. 输入验证Schema定义使用Zod进行严格的输入验证： 123456// 数字参数验证const NumberSchema = z.number().describe(&quot;数值参数，支持整数和浮点数&quot;);// 可以扩展更复杂的验证规则const PositiveNumberSchema = z.number().positive().describe(&quot;正数&quot;);const IntegerSchema = z.number().int().describe(&quot;整数&quot;); 3. 工具实现：加法运算1234567891011121314151617181920212223server.tool( &quot;add&quot;, &quot;执行两个数字的加法运算，返回它们的和。支持整数和浮点数。&quot;, &#123; a: NumberSchema, b: NumberSchema, &#125;, async (&#123; a, b &#125;) =&gt; &#123; const result = a + b; // 记录操作日志（用于调试） console.error(`计算: $&#123;a&#125; + $&#123;b&#125; = $&#123;result&#125;`); return &#123; content: [ &#123; type: &quot;text&quot;, text: `$&#123;a&#125; + $&#123;b&#125; = $&#123;result&#125;`, &#125;, ], &#125;; &#125;); 4. 错误处理：除法运算在实际项目中，错误处理至关重要： 12345678910111213141516171819202122232425262728293031323334server.tool( &quot;divide&quot;, &quot;执行两个数字的除法运算，包含除零错误检查。&quot;, &#123; dividend: NumberSchema.describe(&quot;被除数&quot;), divisor: NumberSchema.describe(&quot;除数&quot;), &#125;, async (&#123; dividend, divisor &#125;) =&gt; &#123; // 除零检查 if (divisor === 0) &#123; console.error(`错误: 除数不能为零`); return &#123; content: [ &#123; type: &quot;text&quot;, text: &quot;错误：除数不能为零，请检查输入参数。&quot;, &#125;, ], &#125;; &#125; const result = dividend / divisor; console.error(`计算: $&#123;dividend&#125; ÷ $&#123;divisor&#125; = $&#123;result&#125;`); return &#123; content: [ &#123; type: &quot;text&quot;, text: `$&#123;dividend&#125; ÷ $&#123;divisor&#125; = $&#123;result&#125;`, &#125;, ], &#125;; &#125;); 5. 服务器启动逻辑123456789101112131415161718async function main() &#123; try &#123; // 使用标准输入输出传输 const transport = new StdioServerTransport(); await server.connect(transport); console.error(&quot;MCP计算器服务器已启动，使用stdio传输&quot;); &#125; catch (error) &#123; console.error(&quot;服务器启动失败:&quot;, error); process.exit(1); &#125;&#125;// 启动服务器并处理异常main().catch((error) =&gt; &#123; console.error(&quot;主函数执行失败:&quot;, error); process.exit(1);&#125;); 完整的服务器代码将所有部分组合起来，我们得到了一个完整的MCP计算器服务器。这个服务器包含四个基本运算工具： add: 加法运算 subtract: 减法运算 multiply: 乘法运算 divide: 除法运算（含错误处理） 每个工具都有详细的描述和严格的输入验证，确保服务器的稳定性和易用性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188#!/usr/bin/env node/** * 新手版 MCP 计算器服务器 * * 这是一个简化的MCP服务器示例，适合初学者学习 * 提供基本的加减乘除运算功能 * * 安装依赖： * npm install @modelcontextprotocol/sdk zod * * 编译运行： * npx tsc * node build/server/index.js */// 导入需要的模块import &#123; McpServer &#125; from &quot;@modelcontextprotocol/sdk/server/mcp.js&quot;;import &#123; StdioServerTransport &#125; from &quot;@modelcontextprotocol/sdk/server/stdio.js&quot;;import &#123; z &#125; from &quot;zod&quot;;// 创建服务器const server = new McpServer(&#123; name: &quot;simple-calculator&quot;, version: &quot;1.0.0&quot;, capabilities: &#123; resources: &#123;&#125;, tools: &#123;&#125;, &#125;,&#125;);// 定义数字验证规则const NumberSchema = z.number().describe(&quot;数字&quot;);// 加法工具server.tool( &quot;add&quot;, &quot;计算两个数字相加&quot;, &#123; a: NumberSchema, b: NumberSchema, &#125;, async (&#123; a, b &#125;) =&gt; &#123; const result = a + b; return &#123; content: [ &#123; type: &quot;text&quot;, text: `$&#123;a&#125; + $&#123;b&#125; = $&#123;result&#125;`, &#125;, ], &#125;; &#125;);// 减法工具server.tool( &quot;subtract&quot;, &quot;计算两个数字相减&quot;, &#123; a: NumberSchema, b: NumberSchema, &#125;, async (&#123; a, b &#125;) =&gt; &#123; const result = a - b; return &#123; content: [ &#123; type: &quot;text&quot;, text: `$&#123;a&#125; - $&#123;b&#125; = $&#123;result&#125;`, &#125;, ], &#125;; &#125;);// 乘法工具server.tool( &quot;multiply&quot;, &quot;计算两个数字相乘&quot;, &#123; a: NumberSchema, b: NumberSchema, &#125;, async (&#123; a, b &#125;) =&gt; &#123; const result = a * b; return &#123; content: [ &#123; type: &quot;text&quot;, text: `$&#123;a&#125; × $&#123;b&#125; = $&#123;result&#125;`, &#125;, ], &#125;; &#125;);// 除法工具server.tool( &quot;divide&quot;, &quot;计算两个数字相除&quot;, &#123; a: NumberSchema, b: NumberSchema, &#125;, async (&#123; a, b &#125;) =&gt; &#123; // 检查除数是否为零 if (b === 0) &#123; return &#123; content: [ &#123; type: &quot;text&quot;, text: &quot;错误：不能除以零&quot;, &#125;, ], &#125;; &#125; const result = a / b; return &#123; content: [ &#123; type: &quot;text&quot;, text: `$&#123;a&#125; ÷ $&#123;b&#125; = $&#123;result&#125;`, &#125;, ], &#125;; &#125;);// 启动服务器async function main() &#123; try &#123; const transport = new StdioServerTransport(); await server.connect(transport); console.error(&quot;计算器服务器已启动&quot;); &#125; catch (error) &#123; console.error(&quot;启动失败:&quot;, error); process.exit(1); &#125;&#125;main().catch((error) =&gt; &#123; console.error(&quot;运行出错:&quot;, error); process.exit(1);&#125;);/*使用方法：1. 安装依赖包 npm install @modelcontextprotocol/sdk zod2. 编译 TypeScript npx tsc3. 在 VS Code 中配置 .vscode/mcp.json： &#123; &quot;servers&quot;: &#123; &quot;calculator&quot;: &#123; &quot;type&quot;: &quot;stdio&quot;, &quot;command&quot;: &quot;node&quot;, &quot;args&quot;: [&quot;你的绝对路径/server/index.js&quot;] &#125; &#125; &#125;4. 重启 VS Code，然后就可以使用计算功能了代码说明：- McpServer: 创建 MCP 服务器- server.tool(): 定义可用的工具/功能- NumberSchema: 验证输入必须是数字- async/await: 处理异步操作- StdioServerTransport: 使用标准输入输出通信每个工具包含：- 名称 (如 &quot;add&quot;)- 描述 (如 &quot;计算两个数字相加&quot;)- 参数定义 (如 &#123;a: NumberSchema, b: NumberSchema&#125;)- 实现函数 (执行具体的计算逻辑)*/ VS Code集成配置1. 创建MCP配置文件在项目根目录的.vscode/mcp.json中配置： 123456789&#123; &quot;servers&quot;: &#123; &quot;mcp-calculator&quot;: &#123; &quot;type&quot;: &quot;stdio&quot;, &quot;command&quot;: &quot;node&quot;, &quot;args&quot;: [&quot;你的绝对路径/server/index.js&quot;] &#125; &#125;&#125; MCP配置参数详解 参数 作用 示例值 说明 servers 服务器配置容器 &#123;...&#125; 包含所有MCP服务器的配置信息 &quot;mcp-calculator&quot; 服务器标识名称 任意字符串 VS Code中显示的服务器名称，可自定义 type 通信协议类型 &quot;stdio&quot; 支持stdio（标准输入输出）模式 command 执行命令 &quot;node&quot; 用于启动MCP服务器的可执行文件 args 命令参数数组 [&quot;你的绝对路径/server/index.js&quot;] 传递给command的参数列表 配置示例解析12345678910111213141516&#123; &quot;servers&quot;: &#123; &quot;calculator&quot;: &#123; // 服务器名称（自定义） &quot;type&quot;: &quot;stdio&quot;, // 使用标准输入输出通信 &quot;command&quot;: &quot;node&quot;, // 使用Node.js执行 &quot;args&quot;: [ // 传递给node的参数 &quot;你的绝对路径/server/index.js&quot; // 编译后的服务器文件路径 ] &#125;, &quot;file-manager&quot;: &#123; // 可以配置多个服务器 &quot;type&quot;: &quot;stdio&quot;, &quot;command&quot;: &quot;python&quot;, &quot;args&quot;: [&quot;-m&quot;, &quot;my_mcp_server&quot;] &#125; &#125;&#125; ⚠️ 重要提示： 路径必须指向编译后的.js文件，不是.ts源文件 确保编译后的文件存在且有执行权限 2. 编译和构建12# 使用tsc编译，在目录下生成js文件npx tsc 3. 测试服务器12345678910# 1. 首先确保TypeScript已编译npx tsc# 2. 直接运行服务器测试node build/server/index.js# 3. 如果正常，您应该看到类似输出：# &quot;计算器服务器已启动&quot;# 4. 使用 Ctrl+C 停止服务器 参考资源 MCP官方文档 Zod验证库","tags":["MCP"],"categories":["技术","AI"]},{"title":"2025-05","path":"/Essays/20250603五月/","content":"离职倒计时。工作交接、华为布道师体验卡、找房子和搬家。chongwen二〇二五年五月 最后的工作时间确定离职 节后和两边领导最终确定了离职事宜。其实节前已经和华为领导沟通过，领导提出了三个挽留方案，但我最终还是没有选择留下。心里还是有些伤感，毕竟和同事们已经很熟悉了。 离职的最后阶段还遇到了一些糟心事。原本计划五月中旬入职新公司，但外包领导以现在离开会影响他们的人力KPI为由，将我的离职时间拖延到6月1号。还好新公司比较通情达理，在我解释原因后同意将入职时间延期到6月，非常感谢他们的理解。 最后一份工作 5月份没有什么新的项目，大部分时间都在处理自己的事情。直到第三周，领导让我协助上海“昇腾开发者训练营”分会场的一个模块赋能讲解。其他模块由几位华为专家负责，让我讲解的原因是我之前在其他场合做过小模型推理的讲师，领导认可我的讲解逻辑，最重要的是我对AI应用相关的模型推理比较熟悉。 课程题目是“DeepSeek+Dify大模型推理部署实践”，内容包括MindIE推理DS大模型、Dify的部署与实操、昇腾推理Embedding和Reranker。这是一门实践课，既有理论讲解也有机器实操，因此需要提前准备机器环境，一共8台机器。稍微有些麻烦，因为8台机器都是新系统，缺少一些软件和依赖。那周主要在准备和测试机器环境、整理课程文档、制作PPT和讲课内容，忙到飞起。课程计划讲解40分钟，实操1小时。 这是最后一项重要的工作。 最后看一眼工位和办公楼 image-20250720211115579image-20250720211149904 华为布道师体验卡 image-20250720211612570image-20250720211731503image-20250720211553727image-20250720211602474 找房子新工作在黄埔，距离现在住的地方大概40多分钟的路程。其实在上海这个时间还好，属于勉强接受的范围，但我习惯这边10分钟的通勤了，决定金钱换通勤时间。 我们找到了20多天房子，看了近10次、20多套房。但距离、价格都没有太合适的，黄埔的房子价格高，装修破，让人难以抉择。拖到了5月底，选择了一个租金偏高、装修好的房子，在一楼，有一个小院子。 在搬家的时候，我们觉得行李还是蛮多的，想着叫个大点的车，没想到叫的太大了😆，加上我的电驴才装了不到四分之一～ image-20250720211917107image-20250720211925179 最后记录一下生活了1年的小屋（是真的小） 小屋","tags":["我"],"categories":["随笔"]},{"title":"【昇腾】昇腾开发者训练营：Dify大模型部署实战","path":"/技术/AI/ai-MindIE-Dify/","content":"本次我负责【昇腾开发者训练营】上海分会场的【DeepSeek+Dify大模型推理部署实践】部分的讲解，需要完成PPT、实操手册、8台服务器的环境部署～ 机器：Atlas800 9000 即昇腾上一代芯片 910A，8卡32G，裸金属。 可能的卡点：ARM架构上部署Dify、910A上跑MindIE、910A上跑BGE向量模型和重排序模型。 注：本文档同样适用于 Atlas800T A2（910B）、Duo卡等设备。 部署 Dify1. Dify 适配 ARM12345git clone https://github.com/langgenius/dify.gitcd difygit checkout 0.15.3cd docker/cp .env.example .env 1. 修改配置文件 123vim docker-compose.yaml# 在redis的command后添加：--ignore-warnings ARM64-COW-BUG 2. 修改sandbox版本 将sandbox版本从0.2.10修改为0.2.1。0.2.10版本会出现新增模型失败的情况，修改后不使用插件式的方式，可以正常添加。 2. 安装 docker12345678910# 使用下面命令一键安装 docker 和 docker-composesudo yum install -y docker-engine docker-engine-selinux &amp;&amp; sudo bash -c &#x27;cat &gt; /etc/docker/daemon.json &lt;&lt;EOF&#123; &quot;registry-mirrors&quot;: [ &quot;https://docker.1ms.run&quot;, &quot;https://docker.xuanyuan.me&quot; ]&#125;EOF&#x27; &amp;&amp; sudo systemctl restart docker &amp;&amp; sudo curl -L &quot;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose &amp;&amp; sudo chmod +x /usr/local/bin/docker-compose 3. 启动 Dify1234567cd dify/dockerdocker-compose up -d# 停止服务并删除容器cd dify/dockerdocker-compose down MindIE+Dify 实操手册本文档以 Atlas 800-9000 服务器和 DeepSeek-R1-Distill-Qwen-32B-W8A8 模型为例，让开发者快速开始使用MindIE进行大模型推理流程。 MindIE（Mind Inference Engine，昇腾推理引擎）是基于昇腾硬件的运行加速、调试调优、快速迁移部署的高性能AI推理引擎。 1. 基础环境搭建注：本次昇腾开发者训练营提供的服务器基础环境已配置完毕，本章节可忽略。 1.1 环境检查物理机部署场景，需要在物理机安装NPU驱动固件以及部署Docker，执行如下步骤判断是否已安装NPU驱动固件和部署Docker。 执行以下命令查看NPU驱动固件是否安装。 1npu-smi info 1.2 下载模型权重权重已下载，路径：/home/aicc/models/DeepSeek-R1-Distill-Qwen-32B-W8A8 1.3 获取MindIE镜像昇腾镜像仓库地址：https://www.hiascend.com/developer/ascendhub/detail/af85b724a7e5469ebd7ea13c3439d48f 进入昇腾官方镜像仓库，根据设备型号选择下载对应的MindIE镜像。该镜像已具备模型运行所需的基础环境，包括：CANN、FrameworkPTAdapter、MindIE与ATB Models，可实现模型快速上手推理。 容器内各组件安装路径： 组件 安装路径 CANN &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;ascend-toolkit CANN-NNAL-ATB &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;nnal&#x2F;atb MindIE &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;mindie ATB Models &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;atb-models 2. 启动容器镜像已下载，执行以下命令启动容器。 本次课程已提供8卡服务器，建议每台服务器启动4个容器，小组内自由分配，每个容器可以使用双卡进行模型推理。 1234567891011121314151617181920212223242526# 注：命令执行前请修改 [容器名称]# 启动容器docker run -itd --privileged --name=m2 --net=host \\ --shm-size 500g \\ --device=/dev/davinci0 \\ --device=/dev/davinci1 \\ --device=/dev/davinci2 \\ --device=/dev/davinci3 \\ --device=/dev/davinci4 \\ --device=/dev/davinci5 \\ --device=/dev/davinci6 \\ --device=/dev/davinci7 \\ --device=/dev/davinci_manager \\ --device=/dev/hisi_hdc \\ --device /dev/devmm_svm \\ -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\ -v /usr/local/Ascend/firmware:/usr/local/Ascend/firmware \\ -v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\ -v /usr/local/sbin:/usr/local/sbin \\ -v /etc/hccn.conf:/etc/hccn.conf \\ -v /home/aicc:/home/aicc \\ swr.cn-central-221.ovaijisuan.com/wh-aicc-fae/mindie:910A-ascend_24.1.rc3-cann_8.0.t63-py_3.10-ubuntu_20.04-aarch64-mindie_1.0.T71.05 \\ bash # 进入容器docker exec -it [容器名称] /bin/bash 参数说明： 参数 参数说明 –privileged 特权容器，允许容器访问宿主机的所有设备。 –name 设置容器名称。 –device 表示映射的设备，可以挂载一个或者多个设备。需要挂载的设备如下：&#x2F;dev&#x2F;davinciX：NPU设备，X是ID号，如：davinci0。&#x2F;dev&#x2F;davinci_manager：davinci相关的管理设备。&#x2F;dev&#x2F;hisi_hdc：hdc相关管理设备。&#x2F;dev&#x2F;devmm_svm：内存管理相关设备。 -v &#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;driver:&#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;driver:ro 将宿主机目录“&#x2F;usr&#x2F;local&#x2F;Ascend&#x2F;driver”挂载到容器，请根据驱动所在实际路径修改。 -v &#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;sbin:ro 将宿主机工具“&#x2F;usr&#x2F;local&#x2F;sbin&#x2F;”以只读模式挂载到容器中，请根据实际情况修改。 -v &#x2F;path-to-weights:&#x2F;path-to-weights:ro 设定权重挂载的路径，需要根据用户的情况修改。说明请将权重文件和数据集文件同时放置于该路径下。 环境检查： 进入容器后，使用 npu-smi info 检查NPU驱动固件是否正常挂载。 3. 纯模型推理测试参考文档 ATB Models的run_pa.py脚本用于纯模型快速测试，脚本中未增加强校验，出现异常情况时，会直接抛出异常信息，常用于快速验证模型的可用性。 3.1 纯模型对话测试例如：使用/home/aicc/models/DeepSeek-R1-Distill-Qwen-32B-W8A8路径下的权重，使用2卡推理&quot;What&#39;s deep learning?&quot;和&quot;Hello World.&quot;，推理时batch size为2。 1pip install pandas # 测试前安装依赖 12345678910111213export ASCEND_RT_VISIBLE_DEVICES=1,2 # 设置使用的卡编号cd $&#123;ATB_SPEED_HOME_PATH&#125;torchrun --nproc_per_node 2 \\ --master_port 20030 \\ -m examples.run_pa \\ --model_path /home/aicc/models/DeepSeek-R1-Distill-Qwen-32B-W8A8 \\ --input_texts &quot;What&#x27;s deep learning?&quot; &quot;Hello World.&quot; \\ --max_batch_size 2 # 参数说明--nproc_per_node 使用的卡数--input_texts 推理文本或推理文本路径，多条推理文本间使用空格分割。省略则使用默认值：&quot;What&#x27;s deep learning?&quot;--max_batch_size 模型推理最大batch size。 启动测试 测试成功 3.2 性能测试安装依赖 1pip install tiktoken fuzzywuzzy jieba rouge # 测试前安装依赖 测试脚本 batch=1, 输入长度256, 输出长度256用例的2卡并行性能测试命令为： 1234export ASCEND_RT_VISIBLE_DEVICES=1,2 # 设置使用的卡编号cd $ATB_SPEED_HOME_PATH/tests/modeltest/bash run.sh pa_fp16 performance [[256,256]] 1 \\qwen /home/aicc/models/DeepSeek-R1-Distill-Qwen-32B-W8A8 2 耗时结果会显示在Console中，并保存在.&#x2F;benchmark_result&#x2F;benchmark.csv文件里。 4. 服务化部署4.1 MindIE 配置参考文档 修改MindIE配置： 1vim /usr/local/Ascend/mindie/latest/mindie-service/conf/config.json 主要参数： 123456789&quot;ipAddress&quot; : &quot;192.168.0.10&quot;, 改为本机内网地址&quot;managementIpAddress&quot; : &quot;192.168.0.10&quot;, 改为本机内网地址()&quot;port&quot; : 1025, 推理端口，请保证端口号无冲突&quot;managementPort&quot; : 1026, 管理面端口，请保证端口号无冲突&quot;metricsPort&quot; : 1027, 服务监控指标接口，请保证端口号无冲突&quot;npuDeviceIds&quot; : [[0,1]], 表示启用哪几张卡。对于每个模型实例分配的npuIds&quot;modelName&quot; : &quot;DeepSeek-R1-Distill-Qwen-32B-W8A8&quot;, 模型名称&quot;modelWeightPath&quot; : &quot;/home/aicc/models/DeepSeek-R1-Distill-Qwen-32B-W8A8/&quot;, 模型权重路径&quot;worldSize&quot; : 2, 启用几张卡推理。本模型启用两卡推理即可 注：小组内多个MindIE服务请保证 port 不同、modelName不同 4.2 MindIE 服务化首先进入mindie-service目录： 1cd /usr/local/Ascend/mindie/latest/mindie-service 方式一（推荐）：使用后台进程方式启动服务。后台进程方式启动服务后，关闭窗口后进程也会保留。 1nohup ./bin/mindieservice_daemon &gt; output.log 2&gt;&amp;1 &amp; 使用 tail 实时跟踪日志 1tail -f output.log 打印如下信息说明启动成功。 1Daemon start success! 方式二：直接启动服务。 1./bin/mindieservice_daemon 回显如下则说明启动成功。 1Daemon start success! 4.3 发起测试请求参考文档 重开一个窗口，使用以下命令发送请求： 1234567891011121314151617181920212223# OpenAI 接口curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; \\-X POST -d &#x27;&#123; &quot;model&quot;: &quot;DeepSeek-R1-Distill-Qwen-32B-W8A8&quot;, &quot;messages&quot;: [&#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot; &#125;], &quot;stream&quot;: false, &quot;presence_penalty&quot;: 1.03, &quot;frequency_penalty&quot;: 1.0, &quot;repetition_penalty&quot;: 1.0, &quot;temperature&quot;: 0.5, &quot;top_p&quot;: 0.95, &quot;top_k&quot;: 10, &quot;seed&quot;: null, &quot;stop&quot;: [&quot;stop1&quot;, &quot;stop2&quot;], &quot;stop_token_ids&quot;: [2, 13], &quot;include_stop_str_in_output&quot;: false, &quot;skip_special_tokens&quot;: true, &quot;ignore_eos&quot;: false, &quot;max_tokens&quot;: 20&#125;&#x27; http://192.168.0.10:1025/v1/chat/completions 5. 接入 Dify5.1 访问 Dify根据 弹性公网IP:Dify端口 访问本机的Dify前端页面 用户名&#x2F;密码：atlas@hw.com &#x2F; 0atlas@hw.com 5.2 配置大模型 点击右上角用户头像，点击“设置” 点击“模型提供商”，搜索OpenAI-API-compatible，点击“添加模型” 添加MindIE模型。 模型名称：填写MindIE配置的modelName API endpoint URL：填写本机内网IP:MindIE配置的port&#x2F;v1 新增OpenAI-API-compatible模型 添加过OpenAI-API-compatible模型后，可在弹窗上方看到已添加的模型列，可以点击“添加模型”继续添加。添加时请避免模型名称相同。 5.3 创建聊天助手 点击“工作室”、“创建空白应用” 选择 “聊天助手”，输入名称，点击 “创建” 选择模型 对话测试 输入内容进行对话测试，接收到响应即为正确。 进阶实操本文档以 Atlas 800-9000 服务器为例，让开发者快速开始使用TEI进行文本嵌入（Embedding）和重排序（Reranker）模型推理流程。 TEI（全称：Text Embeddings Inference）是由Huggingface推出的高性能推理框架，旨在简化和加速文本嵌入（Embedding）和重排序（Reranker）模型在生产环境中的部署。 TEI支持基于HTTP和gRPC协议的服务接口，能够高效处理文本嵌入的生成和基于文本相关性的重排序等任务；TEI框架同时也支持多种嵌入模型和重排序模型，并提供了灵活的请求批处理、模型管理和动态调度功能。通过TEI，开发者可以轻松地扩展和优化文本嵌入和重排序服务，以满足实时应用和批量处理的需求，特别适用于自然语言处理相关的在线推理任务，能够满足RAG（全称：Retrieval-Augmented Generation）、信息检索 (IR)、自然语言理解 (NLU)、文本分类以及个性化推荐系统等下游应用场景。 原生TEI仅支持GPU硬件环境，且Python后端接口仅支持Embedding模型的embed服务。昇腾实现了基于MindIE Torch与ATB的组图优化，拓展其Python后端功能、将其适配到昇腾环境。 本次使用以下模型： 模型名 说明 BAAI&#x2F;bge-large-zh-v1.5 稠密向量模型 BAAI&#x2F;bge-m3 稠密和稀疏向量模型 BAAI&#x2F;bge-reranker-large 排序模型 1. 环境部署注：本次昇腾开发者训练营提供的服务器基础环境已配置完毕，本章节可忽略。 1.1 下载模型权重权重已下载，路径：/home/aicc/bge_model 123456mkdir /home/aicc/bge_modelpip install modelscopemodelscope download --model BAAI/bge-large-zh-v1.5 --local_dir /home/aicc/bge_model/bge-large-zh-v1.5modelscope download --model BAAI/bge-reranker-large --local_dir /home/aicc/bge_model/bge-reranker-large modelscope download --model BAAI/bge-m3 --local_dir /home/aicc/bge_model/bge-m3 修改模型数据类型 修改每一个模型内部的配置项torch_dtype为float16， Atlas800 9000&#x2F;300I Duo&#x2F;300V Pro设备需修改。Atlas 800T A2等设备不用修改。 1234567cd /home/aicc/bge_modelvim bge-reranker-large/config.jsonvim bge-large-zh-v1.5/config.jsonvim bge-m3/config.json# 修改为：torch_dtype&quot;: &quot;float16&quot;, 1.2 获取镜像昇腾镜像仓库：https://www.hiascend.com/developer/ascendhub/detail/07a016975cc341f3a5ae131f2b52399d 进入昇腾官方镜像仓库，根据设备型号选择下载对应的TEI镜像，该镜像已具备模型运行所需的基础环境。 因为本次实验的机器为910A，所以需要根据官方镜像手动修改或重新构建。本次采用的是华为山东AICC的一位老哥的镜像，下载方式：docker pull crpi-8ew3ouqcvy9yujug.cn-hangzhou.personal.cr.aliyuncs.com/sxj731533730/mis-tei_atlas_800_9000:v0 2. 启动容器注意： 请修改本机 IP 和 端口，以下命令采用IP为192.168.0.10，端口为9000、9001、9002 修改推理卡编号：TEI_NPU_DEVICE=0 表示使用0卡推理，请修改为合适的卡号 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# 启动 BAAI/bge-m3 推理容器docker run -itd -u root -e ENABLE_BOOST=True --privileged=true \\-e TEI_NPU_DEVICE=0 --name=bge-m3 --net=host \\-v /home/aicc/bge_model:/home/HwHiAiUser/model \\--device=/dev/davinci_manager \\--device=/dev/hisi_hdc \\--device=/dev/devmm_svm \\--device=/dev/davinci0 \\--device=/dev/davinci1 \\--device=/dev/davinci2 \\--device=/dev/davinci3 \\--device=/dev/davinci4 \\--device=/dev/davinci5 \\--device=/dev/davinci6 \\--device=/dev/davinci7 \\-v /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro \\-v /usr/local/sbin:/usr/local/sbin:ro \\mis-tei_atlas_800_9000:v0 # 启动服务docker exec -it bge-m3 bashexport HOME=/home/HwHiAiUserbash start.sh BAAI/bge-m3 192.168.0.10 9000# 启动 BAAI/bge-large-zh-v1.5 推理容器docker run -itd -u root -e ENABLE_BOOST=True --privileged=true \\-e TEI_NPU_DEVICE=0 --name=bge-large-zh-v1.5 --net=host \\-v /home/aicc/bge_model:/home/HwHiAiUser/model \\--device=/dev/davinci_manager \\--device=/dev/hisi_hdc \\--device=/dev/devmm_svm \\--device=/dev/davinci0 \\--device=/dev/davinci1 \\--device=/dev/davinci2 \\--device=/dev/davinci3 \\--device=/dev/davinci4 \\--device=/dev/davinci5 \\--device=/dev/davinci6 \\--device=/dev/davinci7 \\-v /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro \\-v /usr/local/sbin:/usr/local/sbin:ro \\mis-tei_atlas_800_9000:v0 # 启动服务docker exec -it bge-large-zh-v1.5 bashexport HOME=/home/HwHiAiUserbash start.sh BAAI/bge-large-zh-v1.5 192.168.0.10 9001# 启动 BAAI/bge-reranker-large 推理容器docker run -itd -u root -e ENABLE_BOOST=True --privileged=true \\-e TEI_NPU_DEVICE=0 --name=bge-reranker-large --net=host \\-v /home/aicc/bge_model:/home/HwHiAiUser/model \\--device=/dev/davinci_manager \\--device=/dev/hisi_hdc \\--device=/dev/devmm_svm \\--device=/dev/davinci0 \\--device=/dev/davinci1 \\--device=/dev/davinci2 \\--device=/dev/davinci3 \\--device=/dev/davinci4 \\--device=/dev/davinci5 \\--device=/dev/davinci6 \\--device=/dev/davinci7 \\-v /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro \\-v /usr/local/sbin:/usr/local/sbin:ro \\-v /usr/local/sbin:/usr/local/sbin:ro \\mis-tei_atlas_800_9000:v0 # 启动服务docker exec -it bge-reranker-large bashexport HOME=/home/HwHiAiUserbash start.sh BAAI/bge-reranker-large 192.168.0.10 9002# 对于800TA2、300I Duo设备无需进入容器手动启动服务。将模型名称、IP、端口作为容器启动参数，例如：docker run -itd -u root -e ENABLE_BOOST=True --privileged=true \\-e TEI_NPU_DEVICE=0 --name=bge-m3 --net=host \\-v /home/aicc/bge_model:/home/HwHiAiUser/model \\ -e POOLING=splade \\--device=/dev/davinci_manager \\--device=/dev/hisi_hdc \\--device=/dev/devmm_svm \\--device=/dev/davinci0 \\--device=/dev/davinci1 \\-v /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro \\-v /usr/local/sbin:/usr/local/sbin:ro \\swr.cn-south-1.myhuaweicloud.com/ascendhub/mis-tei:7.0.RC1-800I-A2-aarch64 BAAI/bge-m3 127.0.0.1 9000 关键参数解释： user: 容器运行用户，可配置为root或HwHiAiUser，如果不配置默认使用HwHiAiUser,建议以普通用户HwHiAiUser运行降低容器运行相关安全风险 -e ASCEND_VISIBLE_DEVICES: 挂载指定的npu卡到容器中，只有宿主机安装了Ascend Docker Runtime，此环境变量才会生效，如果未安装Ascend Docker Runtime,可参考配置如下参数挂载指定的卡到容器 1234567--device=/dev/davinci_manager \\--device=/dev/hisi_hdc \\--device=/dev/devmm_svm \\--device=/dev/davinci0 \\--device=/dev/davinci1 \\-v /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro \\-v /usr/local/sbin:/usr/local/sbin:ro \\ -e ENABLE_BOOST: 使能bert、roberta、xml-roberta类模型推理加速 model dir: 模型存放的上级目录，如&#x2F;home&#x2F;data，不能配置为&#x2F;home和&#x2F;home&#x2F;HwHiAiUser容器内的挂载目录&#x2F;home&#x2F;HwHiAiUser&#x2F;model不可更改 image id：从ascendhub网上拉取镜像后的镜像ID model id：从modelscope上获取的模型ID：例如：BAAI&#x2F;bge-base-zh-v1.5, BAAI&#x2F;bge-reranker-large等，如需运行时下载模型，请确保网络可访问modelscope网站 listen ip：TEI服务的监听IP，例如：127.0.0.1 listen port：TEI服务的监听端口，例如：8080 稀疏向量模型添加(本次实践无需添加): -e POOLING=splade,请求接口采用embed_sparse 3. 推理测试使用以下命令进行推理测试： 1234567891011121314curl 192.168.0.10:9000/embed \\ -X POST \\ -d &#x27;&#123;&quot;inputs&quot;:&quot;What is Deep Learning?&quot;&#125;&#x27; \\ -H &#x27;Content-Type: application/json&#x27; curl 192.168.0.10:9001/embed \\ -X POST \\ -d &#x27;&#123;&quot;inputs&quot;:&quot;I like you.&quot;&#125;&#x27; \\ -H &#x27;Content-Type: application/json&#x27;curl 192.168.0.10:9002/rerank \\ -X POST \\ -d &#x27;&#123;&quot;query&quot;:&quot;What is Deep Learning?&quot;, &quot;texts&quot;: [&quot;Deep Learning is not...&quot;, &quot;Deep learning is...&quot;]&#125;&#x27; \\ -H &#x27;Content-Type: application/json&#x27; 本镜像接口规范（符合TEI）： 4. 接入 Dify4.1 配置模型在“模型供应商”中查询Text Embedding Inference，依次添加以下参数： API Key 需要填写，随意填写即可。 模型名称 服务器URL API Key bge-m3 http://192.168.0.10:9000 1 bge-large-zh-v1.5 http://192.168.0.10:9001 1 bge-reranker-large http://192.168.0.10:9002 1 4.2 创建知识库 点击“知识库”，点击“创建知识库” 从本地选择一个文件导入： 选择文件后，点击“下一步” 配置分段：使用默认配置无需修改 保证Embedding模型和Rerank模型设置正确，下滑到底部点击“保存并处理” 点击“前往文档” 可查看处理后的文件状态 5. 创建聊天助手 点击 “创建”点击“工作室”、“创建空白应用” 选择 “聊天助手”，输入名称， 点击添加上下文 选择处理好的知识库 提问 回答正确：","tags":["AI","昇腾"],"categories":["技术","AI"]},{"title":"PocketFlow","path":"/技术/AI/ai-PocketFlow/","content":"文档 PocketFlow是一个只用100代码编写的Agent框架，可以实现多种LLM设计模式，如Agent、Workflow、RAG等，也提供了很多功能样例。 最重要的是，这是一款符合cursor编程的Agent框架，内置了多个cursor-rules，同时由于本身源代码量就很少，所以cursor很容易理解PocketFlow，并基于PocketFlow编写应用。 另一个好处是学习成本低，更容易上手。相比于其他重量级的框架如LangGraph，需要我们熟悉LangGraph的许多框架规则，虽然他提供的功能很多，但也会增加我们的学习成本，也不易调试程序。而PocketFlow规则少、清晰简单。 LangGraph文档 PocketFlow文字也比较详细了，在这里将记录符合我习惯的文档风格，也作为一个学习的过程。 1. 要素1.1 节点 Node描述shared：全局的数据（内存中的字典）。一般作为prep的读取和post的输出。 节点中会顺序执行三个步骤： prep(shared)：数据预处理。读取shared，进行数据的预处理。 exec(prep_res)：动作执行。接收处理好的数据，执行动作。exec中不直接访问shared。 返回exec_res，传递给post()。 如果只需要处理数据，可以不实现exec。 post(shared, prep_res, exec_res)：数据后处理。接收exec的输出，整理数据并写入shared。 通过返回字符串（action = &quot;default&quot;）来决定下一步操作。 123456789class Start(Node): def prep(self, shared): pass def exec(self,prep_res): pass def post(self, shared, prep_res, exec_res): pass 12345678910111213141516class Node(Node): def prep(self, shared): # 数据预处理 return shared.get(&quot;name&quot;) def exec(self,prep_res): # 动作 exec_res = prep_res * 10 return exec_res def post(self, shared, prep_res, exec_res): # 更新状态 shared[&quot;name&quot;] = exec_res # 确定方向 return exec_res 容错参数 max_retries：错误重试次数 wait：下次重试的等待时间，单位秒。场景如 LLM 提供商的速率限制时。 获取当前重试次数： 1234class RetryNode(Node): def exec(self, prep_res): print(f&quot;Retry &#123;self.cur_retry&#125; times&quot;) raise Exception(&quot;Failed&quot;) 容错函数：重试后仍错误，将执行exec_fallback，可准备一个后备结果 12def exec_fallback(self, prep_res, exc): raise exc 代码样例代码 节点运行使用node.run(shared) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from pocketflow import Nodefrom utils.call_llm import call_llm shared = &#123; &quot;data&quot;: &quot;&quot;&quot;**春天的作文**春天，是四季中最充满希望和生机的季节。当冬日的寒冷渐渐退去，温暖的阳光洒满大地，万物开始苏醒，春天就这样悄无声息地来到了我们的身边。清晨，我走出家门，迎面扑来的是清新的空气，夹杂着泥土的芬芳和花草的香气。路边的小草悄悄地从土里探出头来，嫩绿的叶子在微风中轻轻摇曳，仿佛在向人们招手。树木也披上了新装，枝头上绽开了朵朵花苞，有的已经盛开，粉红的桃花、雪白的梨花、金黄的迎春花，把整个世界装扮得五彩缤纷。公园里，孩子们在草地上奔跑、嬉戏，欢笑声回荡在空气中。老人们坐在长椅上，享受着温暖的阳光，脸上洋溢着幸福的笑容。鸟儿们也从南方飞回来了，在树枝间跳跃，唱着动听的歌谣，仿佛在庆祝春天的到来。春天不仅带来了美丽的景色，还给人们带来了无限的希望和动力。农民伯伯开始忙碌起来，播种希望；学生们也重新投入到学习中，迎接新的挑战。春天就像一位温柔的画家，用她的画笔描绘出一幅幅生动的画面，让人心情愉悦，充满活力。我爱春天，爱她的美丽，爱她的生机，更爱她带给人们的希望与梦想。让我们珍惜这美好的季节，努力拼搏，迎接更加灿烂的明天！&quot;&quot;&quot;, &quot;summary&quot;: &quot;&quot;&#125;class SummarizeFile(Node): def prep(self, shared): return shared[&quot;data&quot;] def exec(self, prep_res): if not prep_res: return &quot;Empty file content&quot; prompt = f&quot;Summarize this text in 10 words: &#123;prep_res&#125;&quot; summary = call_llm(prompt) # 现在调用的是工具函数 return summary def exec_fallback(self, prep_res, exc): # Provide a simple fallback instead of crashing return &quot;There was an error processing your request.&quot; def post(self, shared, prep_res, exec_res): shared[&quot;summary&quot;] = exec_res # Return &quot;default&quot; by not returningsummarize_node = SummarizeFile(max_retries=3)# node.run() calls prep-&gt;exec-&gt;post# If exec() fails, it retries up to 3 times before calling exec_fallback()action_result = summarize_node.run(shared)print(&quot;Action returned:&quot;, action_result) # &quot;default&quot;print(&quot;Summary stored:&quot;, shared[&quot;summary&quot;])# 输出# Action returned: None# Summary stored: There was an error processing your request. 1.2 流程 Flow使用Flow做流式编排，通过简单的定义实现LangGraph的功能。 Flow的方向每个Node都会返回一个Action字符串。如果节点的post没有返回值，默认Action为“defaut”。 默认的方向：node_a &gt;&gt; node_b ，意味着如果节点node_a没有返回值或者返回&#39;defaut&#39;，则方向是node_b 命名的方向：node_a - &quot;action_name&quot; &gt;&gt; node_b，意味着如果节点node_a的返回值为&quot;action_name&quot;，则方向是node_b 基于以上两个方向的定义，可以通过Flow创建循环、分支等 Flow的创建 先定义节点方向 创建Flow，用start定义初始节点 run 运行Flow，并根据节点post返回值决定方向并执行，直到没有下一个节点 123node_a &gt;&gt; node_bflow = Flow(start=node_a)flow.run(shared) 样例代码：分支、循环结合 节点post、默认方向流、命名方向流，可以实现节点间的循环、分支判断。 12345678910# Define the flow connectionsreview - &quot;approved&quot; &gt;&gt; payment # If approved, process paymentreview - &quot;needs_revision&quot; &gt;&gt; revise # If needs changes, go to revisionreview - &quot;rejected&quot; &gt;&gt; finish # If rejected, finish the processrevise &gt;&gt; review # After revision, go back for another reviewpayment &gt;&gt; finish # After payment, finish the processflow = Flow(start=review) 做了一个循环、退出循环的测试代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 循环、分支、结束# 循环：a -&gt; b -&gt; c -&gt; d -&gt; a -&gt; ...# 每次循环，shared 的 loop 减 1# 当 loop 为 0 时，返回 &#x27;default&#x27;# 结束：d -&gt; end# 在post中判断方向from pocketflow import Node,Flowclass A(Node): def prep(self, shared): print(&quot;-&quot; * 50) if shared.get(&quot;name&quot;) == &quot;a&quot;: print(f&quot;开始倒数第&#123;shared.get(&#x27;loop&#x27;)&#125;次循环&quot;) return shared.get(&quot;name&quot;) def exec(self,prep_res): exec_res = chr(ord(prep_res) + 1) return exec_res def post(self, shared, prep_res, exec_res): print(f&quot;当前节点: &#123;prep_res&#125;&quot;) print(f&quot;下一个节点: &#123;exec_res&#125;&quot;) shared[&quot;name&quot;] = exec_res if prep_res == &quot;d&quot;: shared[&quot;name&quot;] = &quot;a&quot; shared[&quot;loop&quot;] = shared.get(&quot;loop&quot;) - 1 if shared.get(&quot;loop&quot;) == 0: return &#x27;default&#x27; return &#x27;a&#x27; else: print(f&quot;通过 &#123;shared.get(&#x27;name&#x27;)&#125;&quot;) return exec_resclass End(Node): def prep(self, shared): print(&quot;-&quot; * 50) return None def post(self, shared, prep_res, exec_res): print(&quot;Game Over&quot;) return Nonea = A()b = A()c = A()d = A()end = End()a - &#x27;b&#x27; &gt;&gt; bb - &quot;c&quot; &gt;&gt; cc - &#x27;d&#x27; &gt;&gt; dd - &#x27;a&#x27; &gt;&gt; ad &gt;&gt; endflow = Flow(start=a)shared = &#123; &quot;name&quot;: &quot;a&quot;, &quot;loop&quot;: 3&#125;flow.run(shared) Flow 嵌套流程也是节点，适用节点的规则。 12345678910# Create a sub-flownode_a &gt;&gt; node_bsubflow = Flow(start=node_a)# Connect it to another nodesubflow &gt;&gt; node_c# Create the parent flowparent_flow = Flow(start=subflow) 样例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354from pocketflow import Node,Flowclass Node(Node): def prep(self, shared): print(f&quot;当前节点: &#123;shared.get(&#x27;name&#x27;)&#125;&quot;) return shared.get(&quot;name&quot;) def exec(self,prep_res): exec_res = chr(ord(prep_res) + 1) return exec_res def post(self, shared, prep_res, exec_res): # 更新状态 shared[&quot;name&quot;] = exec_res if prep_res == &quot;d&quot;: return &#x27;end&#x27; # 确定方向 return None class End(Node): def prep(self, shared): return None def exec(self,prep_res): return None def post(self, shared, prep_res, exec_res): print(f&quot;Game Over&quot;) return Nonea = Node()b = Node()c = Node()d = Node()end = End()a &gt;&gt; bflow_a_b = Flow(start=a)c &gt;&gt; dflow_c_d = Flow(start=c)flow_a_b &gt;&gt; flow_c_dflow_c_d - &#x27;end&#x27; &gt;&gt; endflow = Flow(start=flow_a_b)shared = &#123; &quot;name&quot;: &quot;a&quot;,&#125;flow.run(shared)# flow_a_b.run(shared) 1.3 数据流Shared一般是内存中的字典类型，可以包含数据库连接等实现数据持久化。 1shared = &#123;&quot;data&quot;: &#123;&#125;, &quot;summary&quot;: &#123;&#125;, &quot;config&quot;: &#123;...&#125;, ...&#125; LoadData写入数据到shared[&quot;data&quot;] Summarize 从shared[&quot;data&quot;] 读取数据，总结写入 shared[&quot;summary&quot;] 12345678910111213141516171819202122232425262728293031323334353637383940414243from pocketflow import Node,Flowfrom utils.call_llm import call_llm # 处理shared数据class LoadData(Node): def post(self, shared, prep_res, exec_res): # We write data to shared store shared[&quot;data&quot;] = &quot;&quot;&quot;**春天的作文**春天，是四季中最充满希望和生机的季节。当冬日的寒冷渐渐退去，温暖的阳光洒满大地，万物开始苏醒，春天就这样悄无声息地来到了我们的身边。清晨，我走出家门，迎面扑来的是清新的空气，夹杂着泥土的芬芳和花草的香气。路边的小草悄悄地从土里探出头来，嫩绿的叶子在微风中轻轻摇曳，仿佛在向人们招手。树木也披上了新装，枝头上绽开了朵朵花苞，有的已经盛开，粉红的桃花、雪白的梨花、金黄的迎春花，把整个世界装扮得五彩缤纷。公园里，孩子们在草地上奔跑、嬉戏，欢笑声回荡在空气中。老人们坐在长椅上，享受着温暖的阳光，脸上洋溢着幸福的笑容。鸟儿们也从南方飞回来了，在树枝间跳跃，唱着动听的歌谣，仿佛在庆祝春天的到来。春天不仅带来了美丽的景色，还给人们带来了无限的希望和动力。农民伯伯开始忙碌起来，播种希望；学生们也重新投入到学习中，迎接新的挑战。春天就像一位温柔的画家，用她的画笔描绘出一幅幅生动的画面，让人心情愉悦，充满活力。我爱春天，爱她的美丽，爱她的生机，更爱她带给人们的希望与梦想。让我们珍惜这美好的季节，努力拼搏，迎接更加灿烂的明天！&quot;&quot;&quot; return None# 执行class Summarize(Node): def prep(self, shared): # We read data from shared store return shared[&quot;data&quot;] def exec(self, prep_res): # Call LLM to summarize prompt = f&quot;Summarize: &#123;prep_res&#125;&quot; summary = call_llm(prompt) return summary def post(self, shared, prep_res, exec_res): # We write summary to shared store shared[&quot;summary&quot;] = exec_res return &quot;default&quot;load_data = LoadData()summarize = Summarize()load_data &gt;&gt; summarizeflow = Flow(start=load_data)shared = &#123;&#125;flow.run(shared)print(shared[&quot;summary&quot;]) Params所有的 Node 和 Flow 都可以设置专属参数。 Node运行周期内不可变动 node.set_params() flow.set_params() 父Flow参数会覆盖子节点参数 123456789101112131415161718192021222324252627282930# 1) Create a Node that uses paramsclass SummarizeFile(Node): def prep(self, shared): # Access the node&#x27;s param filename = self.params[&quot;filename&quot;] return shared[&quot;data&quot;].get(filename, &quot;&quot;) def exec(self, prep_res): prompt = f&quot;Summarize: &#123;prep_res&#125;&quot; return call_llm(prompt) def post(self, shared, prep_res, exec_res): filename = self.params[&quot;filename&quot;] shared[&quot;summary&quot;][filename] = exec_res return &quot;default&quot;# 2) Set paramsnode = SummarizeFile()# 3) Set Node params directly (for testing)node.set_params(&#123;&quot;filename&quot;: &quot;doc1.txt&quot;&#125;)node.run(shared)# 4) Create Flowflow = Flow(start=node)# 5) Set Flow params (overwrites node params)flow.set_params(&#123;&quot;filename&quot;: &quot;doc2.txt&quot;&#125;)flow.run(shared) # The node summarizes doc2, not doc1 1.4 BatchBatchNode prep(shared): 返回一个可迭代对象，如数组，字符串。 **exec(item)**：对数组的每项进行处理 **post(shared, prep_res, exec_res_list)**：接收exec的结果数组，exec_res_list 123456789class BatchNode(BatchNode): def prep(self, shared): return [] def exec(self, chunk): pass def post(self,shared, prep_res,exec_res_list): return &quot;default&quot; 1234567891011121314151617181920212223242526272829303132333435363738from pocketflow import BatchNode,BatchFlow,Flowfrom utils.call_llm import call_llm class MapSummaries(BatchNode): def prep(self, shared): content = shared[&quot;data&quot;] chunk_size = 20 chunks = [content[i:i+chunk_size] for i in range(0, len(content), chunk_size)] return chunks def exec(self, chunk): prompt = f&quot;Summarize this chunk in 10 words: &#123;chunk&#125;&quot; summary = call_llm(prompt) return summary def post(self,shared, prep_res,exec_res_list): combined = &quot; &quot;.join(exec_res_list) shared[&quot;summary&quot;] = combined return Nonemap_summaries = MapSummaries()flow = Flow(start=map_summaries)shared = &#123; &#x27;data&#x27;: &quot;&quot;&quot;**春天的作文**春天，是四季中最充满希望和生机的季节。当冬日的寒冷渐渐退去，温暖的阳光洒满大地，万物开始苏醒，春天就这样悄无声息地来到了我们的身边。清晨，我走出家门，迎面扑来的是清新的空气，夹杂着泥土的芬芳和花草的香气。路边的小草悄悄地从土里探出头来，嫩绿的叶子在微风中轻轻摇曳，仿佛在向人们招手。树木也披上了新装，枝头上绽开了朵朵花苞，有的已经盛开，粉红的桃花、雪白的梨花、金黄的迎春花，把整个世界装扮得五彩缤纷。公园里，孩子们在草地上奔跑、嬉戏，欢笑声回荡在空气中。老人们坐在长椅上，享受着温暖的阳光，脸上洋溢着幸福的笑容。鸟儿们也从南方飞回来了，在树枝间跳跃，唱着动听的歌谣，仿佛在庆祝春天的到来。春天不仅带来了美丽的景色，还给人们带来了无限的希望和动力。农民伯伯开始忙碌起来，播种希望；学生们也重新投入到学习中，迎接新的挑战。春天就像一位温柔的画家，用她的画笔描绘出一幅幅生动的画面，让人心情愉悦，充满活力。我爱春天，爱她的美丽，爱她的生机，更爱她带给人们的希望与梦想。让我们珍惜这美好的季节，努力拼搏，迎接更加灿烂的明天！&quot;&quot;&quot;, &#x27;summary&#x27;: &quot;&quot;&#125;flow.run(shared)print(shared[&quot;summary&quot;]) BatchFlow使用params而不是shared，每个子流程通过不同的参数独立运行。 BatchFlow 将一批参数传递给子 Flow，每个参数的Flow独立运行 子Flow中通过self.params获取参数 子流程&#x2F;节点 为常规 流程&#x2F;节点，而不是Batch 将文件名作为参数传递给Flow。每个Flow处理一个文件。在shared中收集数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465from pocketflow import BatchNode,BatchFlow,Flow,Nodefrom utils.call_llm import call_llm file = &#123; &quot;file1.txt&quot;: &quot;1234567&quot;, &quot;file2.txt&quot;: &quot;8901234&quot;, &quot;file3.txt&quot;: &quot;5678901&quot;&#125;shared = &#123; &quot;data&quot;: file&#125;class SummarizeAllFiles(BatchFlow): def prep(self, shared): # IMPORTANT: Return a list of param dictionaries (not data for processing) filenames = list(shared[&quot;data&quot;].keys()) # e.g., [&quot;file1.txt&quot;, &quot;file2.txt&quot;, ...] return [&#123;&quot;filename&quot;: fn&#125; for fn in filenames]# Child node that accesses filename from params, not shared storeclass LoadFile(Node): def prep(self, shared): # Access filename from params (not from shared) filename = self.params[&quot;filename&quot;] # Important! Use self.params, not shared return filename def exec(self, filename): # 模拟从文件中读取内容 return file[filename] def post(self, shared, prep_res, exec_res): # Store file content in shared shared[&quot;current_file_content&quot;] = exec_res return &quot;default&quot;# Summarize node that works on the currently loaded fileclass Summarize(Node): def prep(self, shared): return shared[&quot;current_file_content&quot;] def exec(self, content): # 模拟调用llm总结 prompt = f&quot;Summarize this file in 50 words: &#123;content&#125;&quot; return prompt def post(self, shared, prep_res, exec_res): # Store summary in shared, indexed by current filename filename = self.params[&quot;filename&quot;] # Again, using params if &quot;summaries&quot; not in shared: shared[&quot;summaries&quot;] = &#123;&#125; shared[&quot;summaries&quot;][filename] = exec_res return &quot;default&quot;# Create a per-file flowload_file = LoadFile()summarize = Summarize()load_file &gt;&gt; summarizesummarize_file = Flow(start=load_file)# Wrap in a BatchFlow to process all filessummarize_all_files = SummarizeAllFiles(start=summarize_file)summarize_all_files.run(shared)print(&quot; &quot;.join(f&quot;&#123;f&#125;: &#123;s&#125;&quot; for (f,s) in shared[&quot;summaries&quot;].items())) BatchFlow 嵌套可以将一个BatchFlow嵌套在另一个BatchFlow中。 每一层BatchFlow都有参数，在每一层，会将自身参数和父节点参数合并。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263from pocketflow import BatchNode,BatchFlow,Flow,Nodefrom utils.call_llm import call_llm directory = &#123; &quot;dir1&quot;: &#123; &quot;file1.txt&quot;: &quot;dir1 file1 content&quot;, &quot;file2.txt&quot;: &quot;dir1 file2 content&quot;, &quot;file3.txt&quot;: &quot;dir1 file3 content&quot; &#125;, &quot;dir2&quot;: &#123; &quot;file1.txt&quot;: &quot;dir2 file1 content&quot;, &quot;file2.txt&quot;: &quot;dir2 file2 content&quot;, &quot;file3.txt&quot;: &quot;dir2 file3 content&quot; &#125;&#125;shared = &#123; &quot;data&quot;: directory&#125;class FileBatchFlow(BatchFlow): def prep(self, shared): directory = self.params[&quot;directory&quot;] files = list(shared[&quot;data&quot;][directory].keys()) # files = [f for f in os.listdir(directory) if f.endswith(&quot;.txt&quot;)] return [&#123;&quot;filename&quot;: f&#125; for f in files]class DirectoryBatchFlow(BatchFlow): def prep(self, shared): directories = list(shared[&quot;data&quot;].keys()) return [&#123;&quot;directory&quot;: d&#125; for d in directories]# The actual processing nodeclass ProcessFile(Node): def prep(self, shared): # Access both directory and filename from params directory = self.params[&quot;directory&quot;] # From outer batch filename = self.params[&quot;filename&quot;] # From inner batch # full_path = os.path.join(directory, filename) full_path = shared[&quot;data&quot;][directory][filename] return full_path def exec(self, full_path): return f&quot;Processed &#123;full_path&#125;&quot; def post(self, shared, prep_res, exec_res): if &quot;results&quot; not in shared: shared[&quot;results&quot;] = &#123;&#125; shared[&quot;results&quot;][prep_res] = exec_res return &quot;default&quot;# Set up the nested batch structureprocess_node = ProcessFile()inner_flow = FileBatchFlow(start=process_node)outer_flow = DirectoryBatchFlow(start=inner_flow)# Run itouter_flow.run(shared)print(&quot; &quot;.join(f&quot;&#123;f&#125;: &#123;s&#125;&quot; for (f,s) in shared[&quot;results&quot;].items())) 1.5 异步异步节点实现prep_async()、exec_async()、exec_fallback_async()和post_async()。","tags":["AI"],"categories":["技术","AI"]},{"title":"【昇腾】MindIE - Benchmark","path":"/技术/AI/ai_AtlasBenchmark/","content":"1. MindIE 服务化1.1 环境准备镜像传送门 参数说明： device用于挂载卡，下面的例子是挂载了8张卡 倒数第二行的镜像名称记得修改 1234567891011121314151617181920212223docker run -itd --privileged --name=mindie --net=host \\ --shm-size 500g \\ --device=/dev/davinci0 \\ --device=/dev/davinci1 \\ --device=/dev/davinci2 \\ --device=/dev/davinci3 \\ --device=/dev/davinci4 \\ --device=/dev/davinci5 \\ --device=/dev/davinci6 \\ --device=/dev/davinci7 \\ --device=/dev/davinci_manager \\ --device=/dev/hisi_hdc \\ --device /dev/devmm_svm \\ -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\ -v /usr/local/Ascend/firmware:/usr/local/Ascend/firmware \\ -v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \\ -v /usr/local/sbin:/usr/local/sbin \\ -v /etc/hccn.conf:/etc/hccn.conf \\ swr.cn-south-1.myhuaweicloud.com/ascendhub/mindie:1.0.0-800I-A2-py311-openeuler24.03-lts \\ bash# 进入容器 docker exec -it mindie bash 1.2 MindIE基础配置123456789cd /usr/local/Ascend/mindie/latest/mindie-service/vim conf/config.json# 几个参数需要修改：httpsEnabled: falsemodelName: 类似vllm的modelName，用于标识模型，可以随意配置modelWeightPath: 本地模型路径npuDeviceIds: 使用的NPU卡，默认[[0,1,2,3]]，暂时可不修改worldSize: 使用的卡数，和npuDeviceIds对应，默认4 123# 启动MindIEcd /usr/local/Ascend/mindie/latest/mindie-service./bin/mindieservice_daemon 测试服务化 123456789101112curl -H &quot;Accept: application/json&quot; -H &quot;Content-type: application/json&quot; -X POST -d &#x27;&#123; &quot;prompt&quot;: &quot;你是谁&quot;, &quot;max_tokens&quot;: 200, &quot;repetition_penalty&quot;: 1.03, &quot;presence_penalty&quot;: 1.2, &quot;frequency_penalty&quot;: 1.2, &quot;temperature&quot;: 0.5, &quot;top_k&quot;: 10, &quot;top_p&quot;: 0.95, &quot;stream&quot;: false, &quot;ignore_eos&quot;: false&#125;&#x27; http://127.0.0.1:1025/generate ‍ 2. Benchmark2.1 配置1234# 配置文件权限问题chmod 640 /usr/local/lib/python3.11/site-packages/mindieclient/python/config/config.json# 日志打屏export MINDIE_LOG_TO_STDOUT=&quot;benchmark:1; client:1&quot; 2.2 数据集2.1 合成数据（性能测试） 可以指定输入输出的token数量 生成的数据为A[空格]，如输入token数为5: “A A A A A” 输出token数不会因为结束符而停止。可以根据真实场景的输出更好的测试性能。 在任意位置创建：vim synthetic_config.json​ 样例 1234567891011&#123; &quot;Input&quot;:&#123; &quot;Method&quot;: &quot;uniform&quot;, &quot;Params&quot;: &#123;&quot;MinValue&quot;: 1, &quot;MaxValue&quot;: 200&#125; &#125;, &quot;Output&quot;: &#123; &quot;Method&quot;: &quot;gaussian&quot;, &quot;Params&quot;: &#123;&quot;Mean&quot;: 100, &quot;Var&quot;: 200, &quot;MinValue&quot;: 1, &quot;MaxValue&quot;: 100&#125; &#125;, &quot;RequestCount&quot;: 100 &#125; 参数 含义 取值范围 Input 输入配置 - Output 输出配置 - RequestCount 请求次数，即样本数量 [1,1048576] Method 采样方法 取 “uniform”、”gaussian”或”zipf”。 Params 采样方法中对应的采样参数 取值详情请参见表2。 “Input” 中的 “MinValue” token 数量最小值 [1,1048576] “Input” 中的 “MaxValue” token 数量最大值 [1,1048576] “Output” 中的 “MinValue” token 数量最小值 [1,1048576] “Output” 中的 “MaxValue” token 数量最大值 [1,1048576]​ “gaussian” 中的 “Mean” 高斯分布均值 [-3.0 x 10^38, 3.0 x 10^38] “gaussian” 中的 “Var” 高斯分布方差 [0, 3.0 x 10^38] “zipf” 中的 “Alpha” zipf分布Alpha系数 (1.0,10.0] 注：1048576 = 2^20 = 1 M。 Benchmark命令： 合成数据配置路径使用​SyntheticConfigPath​​指定 123456789101112benchmark \\--DatasetType &quot;synthetic&quot; \\--ModelName llama_7b \\--ModelPath &quot;/&#123;模型权重路径&#125;/llama_7b&quot; \\--TestType vllm_client \\--Http https://&#123;ipAddress&#125;:&#123;port&#125; \\--ManagementHttp https://&#123;managementIpAddress&#125;:&#123;managementPort&#125; \\--Concurrency 128 \\--MaxOutputLen 20 \\--TaskKind stream \\--Tokenizer True \\--SyntheticConfigPath /&#123;配置文件路径&#125;/synthetic_config.json 测试环境：910B、四卡、DeepSeek-R1-Qwen-32B 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# 配置：&#123; &quot;Input&quot;:&#123; &quot;Method&quot;: &quot;uniform&quot;, &quot;Params&quot;: &#123;&quot;MinValue&quot;: 500, &quot;MaxValue&quot;: 1000&#125; &#125;, &quot;Output&quot;: &#123; &quot;Method&quot;: &quot;gaussian&quot;, &quot;Params&quot;: &#123;&quot;Mean&quot;: 100, &quot;Var&quot;: 200, &quot;MinValue&quot;: 1, &quot;MaxValue&quot;: 100&#125; &#125;, &quot;RequestCount&quot;: 2000&#125;# 输出+---------------------+----------------+-----------------+----------------+---------------+----------------+----------------+-----------------+------+| Metric | average | max | min | P75 | P90 | SLO_P90 | P99 | N |+---------------------+----------------+-----------------+----------------+---------------+----------------+----------------+-----------------+------+| FirstTokenTime | 762.4963 ms | 9074.5516 ms | 118.6991 ms | 567.9139 ms | 1415.2258 ms | 1415.2258 ms | 8181.3668 ms | 2000 || DecodeTime | 170.4084 ms | 8435.523 ms | 0.0157 ms | 246.6154 ms | 444.639 ms | 185.2339 ms | 767.7023 ms | 2000 || LastDecodeTime | 262.8068 ms | 928.5161 ms | 20.0195 ms | 423.1779 ms | 617.8357 ms | 617.8357 ms | 911.0484 ms | 2000 || MaxDecodeTime | 1279.4515 ms | 8435.523 ms | 75.1517 ms | 907.9784 ms | 2699.2586 ms | 2699.2586 ms | 7724.6093 ms | 2000 || GenerateTime | 16700.8135 ms | 20314.2266 ms | 4299.7291 ms | 18216.5194 ms | 18719.7726 ms | 18719.7726 ms | 20156.1953 ms | 2000 || InputTokens | 753.29 | 999 | 500 | 877.0 | 951.0 | 951.0 | 995.01 | 2000 || GeneratedTokens | 94.5235 | 100 | 55 | 100.0 | 100.0 | 100.0 | 100.0 | 2000 || GeneratedTokenSpeed | 5.8279 token/s | 21.2943 token/s | 4.2824 token/s | 5.677 token/s | 6.0752 token/s | 6.0752 token/s | 14.8526 token/s | 2000 || GeneratedCharacters | 189.047 | 200 | 110 | 200.0 | 200.0 | 200.0 | 200.0 | 2000 || Tokenizer | 4.7329 ms | 33.6573 ms | 1.3688 ms | 5.6392 ms | 6.5679 ms | 6.5679 ms | 8.5305 ms | 2000 || Detokenizer | 1.0233 ms | 1.2207 ms | 0.6008 ms | 1.081 ms | 1.086 ms | 1.086 ms | 1.0986 ms | 2000 || CharactersPerToken | 2.0 | / | / | / | / | / | / | 2000 || PostProcessingTime | 0 ms | 0 ms | 0 ms | 0 ms | 0 ms | 0 ms | 0 ms | 2000 || ForwardTime | 0 ms | 0 ms | 0 ms | 0 ms | 0 ms | 0 ms | 0 ms | 2000 |+---------------------+----------------+-----------------+----------------+---------------+----------------+----------------+-----------------+------+[2025-04-29 19:12:10.619+08:00] [13134] [281473497909536] [benchmark] [INFO] [output.py:121] The BenchMark test common metric result is:+------------------------+---------------------+| Common Metric | Value |+------------------------+---------------------+| CurrentTime | 2025-04-29 19:12:10 || TimeElapsed | 263.6115 s || DataSource | None || Failed | 0( 0.0% ) || Returned | 2000( 100.0% ) || Total | 2000[ 100.0% ] || Concurrency | 128 || ModelName | llm || lpct | 1.0122 ms || Throughput | 7.5869 req/s || GenerateSpeed | 717.1425 token/s || GenerateSpeedPerClient | 5.6027 token/s || accuracy | / |+------------------------+---------------------+ ‍","tags":["AI","昇腾"],"categories":["技术","AI"]},{"title":"2025-04","path":"/Essays/20250428四月/","content":"稳定与动荡的四月。这个月不算忙，只是工作上在稳定与动荡之间切换着。chongwen二〇二五年四月 生活四月中旬，工作稳定、心态稳定，有心情运动了。有几次走着上下班、跟着《成人肥胖食养指南》做饭，体重下降了一点点。不过月末新Offer的事情，扰乱了我的计划，体重又上去了～ 四月份有清明假期，和小齐一起去了浙江台州。逛古城、吃海鲜、爬山…我们早就计划出去玩了，但三月份事情太多，周末一直没有时间，四月初时所有事情尘埃落定，有时间有心情去玩～ 古城。现在很多地方的古城越发像网红街，各种网红“美食”，但台州的网红美食有些还不错，主要还是本地特色为主。吃了扁食（大号蒸素馄饨）和麦虾（一个带虾的面汤）。似乎台州有名的是糯唧唧，我们不太喜欢，没有吃。古城有家网红旗袍店，挺多人的，给小齐买了一件，很好看。 海鲜。晚上去吃了海鲜。味道不错，但也挺贵。 爬山。登顶后有种登高望远、心情开阔的感觉。走了玻璃栈桥，，我恐高。全程大概用了三四个小时，下山之后，我俩的腿累的发抖。 工作离职&amp;留下三月底坚定的向领导谈离职，和领导长谈后，被说服留下。实际上也考虑到那家公司的技术团队、办公环境、工作地点等不如现在，加上领导的说服，认为还是在这里多待一段时间，同时也期望领导能帮忙换一家外包公司，软通待遇实在太差了。但在放弃offer之后，有时会想，要是去了会怎么样？毕竟薪资提高了不少。不过总体来说，四月份中的挺长一段时间，还是很稳定的，专心投入到了工作上。 突然的Offer第三周的周五，收到一家面试邀请。其实自从放弃上一个offer之后，就没有再主动去投简历，只是时不时回一下Boos上的简历邀请。搜了下这家公司的背景还行，也就打算试试，没有想认真对待。面试大概一个小时，对面有两位，分别是技术官和技术主管。面试过程还算顺利，关于项目的问题聊的还不错，期间有几个八股问答的一般。最后还给面试官介绍了最近做的RAG评测系统的开源项目，面试官似乎感觉挺好的。 周一收到了HR的结果，通过了。薪资给的也不错，比上一个offer还要高，给预留的时间也挺长。周一下班我就去了他们公司参观。有趣的是在楼下遇到了其中一位面试官，他很热情，带我上楼一起转。HR也挺热情的，他们两位带我去参观，遇到了一些领导也帮我做了介绍。 这家比上家的办公环境好一些，但和我现在的工作环境还差一些。现在的办公环境确实好，周围都是大落地窗，视野很棒，办公桌面积也超大，重要的是办公区后面可以放折叠床，可以休息，，，，emm，这是我不想去上家offer公司的原因之一。 Offer&amp;意外比较满意这个offer了，准备第二天就和领导说这个事情。但有个事情扰乱了我的计划。技术主管加wx想让我做一个课题。心里实际是抗拒的，毕竟入职之前就给派工作，感觉不太好，后面转念一想，可能是他们不放心我的技术？想测试一下？好吧，和主管沟通确定了课题的背景和需求，我可以cover住，开始熬夜准备了。大概准备了两三天，有一天熬夜到2点，项目的框架算是做出来了，覆盖了常见的情况。给未来领导做了反馈。因为这个情况，担心这份offer会有不确定性，所以那周就没有和领导提离职。过了一周和HR沟通，HR向我承诺100%是没有问题的，，，emm，又要考虑如何给领导提离职了。","tags":["我"],"categories":["随笔"]},{"title":"【昇腾】PaddleOCR转om推理","path":"/技术/AI/ai_PaddleToOM/","content":"概要：PyTorch官方提供了昇腾插件包，安装后虽然可以支持PytorchOCR和PaddlePaddle的推理任务，但性能通常低于GPU。为了充分发挥昇腾硬件的潜力，可以采用离线推理方案：​​模型转换​​：将Paddle模型转换为昇腾专用的OM格式；​高效推理​​：通过昇腾 ACL 框架运行，显著提升性能。这种方案通过硬件深度优化，能大幅提升推理速度。 1. 使用Paddle框架推理1.1 安装123456# 先安装飞桨 CPU 安装包python -m pip install paddlepaddle==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/# 再安装飞桨 NPU 插件包python -m pip install paddle-custom-npu==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/npu/ 如果失败，使用源码编译安装（确实会有安装失败的情况） 123456789101112131415# 下载 PaddleCustomDevice 源码git clone https://github.com/PaddlePaddle/PaddleCustomDevice -b release/3.0.0# 进入硬件后端(昇腾 NPU)目录cd PaddleCustomDevice/backends/npu# 先安装飞桨 CPU 安装包python -m pip install paddlepaddle==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/# 执行编译脚本 - submodule 在编译时会按需下载bash tools/compile.sh# 飞桨 NPU 插件包在 build/dist 路径下，使用 pip 安装即可python -m pip install build/dist/paddle_custom_npu*.whl 健康检查： 1234# 检查当前安装版本python -c &quot;import paddle_custom_device; paddle_custom_device.npu.version()&quot;# 飞桨基础健康检查python -c &quot;import paddle; paddle.utils.run_check()&quot; 1.2 推理设置环境变量： 推理时有算子触发jit编译，会导致推理很慢。所以需要设置环境变量来禁止。 12export FLAGS_npu_jit_compile=0export FLAGS_use_stride_kernel=0 推理代码：添加参数：use_npu=True 123456from paddleocr import PaddleOCRPaddleOCR( show_log=True, use_npu=True, # 其他参数 ) 2. paddle 转 ONNX参考文档下载模型 12345wget -nc -P ./inference https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_det_infer.tarcd ./inference &amp;&amp; tar xf ch_PP-OCRv4_det_infer.tar &amp;&amp; cd ..wget -nc -P ./inference https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_rec_infer.tarcd ./inference &amp;&amp; tar xf ch_PP-OCRv4_rec_infer.tar &amp;&amp; cd .. 转ONNX 12345678910111213paddle2onnx --model_dir ./inference/ch_PP-OCRv4_det_infer \\--model_filename inference.pdmodel \\--params_filename inference.pdiparams \\--save_file ./inference/det_onnx/model.onnx \\--opset_version 11 \\--enable_onnx_checker Truepaddle2onnx --model_dir ./inference/ch_PP-OCRv4_rec_infer \\--model_filename inference.pdmodel \\--params_filename inference.pdiparams \\--save_file ./inference/rec_onnx/model.onnx \\--opset_version 11 \\--enable_onnx_checker True 3. 转om请保证昇腾环境已安装，文档 我的场景下只需要这两个模型：rec、det。即文本识别、文本检测。 对于shape需要观察paddle模型的结构，根据输入shape和我们的业务需求来做配置，在线查看模型结构网站：https://netron.app rec其原有模型结构为：(x:-1,3,48,-1) 。batch 和 宽度是动态的，那么正常来说ATC转换时也根据这个来配置就好了，但我测试了多次，如果按照(x:-1,3,48,-1) 会报错，或者转换不保存推理时报错。档位直接-1也会报错。所以我选择了(x:-1,3,48,320)，并设置了动态batch分档。当然如果没有动态shape的需求，会更简单，固定即可，大概率是ok的。 det 其原有模型结构为：(x:-1,3,-1,-1) 。可以正常去做动态shape。 1234567891011121314atc --model=./inference/rec_onnx/model.onnx \\--framework=5 \\--output=./d_n_recfix \\--input_format=NCHW \\--input_shape=&quot;x:-1,3,48,320&quot; \\--dynamic_batch_size=&quot;1,2,3,4,5,6&quot; \\--soc_version=Ascend910B3atc --model=./inference/det_onnx/model.onnx \\--framework=5 \\--output=./d_n_decfix \\--input_format=NCHW \\--input_shape=&quot;x:-1,3,-1,-1&quot; \\--soc_version=Ascend910B3 4. Ais_bench 命令推理Ais_bench 是昇腾测试 om 模型性能的工具。功能可以这样理解：快速验证om模型是否正常、快速编写推理代码。 最开始说我们要使用ACL来做推理，直接编写ACL是很麻烦的，设计到数据内存设计、内存申请、释放、数据搬入搬出等等操作，Ais_bench是更上层的测试工具，我们可以暂时使用Ais_bench来做推理测试和代码编写。Ais_bench即有命令行工具也提供python包。 ais_bench推理工具使用指南。请先根据文档下载whl包。 1python3 -m ais_bench --model d_n_recfix.om --dymBatch 6 如果有本地的bin文件，可以添加参数：--input=/rec/binbin文件：可以将数据预处理后的tensor保存为bin文件，再用ais_bench推理bin文件可以输出一个bin，再用输出的bin接入后处理，可以快速验证推理的正确性 5. Ais_bench 编写推理代码Ais_bench接口文档 代码中 muti_infer_det、infer_rec、infer_det 函数需要实例AisBenchInfer后使用。 下面两部分主要是用于测试om模型是否正常和他们的精度，可以删除： infer_with_file、infer_with_file_det 为推理单张图片bin文件&#x2F;bin文件夹 使用。因为bin只是tensor数据，没有shape，所以需要重塑shape为正常形状infer_folder_det、infer_folder_rec 推理整个文件夹，每个bin都有一个相应的记录shape的txt，每次都读取bin和shape的txt文件，用于重塑shape为正常形状样例文件： 其他说明：rec推理没有问题，只是只能batch为动态，宽度固定。det推理单张图片没有问题，推理多张图片会出现错误，大概率和Ais_bench中的session创建有关系。有一个不是好方案的方案，使用MultiDeviceSession，多线程调用，每次调用时创建一个session，即推理多张图片每次都需要初始化，所以会很慢。毕竟Ais_bench是ACL的上层封装，或许在某些场景确实有问题，有可能使用ACL编写代码会避免，但ACL有一定的学习成本，大家如果有测试的可以发出来一起讨论。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331import osimport timeimport numpy as npfrom ais_bench.infer.interface import InferSession,MultiDeviceSessionfrom ais_bench.infer.common.utils import logger_printmodel_path_rec = &quot;/home/aicc/mineru/model/d_n_recfix.om&quot;model_path_det = &quot;/home/aicc/mineru/model/d_n_decfix_linux_aarch64.om&quot;class AisBenchInfer: _instance = None # 单例模式的类变量 def __new__(cls, device_id=1): # 单例模式实现：如果实例不存在则创建，否则返回已有实例 if cls._instance is None: cls._instance = super(AisBenchInfer, cls).__new__(cls) cls._instance._initialized = False # 标记是否已经初始化 return cls._instance def __init__(self, device_id=1): &quot;&quot;&quot; 初始化推理模型 Args: device_id: 设备ID model_path: 模型路径 &quot;&quot;&quot; # 只在第一次初始化时执行 if not self._initialized: self.device_id = device_id self.model_path_rec = model_path_rec self.session_rec = InferSession(device_id, self.model_path_rec) self.model_path_det = model_path_det # self.session_det = InferSession(device_id, self.model_path_det) self.multi_session_det = MultiDeviceSession(self.model_path_det) # self.session_det.set_staticbatch() print(&quot;初始化完成:&quot;) self._initialized = True # 标记为已初始化 def muti_infer_det(self, norm_img_batch: np.ndarray): &quot;&quot;&quot; 执行推理 Args: norm_img_batch: 输入的图像批次数据 Returns: 推理输出结果 &quot;&quot;&quot; outputs = self.multi_session_det.infer(&#123;self.device_id: [[norm_img_batch]]&#125;, mode=&#x27;dymshape&#x27;, custom_sizes=1000000) print(&quot;推理成功&quot;) # print(outputs) return outputs def infer_rec(self, norm_img_batch: np.ndarray): &quot;&quot;&quot; 执行推理 Args: norm_img_batch: 输入的图像批次数据 Returns: 推理输出结果 &quot;&quot;&quot; outputs = self.session_rec.infer([norm_img_batch], mode=&#x27;dymbatch&#x27;) print(&quot;推理成功&quot;) return outputs def infer_det(self, norm_img_batch: np.ndarray): &quot;&quot;&quot; 执行推理 Args: norm_img_batch: 输入的图像批次数据 Returns: 推理输出结果 &quot;&quot;&quot; # model_path_det = &quot;/home/aicc/mineru/model/d_n_decfix_linux_aarch64.om&quot; # session_det = InferSession(self.device_id, model_path_det) outputs = self.session_det.infer([norm_img_batch], mode=&#x27;dymshape&#x27;) print(&quot;type(outputs):&quot;, type(outputs)) # 应输出 &lt;class &#x27;list&#x27;&gt; print(&quot;type(outputs[0]):&quot;, type(outputs[0])) # 应输出 &lt;class &#x27;numpy.ndarray&#x27;&gt; print(&quot;outputs[0].dtype:&quot;, outputs[0].dtype) # 应输出 float32 print(&quot;outputs[0].shape:&quot;, outputs[0].shape) # 例如 (6, 25, 6625) print(&quot;outputs:&quot;, outputs) # 例如 (6, 25, 6625) print(len(outputs)) # 例如 (6, 25, 6625) print(&quot;推理成功&quot;) # outputs = self.session_det.infer([norm_img_batch], mode=&#x27;dymshape&#x27;) # print(&quot;推理成功&quot;) # session_det.free_resource() return outputs def free_resource(self): &quot;&quot;&quot;释放模型资源&quot;&quot;&quot; if hasattr(self, &#x27;session&#x27;): self.session.free_resource() @staticmethod def infer_with_file(bin_file_path, device_id=0, model_path=&#x27;/home/aicc/mineru/model/d_model_rec_linux_aarch64.om&#x27;): &quot;&quot;&quot; 使用文件执行动态批量推理 Args: bin_file_path: 二进制输入文件路径 device_id: 设备ID model_path: 模型路径 Returns: 推理输出结果 &quot;&quot;&quot; session = InferSession(device_id, model_path) # 读取数据 ndata = np.fromfile(bin_file_path, dtype=np.float32) print(&quot;ndata shape:&quot;, ndata.shape) print(&quot;ndata元素数量:&quot;, ndata.size) print(&quot;ndata数据类型:&quot;, ndata.dtype) # 重塑数据 ndata = ndata.reshape(6, 3, 48, 320) print(&quot;重塑后的ndata shape:&quot;, ndata.shape) # 执行推理 outputs = session.infer([ndata], mode=&#x27;dymshape&#x27;) # 打印输出信息 print(type(outputs)) # 应输出 &lt;class &#x27;list&#x27;&gt; print(type(outputs[0])) # 应输出 &lt;class &#x27;numpy.ndarray&#x27;&gt; print(outputs[0].dtype) # 应输出 float32 print(outputs[0].shape) # 例如 (6, 25, 6625) # 释放资源 session.free_resource() return outputs @staticmethod def infer_with_file_det(bin_file_path, device_id=0, model_path=&#x27;/home/aicc/mineru/model/d_n_decfix_linux_aarch64.om&#x27;): &quot;&quot;&quot; 使用文件执行动态批量推理 Args: bin_file_path: 二进制输入文件路径 device_id: 设备ID model_path: 模型路径 Returns: 推理输出结果 &quot;&quot;&quot; session = InferSession(device_id, model_path) # 读取数据 ndata = np.fromfile(bin_file_path, dtype=np.float32) print(&quot;ndata shape:&quot;, ndata.shape) print(&quot;ndata元素数量:&quot;, ndata.size) print(&quot;ndata数据类型:&quot;, ndata.dtype) # 重塑数据 ndata = ndata.reshape(1, 3, 800, 704) print(&quot;重塑后的ndata shape:&quot;, ndata.shape) # 执行推理 outputs = session.infer([ndata], mode=&#x27;dymshape&#x27;) # 打印输出信息 print(type(outputs)) # 应输出 &lt;class &#x27;list&#x27;&gt; print(type(outputs[0])) # 应输出 &lt;class &#x27;numpy.ndarray&#x27;&gt; print(outputs[0].dtype) # 应输出 float32 print(outputs[0].shape) # 例如 (6, 25, 6625) # 释放资源 session.free_resource() return outputs @staticmethod def infer_folder_det(folder_path, device_id=0, model_path=&#x27;/home/aicc/mineru/model/d_n_decfix_linux_aarch64.om&#x27;): &quot;&quot;&quot; 处理文件夹中的所有bin文件进行检测推理 Args: folder_path: 包含bin文件和shape.txt文件的文件夹路径 device_id: 设备ID model_path: 模型路径 Returns: 所有bin文件的推理结果字典，键为bin文件名，值为推理输出 &quot;&quot;&quot; session = MultiDeviceSession( model_path) # session.set_staticbatch() results = &#123;&#125; # 获取文件夹中所有bin文件 bin_files = [f for f in os.listdir(folder_path) if f.endswith(&#x27;.bin&#x27;) and not f.endswith(&#x27;.shape.txt&#x27;)] for bin_file in bin_files: bin_file_path = os.path.join(folder_path, bin_file) shape_file_path = bin_file_path + &#x27;.shape.txt&#x27; # 检查shape文件是否存在 if not os.path.exists(shape_file_path): print(f&quot;跳过 &#123;bin_file&#125;: 找不到shape文件&quot;) continue # 读取shape数据 with open(shape_file_path, &#x27;r&#x27;) as f: shape_str = f.read().strip() # 解析shape数据 shape = tuple(map(int, shape_str.split(&#x27;,&#x27;))) # 读取bin数据 ndata = np.fromfile(bin_file_path, dtype=np.float32) print(f&quot;处理 &#123;bin_file&#125;&quot;) print(f&quot;原始数据shape: &#123;ndata.shape&#125;&quot;) print(f&quot;从shape文件读取的形状: &#123;shape&#125;&quot;) # 重塑数据 try: ndata = ndata.reshape(shape) print(f&quot;重塑后的数据shape: &#123;ndata.shape&#125;&quot;) # 执行推理 outputs = session.infer(&#123;device_id: [[ndata]]&#125;, mode=&#x27;dymshape&#x27;, custom_sizes=10000000) print(f&quot;&#123;bin_file&#125; 推理成功&quot;) # 记录结果 results[bin_file] = outputs except Exception as e: print(f&quot;处理 &#123;bin_file&#125; 时出错: &#123;e&#125;&quot;) # 释放资源 # session.free_resource() return results @staticmethod def infer_folder_rec(folder_path, device_id=0, model_path=&#x27;/home/aicc/mineru/model/d1001_n_recfix_linux_aarch64.om&#x27;): &quot;&quot;&quot; 处理文件夹中的所有bin文件进行识别推理 Args: folder_path: 包含bin文件和shape.txt文件的文件夹路径 device_id: 设备ID model_path: 模型路径 Returns: 所有bin文件的推理结果字典，键为bin文件名，值为推理输出 &quot;&quot;&quot; session = InferSession(device_id, model_path) results = &#123;&#125; # 获取文件夹中所有bin文件 bin_files = [f for f in os.listdir(folder_path) if f.endswith(&#x27;.bin&#x27;) and not f.endswith(&#x27;.shape.txt&#x27;)] for bin_file in bin_files: bin_file_path = os.path.join(folder_path, bin_file) shape_file_path = bin_file_path + &#x27;.shape.txt&#x27; # 检查shape文件是否存在 if not os.path.exists(shape_file_path): print(f&quot;跳过 &#123;bin_file&#125;: 找不到shape文件&quot;) continue # 读取shape数据 with open(shape_file_path, &#x27;r&#x27;) as f: shape_str = f.read().strip() # 解析shape数据 shape = tuple(map(int, shape_str.split(&#x27;,&#x27;))) # 读取bin数据 ndata = np.fromfile(bin_file_path, dtype=np.float32) print(f&quot;处理 &#123;bin_file&#125;&quot;) print(f&quot;原始数据shape: &#123;ndata.shape&#125;&quot;) print(f&quot;从shape文件读取的形状: &#123;shape&#125;&quot;) # 重塑数据 try: ndata = ndata.reshape(shape) print(f&quot;重塑后的数据shape: &#123;ndata.shape&#125;&quot;) # 执行推理 outputs = session.infer([ndata], mode=&#x27;dymbatch&#x27;) print(f&quot;&#123;bin_file&#125; 推理成功&quot;) # 记录结果 results[bin_file] = outputs except Exception as e: print(f&quot;处理 &#123;bin_file&#125; 时出错: &#123;e&#125;&quot;) # 释放资源 session.free_resource() return results# 使用示例:# import acl# infer_model = AisBenchInfer()# result = infer_model.infer_det(np.zeros((1, 3, 608, 704), dtype=np.float32))# result = infer_model.infer_det(np.zeros((1, 3, 608, 704), dtype=np.float32))# 使用 muti 推理多个 ，muti每次都会创建InferSession。 使用推理接口时才会在指定的几个devices的每个进程中新建一个InferSession。# result = infer_model.muti_infer_det(np.zeros((1, 3, 800, 704), dtype=np.float32))# result = infer_model.muti_infer_det(np.zeros((1, 3, 608, 704), dtype=np.float32))# infer_model.free_resource()# 或者直接使用静态方法:# result = AisBenchInfer.infer_with_file(&#x27;/home/aicc/mineru/MinerU_1.3.0/demo/preprocessed_data/rec/rec_input_batch_0_20250421_091529_142.bin&#x27;)# result = AisBenchInfer.infer_with_file_det(&#x27;/home/aicc/mineru/MinerU_1.3.0/demo/preprocessed_data/det/det_input_20250421_034746_105.bin&#x27;)# results = AisBenchInfer.infer_folder_det(&#x27;/home/aicc/mineru/MinerU_1.3.0/demo/preprocessed_data/det&#x27;)# results = AisBenchInfer.infer_folder_rec(&#x27;/home/aicc/mineru/MinerU_1.3.0/demo/preprocessed_data/rec&#x27;)# print(&quot;检测推理结果:&quot;, results)","tags":["AI","昇腾","OCR"],"categories":["技术","AI"]},{"title":"【昇腾】LLaMA-Factory 训练 Qwen","path":"/技术/AI/ai-LlamaFactory/","content":"@[toc] 服务器：800TA2芯片：910B3模型：Qwen2.5-14B-Instruct数据集：魔搭自定义数据集，alpaca格式 1. 使用docker安装1.1 配置docker配置docker镜像源： 1sudo vi /etc/docker/daemon.json 填入： 1234567&#123; &quot;registry-mirrors&quot;: [ &quot;https://2t697950.mirror.aliyuncs.com&quot;, &quot;https://docker.1ms.run&quot;, &quot;https://docker.xuanyuan.me&quot; ]&#125; 安装 docker-compose 123sudo curl -L https://github.com/docker/compose/releases/download/v2.33.0/docker-compose-linux-aarch64 -o /usr/local/bin/docker-composechmod 777 /usr/local/bin/docker-composedocker-compose -v 1. 2 拉取 LLaMA-Factory12345# 以下环境都基于路径 /home/aicc1mkdir /home/aicc1cd /home/aicc1git clone https://github.com/hiyouga/LLaMA-Factory.gitcd LLaMA-Factory/docker/docker-npu 1.3 修改配置请保证docker镜像源已配置完毕。修改Dockerfile 、 docker-compose.yml，中挂载的设备数量、python镜像源。默认只挂载了一个卡，下面的配置通过添加devices挂载了8张卡。 挂载了目录 /home/aicc1，用于与宿主机数据交互。具体请修改为你自己的文件路径 docker-compose.yml： 12345678910111213141516171819202122232425262728293031323334353637383940414243services: llamafactory: build: dockerfile: ./docker/docker-npu/Dockerfile context: ../.. args: INSTALL_DEEPSPEED: &quot;false&quot; PIP_INDEX: https://pypi.tuna.tsinghua.edu.cn/simple container_name: llamafactory volumes: - ../../hf_cache:/root/.cache/huggingface - ../../ms_cache:/root/.cache/modelscope - ../../om_cache:/root/.cache/openmind - ../../data:/app/data - ../../output:/app/output - /usr/local/dcmi:/usr/local/dcmi - /usr/local/bin/npu-smi:/usr/local/bin/npu-smi - /usr/local/Ascend/driver:/usr/local/Ascend/driver - /etc/ascend_install.info:/etc/ascend_install.info - /home/aicc1:/home/aicc1 - /home/aicc2:/home/aicc2 ports: - &quot;7860:7860&quot; - &quot;8000:8000&quot; ipc: host tty: true shm_size: &quot;16gb&quot; stdin_open: true command: bash devices: - /dev/davinci0 - /dev/davinci1 - /dev/davinci2 - /dev/davinci3 - /dev/davinci4 - /dev/davinci5 - /dev/davinci6 - /dev/davinci7 - /dev/davinci_manager - /dev/devmm_svm - /dev/hisi_hdc restart: unless-stopped Dockerfile : 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475# Use the Ubuntu 22.04 image with CANN 8.0.rc1# More versions can be found at https://hub.docker.com/r/ascendai/cann/tags# FROM ascendai/cann:8.0.rc1-910-ubuntu22.04-py3.8FROM ascendai/cann:8.0.0-910b-ubuntu22.04-py3.10# FROM ascendai/cann:8.0.rc1-910-openeuler22.03-py3.8# FROM ascendai/cann:8.0.rc1-910b-openeuler22.03-py3.8# Define environmentsENV DEBIAN_FRONTEND=noninteractive# Define installation argumentsARG INSTALL_DEEPSPEED=falseARG PIP_INDEX=https://pypi.tuna.tsinghua.edu.cn/simpleARG TORCH_INDEX=https://mirrors.aliyun.com/pytorch-wheels/cpuARG HTTP_PROXY=# Set the working directoryWORKDIR /app# Set http proxyRUN if [ -n &quot;$HTTP_PROXY&quot; ]; then \\ echo &quot;Configuring proxy...&quot;; \\ export http_proxy=$HTTP_PROXY; \\ export https_proxy=$HTTP_PROXY; \\ fi# Install the requirementsCOPY requirements.txt /app# RUN python -m pip install --upgrade pip &amp;&amp; \\# pip config set global.index-url &quot;$PIP_INDEX&quot; &amp;&amp; \\# pip config set global.extra-index-url &quot;$TORCH_INDEX&quot; &amp;&amp; \\# if [ -n &quot;$HTTP_PROXY&quot; ]; then \\# python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --proxy=$HTTP_PROXY -r requirements.txt; \\# else \\# python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt; \\# fiRUN python -m pip install --upgrade pip &amp;&amp; \\ pip config set global.index-url &quot;$PIP_INDEX&quot; &amp;&amp; \\ pip config set global.extra-index-url &quot;$TORCH_INDEX&quot; &amp;&amp; \\ pip install --retries=3 --timeout=60 \\ -r requirements.txt \\ -i &quot;$PIP_INDEX&quot; \\ --extra-index-url &quot;$TORCH_INDEX&quot;# Copy the rest of the application into the imageCOPY . /app# Install the LLaMA FactoryRUN EXTRA_PACKAGES=&quot;torch-npu,metrics&quot;; \\ if [ &quot;$INSTALL_DEEPSPEED&quot; == &quot;true&quot; ]; then \\ EXTRA_PACKAGES=&quot;$&#123;EXTRA_PACKAGES&#125;,deepspeed&quot;; \\ fi; \\ if [ -n &quot;$HTTP_PROXY&quot; ]; then \\ pip install --proxy=$HTTP_PROXY -e &quot;.[$EXTRA_PACKAGES]&quot;; \\ else \\ pip install -e &quot;.[$EXTRA_PACKAGES]&quot;; \\ fi# Unset http proxyRUN if [ -n &quot;$HTTP_PROXY&quot; ]; then \\ unset http_proxy; \\ unset https_proxy; \\ fi# Set up volumesVOLUME [ &quot;/root/.cache/huggingface&quot;, &quot;/root/.cache/modelscope&quot;, &quot;/app/data&quot;, &quot;/app/output&quot; ]# Expose port 7860 for the LLaMA BoardENV GRADIO_SERVER_PORT 7860EXPOSE 7860# Expose port 8000 for the API serviceENV API_PORT 8000EXPOSE 8000 1.4 构建容器修改完毕配置后，在路径下：LLaMA-Factory/docker/docker-npu 1docker compose up -d 2. 下载模型ps：请修改为你要训练的模型 12345# 进入容器docker exec -it llamafactory bash# 下载模型pip install modelscopemodelscope download --model Qwen/Qwen2.5-14B-Instruct --local_dir /home/aicc1/Qwen2.5-14B-Instruct/ 3. 准备训练数据3.1 下载数据集使用魔搭上一个医疗的数据，大小：580M，格式：Alpaca。数据处理或格式要求请查看官方文档：传送门 ps：如果认为数据集太大（训练时间会加长），可以下载后删除大部分，保留几百条数据去测试 123# 在宿主机上 （容器中没有下载wget）cd /home/aicc1/LLaMA-Factory/datawget https://modelscope.cn/datasets/swift/Alpaca-CoT/resolve/master/Chinese-medical/chinesemedical.json 3.2 自定义数据集配置如果使用自定义数据集，需要配置LLaMA-Factory 1vim /home/aicc1/LLaMA-Factory/data/dataset_info.json 在其中添加： 12345678&quot;my_dataset&quot;: &#123; &quot;file_name&quot;: &quot;chinesemedical.json&quot;, &quot;columns&quot;: &#123; &quot;prompt&quot;: &quot;instruction&quot;, &quot;query&quot;: &quot;input&quot;, &quot;response&quot;: &quot;output&quot; &#125;&#125;, 4. 训练4.1 训练配置123mkdir /home/aicc1/LLaMA-Factory/qwen_configcd /home/aicc1/LLaMA-Factory/qwen_configtourch qwen2_5_lora_sft_ds.yaml qwen2_5_lora_sft_ds.yaml 配置： 该配置采用文档中qwen1.5的训练配置。传送门 12345678910111213141516171819202122232425262728293031323334353637383940414243### modelmodel_name_or_path: /home/aicc1/Qwen2.5-14B-Instruct### methodstage: sftdo_train: truefinetuning_type: loralora_target: q_proj,v_proj### ddpddp_timeout: 180000000deepspeed: examples/deepspeed/ds_z0_config.json### datasetdataset: identity,my_datasettemplate: qwencutoff_len: 1024max_samples: 1000overwrite_cache: truepreprocessing_num_workers: 16### outputoutput_dir: saves/Qwen2.5-14B/lora/sftlogging_steps: 10save_steps: 500plot_loss: trueoverwrite_output_dir: true### trainper_device_train_batch_size: 1gradient_accumulation_steps: 2learning_rate: 0.0001num_train_epochs: 10.0lr_scheduler_type: cosinewarmup_ratio: 0.1fp16: true### evalval_size: 0.1per_device_eval_batch_size: 1eval_strategy: stepseval_steps: 500 请注意一些关键参数：model_name_or_path：下载的模型路径dataset：数据集num_train_epochs：训练轮次 本篇用到的数据集为 LLaMA-Factory 自带的 identity 和 自定义的my_dataset，对 identity 数据集进行如下全局替换即可实现定制指令： 替换为 Ascend-helper 替换为 Ascend 执行下方命令替换： 1sed -i &#x27;s/&#123;&#123;name&#125;&#125;/Ascend-helper/g; s/&#123;&#123;author&#125;&#125;/Ascend/g&#x27; /home/aicc1/LLaMA-Factorydata/identity.json 4.2 启动训练1234567cd /home/aicc1/LLaMA-FactoryASCEND_RT_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 torchrun --nproc_per_node 8 \\ --nnodes 1 \\ --node_rank 0 \\ --master_addr 127.0.0.1 \\ --master_port 7007 \\ src/train.py qwen_config/qwen2_5_lora_sft_ds.yaml 训练开始：训练中间：训练结束： 输出关于训练、评估的指标信息 结果保存在saves文件夹下Loss下降的感觉还不错： 4.3 训练效果测试指定原始模型路径、训练后lora路径。 1234llamafactory-cli chat --model_name_or_path /home/aicc1/Qwen2.5-14B-Instruct \\ --adapter_name_or_path /home/aicc1/LLaMA-Factory/saves/Qwen2.5-14B/lora/sft \\ --template qwen \\ --finetuning_type lora 询问identity数据集内容，返回成功。如图所示： 5. 合并权重123456789ASCEND_RT_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 llamafactory-cli export \\ --model_name_or_path /home/aicc1/Qwen2.5-14B-Instruct \\ --adapter_name_or_path ./saves/Qwen2.5-14B/lora/sft \\ --template qwen \\ --finetuning_type lora \\ --export_dir ./saves/Qwen2.5-14B/lora/megred-model-path \\ --export_size 2 \\ --export_device auto \\ --export_legacy_format False","tags":["昇腾","模型训练"],"categories":["技术","AI"]},{"title":"Python语法","path":"/技术/Basic-Knowledge/python/","content":"自从Java转入Python，很尴尬的是一直没有全量学习Python的内容，只是快速熟悉了语法后就开始用了。选择了全面转入Python，发现还是不够的，这篇就记录下Python中会经常忘记的知识。 基础 123456789101112131415161718192021# 链接字符串a = &quot;is &quot; &quot;a &quot; &quot;string&quot;# 复制b = a * 2c = &quot;0123456789&quot;print(a)print(b)# 截取字符串print(c[1:3])# 截取并设置步长print(c[1:9:2])# 2个之后的print(c[2:])# 之前的print(c[:5])# 倒数第几个print(c[-1])# 不转译print(r&quot; &quot;)# 反转print(c[-1::-1]) 123456789is a stringis a stringis a string12135723456789012349 9876543210 数组 123456789a = &#x27;I am boy&#x27;# 拆分a = a.split(&#x27; &#x27;)print(a)# 合并a = &#x27; &#x27;.join(a)print(a)# 反转print(a[-1::-1]) 123456789a = &#x27;I am boy&#x27;# 拆分a = a.split(&#x27; &#x27;)print(a)# 合并a = &#x27; &#x27;.join(a)print(a)# 反转print(a[-1::-1])","tags":["基础知识"],"categories":["技术"]},{"title":"2025-03","path":"/Essays/20250324三月/","content":"三月的事情入职 二月底入职的流程终于办完了，令人失望的是，没有赶上二月份的社保，这样我的社保就断交俩月了。 我两个月没有接触这个岗位的工作了，最近DeepSeek很火，大家都在搞这类的项目。 入职后，领导先让我继续完成去年遗留的一个大项目。完成之后，我开始快速浏览一些DeepSeek的相关知识，补充下我这两个月的知识空缺。 入职后不忙，也有新项目，但也比较轻松。有个让人失望的事情，我的内网权限一直没有下来，更上层的领导不同意，因信息安全问题不给外包开高风险权限，导致办公电脑不能访问内网，手机APP也只能看信息不能看图片等媒体文件，导致工作中有诸多不便。 找工作 在去年，我一直认为这是我最后一个工作，我想工作几年后就回老家了。同时也期待着HR的OD承诺，结果让人失望，没有OD，也没有年终奖，也是最低社保。也因为HW原因让我们在家赋闲2个月，没有任何补偿和安慰。 综合种种原因，我开始认真投简历找工作了。 其实刚过完年我投了一段时间，最高的一个比我现在高5.5k。但那时候我只是试试面试的感觉，主要也是岗位在北京，我在上海。 这次的面试我准备的比上次要好，我分析我的两个项目和最近的一些新技术。投了20天左右的样子，只投上海并且离我比较近的岗位，虽说有不少面试机会，但真正合适的公司我感觉没有多少。也有很多是面试完就没有结果，最终收获的offer并不多，不过最后一个offer的薪资和公司我总体是满意的，虽然也有一些不足的地方。 这个offer有三轮面试，第一轮是线上，有两个面试官，聊了一个小时，主要集合工作内容和我的项目。第二轮是线下，我未来的主管领导，也聊了一个小时。第三轮是VP，电话聊了十几分钟。从这几轮面试官来看，他们对新技术还是有所关注的，也独特的思考，并且隐喻考察候选人的各方面情况。有年终，是正编、高工资。但没有没有加班费、社保低、试用期长。 离职 上周给各位领导申请了离职，HW领导因在出差要本周找我再聊。领导曾经给表示过，今年我多承担一些重要项目，以后如果推荐OD也有相应的凭证，这一类的话。 现在这个外包公司真的很让我反感，曾经提出要切换外包公司，但因为一些原因领导还是建议不动。离职原因有几个，外包公司算一个，这里的工作内容让我感觉没有兴趣是一个，和其他同事比我们的待遇低是一个，想去做应用是一个。 离职嘛，终归是对现状的不满的积累。 但我也不知道我离职的决定是让我的发展更好还是更坏。在这里未来有可能转OD，也有可能是-；同时时间遥遥无期且要忍受这个外包公司的恶心规定；在这里离住的地方近，工作有时不饱和有时间学习；在这里代表着今年仍没有年终奖，没有绩效工资，没有福利。 是这样的，反反复复就这几个问题，不想在这里，又担心新公司有坑。","tags":["我"],"categories":["随笔"]},{"title":"AI资讯/工具","path":"/技术/AI/ai-tools/","content":"AI编程1. 前端三个比较火的前端AI编程工具：V0, Lovable，bolt.new 名称 描述 链接 V0 最早的前端AI编程，但效果最差 https://v0.dev/ Lovable UI设计不催 https://lovable.dev/ bolt.new 功能理解&#x2F;UI设计最优 https://bolt.new/ MCP 序号 名称 作用 时间 1 mcpdoc langchain的MCP工具，用于cursor访问langchain文档 4&#x2F;14 2 Minimax 使用Minimax的图像生成和TTS功能 4&#x2F;11 1. langchain的MCP：mcpdoc通过解析llms.txt文件提取相关信息，解决信息过载&#x2F;不完整&#x2F;不准确的问题，帮AI助手理解复杂的框架文档。 场景是我们期望在cursor等工具中使用langchain类似的框架编写代码，但cursor的LLM对langchain并不了解，不会达到很好的效果。那么利用mcpdoc，较为精准的找到用户问题相关的langchain文档，LLM获取了正确文档后，对用户解答或者编写代码。 工具： 1234567891011工具一：list_doc_sources作用：列出所有可用的文档源这是工作流程中的第一个工具，它会返回文档源的 URLs 或本地文件路径不需要任何输入参数工具二：fetch_docs作用：获取并解析指定 URL 的文档内容需要提供 url 参数它可以:先获取 llms.txt 文件内容分析文件中列出的 URLs获取与用户问题相关的特定文档页面 langchain提供的一个llms.txt（谷歌翻译版）： 可以看到一个链接、此链接的详细说明。 应用场景的思考 这个还是很有用的，之前如果用cursor用langchain编写代码，应该是有很大问题，比如：版本旧、不知道细节特性等。 对于这种新兴框架、新兴技术、LLM没有训练过的技术知识，很有用。如：langchain这种新兴框架文档、公司内部技术框架文档 2. Minimax使用Minimax的图像生成和TTS功能，提供一段主题让大模型生成包含图片的讲解播客&#x2F;动画等。 仓库：https://github.com/PsychArch/minimax-mcp-tools 123456789101112131415# 添加Minimax Key&#123; &quot;mcpServers&quot;: &#123; &quot;minimax-mcp-tools&quot;: &#123; &quot;command&quot;: &quot;npx&quot;, &quot;args&quot;: [ &quot;minimax-mcp-tools&quot; ], &quot;env&quot;: &#123; &quot;MINIMAX_API_KEY&quot;: &quot;your-minimax-api-key&quot;, &quot;MINIMAX_GROUP_ID&quot;: &quot;your-minimax-group-id&quot; &#125; &#125; &#125;&#125; 3. Chrome MCP ServerChrome MCP Server把Chrome浏览器的功能暴露给了像Claude等AI 助手，来实现浏览器自动化、内容分析和语义搜索 可以用任意LLM，与原本使用的浏览器无缝集成 支持跨标签页上下文，内置向量数据库 支持截图、网络监控、交互操作、书签管理、浏览历史等20多种工具 本地运行 github：https://github.com/hangwin/mcp-chrome来源：https://d.aigclink.ai/Chrome-AI-AI-Chrome-MCP-Server-22d9857c0f47802eb67fd4d3f776c9ca 测试Prompt： 123456789请使用minimax生成图片和音频。请生成一个关于西红柿炒蛋的播客，内容包括完整的制作流程，适合家庭和儿童参与，强调健康饮食和烹饪乐趣【具体要求如下】：文字内容: 播客内容不少于500字，语言简洁易懂，适合家庭成员共同收听，包含西红柿炒蛋的历史、营养价值以及制作步骤，最后要有健康饮食的启示。切菜过程: 详细描述切西红柿和鸡蛋的步骤，强调安全和技巧，适合儿童学习。炒菜过程: 讲解炒菜的技巧，包括火候掌握、调味品的使用等，鼓励家庭成员一起参与。互动环节: 设计一个互动环节，鼓励听众分享他们的西红柿炒蛋故事或变种食谱，增加参与感。音频生成: 将完整播客内容生成清晰、温暖的语音版本，语速适中，适合家庭收听。HTML页面输出: 将播客文本、相关插图和音频整合为一个美观的HTML页面：页面配色温暖（如浅红、米白等），图文并茂，图像插在相关文字段落附近，页面底部附带“播放音频”按钮，支持语音播放，适配手机端阅读体验。【输出格式】: HTML页面源代码，所有使用的图像链接（如有生成），语音文件链接或播放控件的嵌入代码。 测试效果：使用生成的图片，并在下方支持声音播放。 @tianhao_wang@tianhao_wang@vklemen 智能体（1） 名称 作用 时间 Genspark LLM+工具（文本、图片、视频） 4&#x2F;8 1. Genspark 时间：4&#x2F;8 结合LLM+80多个工具集，官方视频很惊艳。 网站：https://www.genspark.ai/ 功能包含： 智能体（旅游、咨询等调用工具+LLM）：测试了旅游，效果没有那么好，而且会优先搜索国外的内容。 图片处理：看着是比较常见的图片场景：背景消除、橡皮擦、扩展、去模糊等。 视频生成：测试了一个生成炒菜的视频，最终效果很差。会先优化提示词，将其拆飞为多个视频的提示词，并描述细节，但最终只生成了一个视频，并且效果差。（有可能是账号配额问题？） 深度研究 生成视频时，会分析用户提示词并且重构提示词，添加很多细节，这一点很不错。但是最终生成的视频效果挺一般。 文档提取（1）1. SmolDocling全文档OCR的多模态视觉语言模型，具有256M参数，支持复杂文档的全面OCR：布局、代码、公式、图表识别。 模型：https://huggingface.co/ds4sd/SmolDocling-256M-preview 实测：测试了三个文件，其中两个是左右布局的文档，另一个是竖向表格文档。 第一张图片只识别了左侧文本，右侧没有识别。可能右侧有小图片的原因。 第二张文本中间有公式，识别的较好。 第三张识别不出来，他左侧是一张竖着的表格图片，可能是表格的影响。 总的来说，如果是常规的PDF、普通图表等文档，用这个是不错的。如果是复杂的就用MinerU，使用多个模型进行应用处理。","tags":["AI"],"categories":["技术","AI"]},{"title":"大模型应用开发 - LangChain","path":"/技术/AI/ai-langchain/","content":"LangGraph函数定义 官方手册 1. 定义LangGraph定义 LangGraph将Agent运转流程建模为一个图，可以想象成代码版的应用编排，定义三个要素：状态、节点、边。 状态：一个数据结构。作为节点的输入、输出。 是图中不断流转、改变的数据。可以是任何Python类型，一般用TypedDict或 Pydantic BaseModel。 节点：Python 函数。动作执行单元。接受当前状态并对其进行处理，然后返回更新后的状态。 边：Python 函数。根据当前节点确定下一个节点。可以说条件分支，也可以是固定路径。 一些函数&#x2F;特征的定义 StateGraph：状态图。LangGraph中使用的主要图类。 MessageGraph：消息图。一种特殊的图类型，MessageGraph 的 State 仅为消息列表，一般仅用于聊天机器人。 graph_builder.compile(…)：图编译。必须要编译，会对图结构做检查。 add_node：参数为节点函数。增加节点，如果没有指定节点名称，默认为函数名。 StateGraph：构建图。参数为状态的数据结构。 Annotated：状态中定义属性时，用这个来实现reducer。 2. 特性2.1 基本流程一个简单的样例，其定义的流程为： 定义状态（数据结构） 定义节点（执行动作） 定义边（执行路径） 图编译 图执行 1234567891011121314151617181920212223242526272829303132333435363738394041class InputState(TypedDict): user_input: strclass OutputState(TypedDict): graph_output: strclass OverallState(TypedDict): foo: str user_input: str graph_output: strclass PrivateState(TypedDict): bar: strdef node_1(state: InputState) -&gt; OverallState: # Write to OverallState return &#123;&quot;foo&quot;: state[&quot;user_input&quot;] + &quot; name&quot;&#125;def node_2(state: OverallState) -&gt; PrivateState: # Read from OverallState, write to PrivateState return &#123;&quot;bar&quot;: state[&quot;foo&quot;] + &quot; is&quot;&#125;def node_3(state: PrivateState) -&gt; OutputState: # Read from PrivateState, write to OutputState return &#123;&quot;graph_output&quot;: state[&quot;bar&quot;] + &quot; Lance&quot;&#125; # StateGraph参数是状态的数据结构，如果状态都是dict类型，那么可以 builder = StateGraph(dict)builder = StateGraph(OverallState,input=InputState,output=OutputState)# 如果没有制定节点名称，那么默认名称为函数名builder.add_node(&quot;node_1&quot;, node_1)builder.add_node(&quot;node_2&quot;, node_2)builder.add_node(&quot;node_3&quot;, node_3)builder.add_edge(START, &quot;node_1&quot;)builder.add_edge(&quot;node_1&quot;, &quot;node_2&quot;)builder.add_edge(&quot;node_2&quot;, &quot;node_3&quot;)builder.add_edge(&quot;node_3&quot;, END)graph = builder.compile()graph.invoke(&#123;&quot;user_input&quot;:&quot;My&quot;&#125;)输出：&#123;&#x27;graph_output&#x27;: &#x27;My name is Lance&#x27;&#125; 2.2 operator operator ： Python 标准库中的一个模块，它提供了一系列对应于 Python 内置运算符的函数。 Annotated 类型：Annotated 是 Python 3.9 引入的类型提示工具。 Reducer：在 Langgraph 中，reducer 是一个特殊的函数，用于定义当状态更新时如何处理和合并数据。Reducer 本质上是一个接收两个参数并返回一个结果的函数： 当前状态中的值 节点返回的新值 返回合并后的结果 如果您没有指定 reducer，则每次状态更新都会用最近提供的消息列表覆盖现有消息列表。如果您想简单地将消息追加到现有列表中，则可以使用 operator.add 作为 reducer。 对于这个代码，bar在更新时会将新值加入list，而不是覆盖。比如 初始值：&#123;&quot;foo&quot;: 1, &quot;bar&quot;: [&quot;hi&quot;]&#125; 节点1返回：&#123;&quot;foo&quot;: 2&#125;。输出&#123;&quot;foo&quot;: 2, &quot;bar&quot;: [&quot;hi&quot;]&#125; 节点2返回：&#123; &quot;bar&quot;: [&quot;Tom&quot;]&#125;。输出**&#123;&quot;foo&quot;: 2, &quot;bar&quot;: [&quot;hi&quot;，&#39;Tom&#39;]&#125;** 注意：节点返回时可以不完全返回状态的数据结构，可以只返回其中的一个属性。那么输出状态只会更新其新属性。 1234567from typing import Annotatedfrom typing_extensions import TypedDictfrom operator import addclass State(TypedDict): foo: int bar: Annotated[list[str], add] 2.3 消息对于消息的数据结构，预定义了reducer函数：add_messages。 状态更新时会反序列化为LangChain的Message对象。 12345# this is supported&#123;&quot;messages&quot;: [HumanMessage(content=&quot;message&quot;)]&#125;# and this is also supported&#123;&quot;messages&quot;: [&#123;&quot;type&quot;: &quot;human&quot;, &quot;content&quot;: &quot;message&quot;&#125;]&#125; 12345678910111213from langchain_core.messages import AnyMessagefrom langgraph.graph.message import add_messagesfrom typing import Annotatedfrom typing_extensions import TypedDictclass GraphState(TypedDict): messages: Annotated[list[AnyMessage], add_messages] # 也可以使用MessagesState。MessagesState 使用 add_messages reducerfrom langgraph.graph import MessagesStateclass State(MessagesState): documents: list[str] 3. 节点、边节点 START 节点：用户初始输入数据到达的节点。 END 节点：终端节点。表示此边后没有操作。 边 普通边：直接从一个节点到下一个节点。 条件边：调用一个函数来确定要转到下一个节点。 入口点：用户输入到达时要调用的第一个节点。 条件入口点：调用一个函数来确定用户输入到达时要调用的第一个节点。 并行策略：如果一个节点有多个输出边，那么这些目标节点会并行执行。 普通边 1graph.add_edge(&quot;node_a&quot;, &quot;node_b&quot;) 条件边 add_conditional_edges 路由到1条边或多条边。 1graph.add_conditional_edges(&quot;node_a&quot;, routing_function) routing_function类似节点，接受图的当前 state 并返回一个值。 默认将routing_function的返回状态作为下一组节点的输入，然后下组节点并行。 指定下一节点名称： 1graph.add_conditional_edges(&quot;node_a&quot;, routing_function, &#123;True: &quot;node_b&quot;, False: &quot;node_c&quot;&#125;) 入口点 12from langgraph.graph import STARTgraph.add_edge(START, &quot;node_a&quot;) 条件入口点 同条件边 1234from langgraph.graph import STARTgraph.add_conditional_edges(START, routing_function)#或graph.add_conditional_edges(START, routing_function, &#123;True: &quot;node_b&quot;, False: &quot;node_c&quot;&#125;) 4. Send并行多次调用同一个节点，并使用不同的状态，然后将结果聚合回主图的状态。 属性： node要发送消息的目标节点的名称。 arg要发送到目标节点的状态或消息。 Send是发送到节点的一种策略，可以动态指定发生到某个节点（通过参数node）。那么继而可以实现多次发送到同一个节点，实现同节点的并行处理一批数据。 此样例： 定义状态OverallState 定义节点generate_joke 定义条件边continue_to_jokes 定义将一批数据都发送到一个节点，实现并行。 12345678910111213141516171819202122from typing import Annotated, TypedDictimport operatorfrom langgraph.types import Sendfrom langgraph.graph import END, STARTfrom langgraph.graph import StateGraphclass OverallState(TypedDict): subjects: list[str] jokes: Annotated[list[str], operator.add]def continue_to_jokes(state: OverallState): return [Send(&quot;generate_joke&quot;, &#123;&quot;subject&quot;: s&#125;) for s in state[&#x27;subjects&#x27;]]builder = StateGraph(OverallState)builder.add_node(&quot;generate_joke&quot;, lambda state: &#123;&quot;jokes&quot;: [f&quot;Joke about &#123;state[&#x27;subject&#x27;]&#125;&quot;]&#125;)builder.add_conditional_edges(START, continue_to_jokes)builder.add_edge(&quot;generate_joke&quot;, END)graph = builder.compile()# Invoking with two subjects results in a generated joke for eachprint(graph.invoke(&#123;&quot;subjects&quot;: [&quot;cats&quot;, &quot;dogs&quot;]&#125;))# &#123;&#x27;subjects&#x27;: [&#x27;cats&#x27;, &#x27;dogs&#x27;], &#x27;jokes&#x27;: [&#x27;Joke about cats&#x27;, &#x27;Joke about dogs&#x27;]&#125; ps：Map-Reduce 设计模式介绍 Map-Reduce 是一种用于处理和生成大型数据集的编程模型，最初由 Google 提出。这种设计模式主要包含两个阶段： 基本概念 Map 阶段 ：将输入数据分割成独立的块，并行处理这些块，生成中间结果（键值对）。 Reduce 阶段 ：收集 Map 阶段的所有中间结果，进行合并和处理，生成最终输出。 5. 配置标记图的某些部分是可配置的，通过传入配置数据。比如在一些节点选择不同的llm，或者提示词等。 1234567891011121314class ConfigSchema(TypedDict): llm: str# 实例化时传入 状态和配置 的数据结构graph = StateGraph(State, config_schema=ConfigSchema)# 执行时使用的配置数据config = &#123;&quot;configurable&quot;: &#123;&quot;llm&quot;: &quot;anthropic&quot;&#125;&#125;graph.invoke(inputs, config=config)def node_a(state, config): llm_type = config.get(&quot;configurable&quot;, &#123;&#125;).get(&quot;llm&quot;, &quot;openai&quot;) llm = get_llm(llm_type) ... 6. 递归限制文档 设置正确的图递归限制对于避免图运行陷入长时间运行的循环很重要，因此有助于最大限度地减少不必要的成本。 限制图最多能走几个节点。 1graph.invoke(inputs, config=&#123;&quot;recursion_limit&quot;: 5, &quot;configurable&quot;:&#123;&quot;llm&quot;: &quot;anthropic&quot;&#125;&#125;) 7. 断点断点 在某些节点执行之前或之后设置断点。 也可以动态添加断点：根据某些条件，动态地从给定节点内部中断图。 8. 显示图123456789101112# 显示图像from IPython.display import Image, display# 生成并保存图像png_data = graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API,)# 保存图像到文件with open(&#x27;workflow_graph.png&#x27;, &#x27;wb&#x27;) as f: f.write(png_data)# 显示图像display(Image(png_data)) 9. 流式输出文档 .stream 和 .astream 是同步和异步方法，用于从图运行中流式返回输出。 可以指定多种不同的模式： &quot;values&quot;: 这会在图的每一步之后流式传输状态的完整值。 &quot;updates&quot;: 这会在图的每一步之后流式传输状态的更新。如果在同一步骤中进行了多个更新（例如运行多个节点），则这些更新将单独流式传输。 &quot;debug&quot;: 这在整个图执行过程中流式传输尽可能多的信息。 流式 LLM 标记和事件 (.astream_events) 可以使用 astream_events 方法流式传输节点内部发生的事件。 每个节点（可运行的）都会在开始执行时发出 on_chain_start，在节点执行期间发出 on_chain_stream，并在节点完成时发出 on_chain_end。节点事件将具有事件的 name 字段中的节点名称 对状态通道的任何写入（即任何时候更新其中一个状态键的值）都会发出 on_chain_start 和 on_chain_end 事件 可以利用节点名称等信息，在返回图表等特殊数据时，前端对其进行特殊渲染。 123456789101112131415161718192021222324252627import osimport asynciofrom langchain_openai import ChatOpenAIfrom langgraph.graph import StateGraph, MessagesState, START, ENDmodelName = &#x27;qwen-max-latest&#x27;baseUrl = &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;os.environ[&quot;OPENAI_API_KEY&quot;] = &#x27;&#x27;model = ChatOpenAI(model=modelName, base_url=baseUrl)def call_model(state: MessagesState): response = model.invoke(state[&#x27;messages&#x27;]) return &#123;&quot;messages&quot;: response&#125;workflow = StateGraph(MessagesState)workflow.add_node(call_model)workflow.add_edge(START, &quot;call_model&quot;)workflow.add_edge(&quot;call_model&quot;, END)app = workflow.compile()async def main(): inputs = [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hi!&quot;&#125;] async for event in app.astream_events(&#123;&quot;messages&quot;: inputs&#125;, version=&quot;v1&quot;): kind = event[&quot;event&quot;] print(f&quot;&#123;kind&#125;: &#123;event[&#x27;name&#x27;]&#125;&quot;)if __name__ == &quot;__main__&quot;: asyncio.run(main()) 我们从整体图开始（on_chain_start: LangGraph）。然后我们写入 __start__ 节点（这是一个处理输入的特殊节点）。然后我们启动 call_model 节点（on_chain_start: call_model）。然后我们启动聊天模型调用（on_chat_model_start: ChatOpenAI），按标记流式返回（on_chat_model_stream: ChatOpenAI），然后完成聊天模型（on_chat_model_end: ChatOpenAI）。从那里，我们将结果写回通道（ChannelWrite&lt;call_model,messages&gt;），然后完成 call_model 节点，最后完成整个图。 一个完整的事件数据： 12345678910111213141516&#123;&#x27;event&#x27;: &#x27;on_chat_model_stream&#x27;, &#x27;name&#x27;: &#x27;ChatOpenAI&#x27;, &#x27;run_id&#x27;: &#x27;3fdbf494-acce-402e-9b50-4eab46403859&#x27;, &#x27;tags&#x27;: [&#x27;seq:step:1&#x27;], &#x27;metadata&#x27;: &#123;&#x27;langgraph_step&#x27;: 1, &#x27;langgraph_node&#x27;: &#x27;call_model&#x27;, &#x27;langgraph_triggers&#x27;: [&#x27;start:call_model&#x27;], &#x27;langgraph_task_idx&#x27;: 0, &#x27;checkpoint_id&#x27;: &#x27;1ef657a0-0f9d-61b8-bffe-0c39e4f9ad6c&#x27;, &#x27;checkpoint_ns&#x27;: &#x27;call_model&#x27;, &#x27;ls_provider&#x27;: &#x27;openai&#x27;, &#x27;ls_model_name&#x27;: &#x27;gpt-4o-mini&#x27;, &#x27;ls_model_type&#x27;: &#x27;chat&#x27;, &#x27;ls_temperature&#x27;: 0.7&#125;, &#x27;data&#x27;: &#123;&#x27;chunk&#x27;: AIMessageChunk(content=&#x27;Hello&#x27;, id=&#x27;run-3fdbf494-acce-402e-9b50-4eab46403859&#x27;)&#125;, &#x27;parent_ids&#x27;: []&#125; &#39;langgraph_node&#39;: &#39;call_model&#39;,告诉我们这个模型是在哪个节点内调用的。","tags":["AI","Agent框架"],"categories":["技术","AI"]},{"title":"大模型应用开发 - 提示词优化","path":"/技术/AI/ai-prompt/","content":"基本的方法论框架基础要素：指令、背景信息、补充数据（要求）、输出格式、（其他限制条件） 例如： 大模型用来画思维导图 指令： 帮我写一个模型训练的思维导图。背景信息：千帆ModelBuilder训练流程为框架。补充数据：思维导图为横版展示。输出格式：输出内容要有数据准备、模型训练、模型管理和服务管理4大流程。 大模型担任律师 能力与角色：你现在是一个资深律师。背景信息：最近你接了一个财务侵占的官司，涉案金额5xxx元，你是受害人的辩护律师。指令： 请帮忙出一个法律公告，警示被告尽快偿还非法侵占的财务。输出风格：公告内容要严谨严肃专业。输出范围：公告内容不宜超过800字。 COT &#x2F; CODChain of Thought（思维链） COT（Chain of Thought）是一种通过引导大语言模型（LLM）生成逐步推理过程来提升复杂任务解决能力的技术。其核心在于让模型模仿人类分步骤思考的思维链，将问题分解为多个中间推理环节，最终推导出答案 技术特点：结构化推理：通过示例或指令要求模型展示“解题过程”，例如数学问题中的分步计算；可解释性增强：中间步骤的输出便于用户理解模型逻辑，提升信任度；适用场景：数学推理、符号逻辑、复杂问答等需要多步验证的任务 添加“请逐步思考”“分三步论证”等指令，引导模型展示完整推理路径。测试显示该方法可使数学题准确率提升 Chain of Draft（草稿链） COD（Chain of Draft）是COT的高效演化版本，其核心是仅保留推理中的关键步骤，通过极简的中间表达（如公式、符号）降低计算成本。 技术特点：极简输出：每个推理步骤仅用5个词以内表达，例如“20-12&#x3D;8→答案8”；效率优势：相比COT减少80%的Token使用量，延迟降低40%-76%；适用场景：实时交互（客服、语音助手）、资源受限环境（手机、IoT设备） 我的应用场景：在RAG等系统中，与大模型交互的中间步骤，有需要大模型判断的节点。 例如：我需要让视觉大模型判断是否已经打开了某个APP。 12345678&#123; &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&quot;&quot;你是一个移动应用识别专家。 请根据提供的移动应用屏幕截图判断目标应用是否匹配。 在分析过程中，请逐步思考，但每个步骤的描述尽量简洁（不超过10个字）。 使用分隔符“####”来区分思考过程与最终答案。 最终只需回答“是”或“否”。&quot;&quot;&quot;&#125; Prompt拆解： 提供角色 在分析过程中，请逐步思考 每个思考步骤不超过10个字 也可以添加要识别APP的背景信息，如盒马：盒马是一家线上买菜平台 使用通义千问2.5-VL-72B： 123456789101112131415161718192021222324252627282930313233343536373839401. COD&#123; &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&quot;&quot;你是一个移动应用识别专家。 请根据提供的移动应用屏幕截图判断目标应用是否匹配。 在分析过程中，请逐步思考，但每个步骤的描述尽量简洁（不超过10个字）。 使用分隔符“####”来区分思考过程与最终答案。 最终只需回答“是”或“否”。&quot;&quot;&quot;&#125;&#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&quot;&quot;请分析这个屏幕截图，判断它是否属于盒马APP的页面。 盒马APP：盒马是一家线上买菜平台。&quot;&quot;&quot;&#125;回复：搜索框有水果促销信息####是2. COT&#123; &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&quot;&quot;你是一个移动应用识别专家。 请根据提供的移动应用屏幕截图判断目标应用是否匹配。 在分析过程中，请逐步思考。 使用分隔符“####”来区分思考过程与最终答案。 最终只需回答“是”或“否”。&quot;&quot;&quot;&#125;&#123; &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&quot;&quot;请分析这个屏幕截图，判断它是否属于盒马APP的页面。 盒马APP：盒马是一家线上买菜平台。&quot;&quot;&quot;&#125;回复：从屏幕截图中可以看到以下特征：页面顶部显示了“星宝店”，这是盒马APP中常见的店铺名称。页面中部有多个分类标签，如“水果鲜花”、“蔬菜豆制品”、“肉禽蛋品”等，这些分类与盒马APP的食品分类一致。页面底部有“分类”、“盒马小镇”、“购物车”和“我的”等标签，这些标签也是盒马APP的标准导航栏。页面整体设计风格和布局与盒马APP非常相似。综合以上分析，可以判断这个屏幕截图属于盒马APP的页面。是 COT &#x2F; COD对比 对大模型在数据集GSM8K上对测试，可发现COD的准确率几乎和COT相同。 但在所需Token、延迟时间上，COD有明显的优势。 例如： 问题： 杰森有20个棒棒糖。他给了丹尼一些。现在他还剩下12个。杰森给了丹尼多少个棒棒糖？ 1.标准提示（直接答案） 回复： 8 2.思维链（CoT）提示（逐步解释） 回复： 杰森一开始有20个棒棒糖。 给了一些之后，他剩下12个。 要找出他给了多少，我们做减法：20 - 12。 这给出了8。 3.草稿链（CoD）提示（简洁推理） 回复： 20 - 12 &#x3D; 8 → 最终答案：8. CoT是全面的，但可能过于繁琐。CoD去除了不必要的部分，保留清晰度的同时节省时间。 其他优化点1. 示例引导与少样本学习 提供3-5个输入输出示例，帮助模型快速掌握任务模式。如翻译任务可给出中英对照样例 对于创意类任务，给出风格参考（如：“模仿鲁迅杂文风格写作”） 对于文本分类，”样例：’CPU性能升级’→科技 样例2：’欧冠决赛’→体育 请分类：’新型电池技术’” 2. 角色设定与背景引导明确要求模型扮演特定角色（如科学家、程序员），并设定其职业背景、目标动机，可提升回答的专业性与一致性。例如：“你是一名资深营养学家，需用通俗语言解释维生素C的作用”。 科学解释场景“你是一位量子物理研究员，需用生活化比喻向中学生解释量子纠缠现象”→ 输出会使用”如同心灵感应的粒子”等类比 商业分析场景“作为麦肯锡咨询顾问，请用SWOT分析法评估新能源汽车市场”→ 生成包含竞争优势、政策风险等维度的结构化报告 3. 任务分解与步骤引导 将复杂任务拆解为明确步骤，例如：“第一步分析数据特征→第二步建立模型→第三步验证结果” 要求模型先展示推理过程再输出结论，可提升数学类问题的准确性 活动策划：”1.确定主题→2.预算分配→3.流程设计→4.风险评估”。→ 生成包含时间轴、应急预案的方案","tags":["AI","大模型应用","提示词优化"],"categories":["技术","AI"]},{"title":"大模型应用开发 - 知识补齐（全）","path":"/技术/AI/ai-other/","content":"前言最近准备投简历，但发现还有一些技术点自己不熟悉。 那么这里就把没有掌握的技术点做个记录和总结。 已掌握（2025.3.5）： 基础：Python、Django、Flask等 大模型运用方式方法，有自己的一些技巧 RAG概念、Agent概念、智能体概念 了解大模型在一些方面的强项和弱项 熟练使用cursor等AI编程工具，突破技术瓶颈 实操过大模型训练、微调方法，知道何时需要上微调 熟悉Linux操作，熟练掌握大模型、小模型部署流程 大模型如何利用结构化、非结构化数据 未掌握（2025.3.5）： 之前做的两个大模型项目的难点、流程，没有总结。面试时会有风险。️ 热门向量数据库用法、特点。只熟悉ES的向量数据库用法，不会Milvus。 召回优化、多路？ Rerank模型了解较少，需要懂理论，会用法。 VLLM推理 LlamaFactory训练 Agent框架不熟悉 RAG、智能体、Agent 的场景用法没有统一的思路，要总结 和知识图谱结合 没有深度使用Dify、FlowRAG等RAG开源项目 当前： O1 大模型应用开发缺少的知识点 正常 50% KR1 总结两个大模型项目的经验，重点是难点、流程 为什么用ES的向量数据库，不用Milvus？ 正常 60% KR2 学习其他向量数据库的用法、特点 MilvusChorma 不着急 正常 30% KR3 Rerank模型了解较少，需要懂理论，会用法 用法理论场景 正常 20% KR-4 VLLM推理的部署 正常 50% KR-5 LlamaFactory训练 正常 90% KR-6 学习常见Agent框架用法、场景 LangChainllamaindexRAGFlow 正常 60% KR-7 与知识图谱结合的场景、技术 正常 0% KR-8 其他能力 Query理解、文档解析、召回、排序、相关性、引用计算、提示调优、评估迭代。 正常 70% KR-9 深度使用RAG开源项目 深度使用Dify、FlowRAG等RAG开源项目 正常 70% 一、项目总结用ES的原因：有些检索需要向量，有些检索需要ES的分词检索。比如事项问答，需要用ES分词检索。而本地风土人情需要用向量数据库检索。 有些功能，比如类案推送、法律法规检索。类案推送中已经让大模型提取出了关键词，那么已经有了这些关键词，可以在ES检索中配置关键词匹配的数量、是否分词等条件，可以更快、更精准的匹配到内容。法律法规的话，也是同样的已经用正则表达式处理好了法典名称、条目，用ES会更精准。 1.1 项目一 AI辅助办案平台项目难点分析：类案推送系统的设计与优化在开发类案推送功能时，我们遇到了传统RAG方案的局限性，并最终通过结构化数据方案进行了解决。最初，我们尝试将”类案推送”设计为传统的RAG（检索增强生成）项目：将案例数据进行向量化处理-&gt;存储到向量数据库中-&gt;用户输入的案情信息作为检索条件然而，在测试阶段我们发现这种方法存在问题：检索结果往往相关度不高。后来发现是因为法律案例与普通文本不同，它们具有独特的结构和专业术语，简单的语义相似度无法捕捉案例间的实质联系。解决方案:经过多次迭代，最终选择用结构化数据+ES检索： 在数据处理时，对原始数据进行结构化预处理：使用正则表达式，将非结构化案例文本转换为结构化数据，提取出案件的关键组成部分，比如将案件的各类基本信息进行提取。 在检索时：利用大模型从三个维度对案件进行提取，[争议焦点，核心事实，关键词] 争议焦点（法律争议点锚定） 核心事实（时间-地点-人物-行为四要素） 关键词（罪名+法律要件关键词） ES进行混合检索：基于这三个维度构建精确的ES查询条件，通过对三个维度进行不同的权重分配去做检索 混合检索策略： must子句保证基础要件匹配 should子句提升语义相关性 boost参数动态调整字段权重 处理长文本：很多法律有上千字的详细描述，这对于普通模型来说超出了上下文处理能力。我们采用了两项技术突破： 采用大上下文窗口模型：使用支持128K上下文窗口的大语言模型，确保能够处理完整案例 设计Prompt：精心设计了比较两个案例相似点和差异点的专业Prompt，引导模型关注法律要素而非表面文字 其他的优化思路先对长案例进行分段总结，获取核心要点后再进行对比，分段总结时可以并行处理，提高效率。 功能 类案推送：根据案情信息，提取[争议焦点，核心事实，关键词]， 总体流程 系统总体流程 类案推送 类案推送 数据建模 数据建模 法律法规 法律法规 文书生成 文书生成 1.2 项目二 政务问答助手系统总体流程 详细版总流程 二、向量数据库2.1 向量数据库对比 Metadata filter：支持对元数据进行过滤。元数据是附加在向量上的一些信息，键值对的形式。 BM25（Best Matching 25）：是一种用于信息检索的排序算法，文档长度归一化和词频饱和机制，更精准地评估文档与搜索查询的相关性。 文档长度归一化 作用：避免长文档因包含更多词汇而获得不合理的高分。 机制：根据文档长度动态调整词频权重，短文档中匹配关键词的得分更高。示例：搜索“人工智能”，一篇100字的短文比1000字的长文更易因关键词集中而排名靠前。 词频饱和（Term Frequency Saturation） 作用：限制高频词对得分的过度影响。 机制：使用对数函数对词频进行压缩，使词频达到一定阈值后重要性增幅趋缓。示例：某文档中“算法”出现100次，BM25会将其重要性压缩至接近出现10次时的水平。 稀疏嵌入表示 Sparse（稀疏检索） Hybrid（混合检索） 方法 核心逻辑 优势场景 BM25 关键词统计匹配 短文本、精确关键词搜索 Sparse 高维稀疏向量（词频驱动） 可解释性要求高的结构化检索 Hybrid 关键词+语义联合优化 复杂语义与关键词混合查询 2.2 Milvus四、VLLM推理GPU环境下安装较为简单，pip安装。 123456conda create -n myenv python=3.10 -yconda activate myenvpip install vllm# 可设置modelscope的下载模型export VLLM_USE_MODELSCOPE=True 使用脚本进行推理 1234567891011121314151617181920from vllm import LLM, SamplingParamsprompts = [ &quot;Hello, my name is&quot;, &quot;The president of the United States is&quot;, &quot;The capital of France is&quot;, &quot;The future of AI is&quot;,]sampling_params = SamplingParams(temperature=0.8, top_p=0.95)llm = LLM(model=&quot;/mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-1.5B-Instruct&quot;)outputs = llm.generate(prompts, sampling_params)# Print the outputs.# 打印输出for output in outputs: prompt = output.prompt generated_text = output.outputs[0].text print(f&quot;Prompt: &#123;prompt!r&#125;, Generated text: &#123;generated_text!r&#125;&quot;) 使用OpenAPI接口进行推理vllm后可接本地或模型仓库名 1234vllm serve /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-1.5B-Instruct或vllm serve /mnt/workspace/.cache/modelscope/models/Qwen/Qwen2.5-1.5B-Instruct \\ --served-model-name Qwen2.5-1.5B-Instruct 1234567curl http://localhost:8000/v1/completions \\-H &quot;Content-Type: application/json&quot; \\-d &#x27;&#123;&quot;model&quot;: &quot;Qwen2.5-1.5B-Instruct&quot;,&quot;prompt&quot;: &quot;法国的首都是&quot;,&quot;max_tokens&quot;: 50&#125;&#x27; 五、LlamaFactory训练 总结到了这里 九、开源平台技术洞察1. Dify 技术洞察文档 1.1 知识库 导入方式 本地文件，单文件15M限制 其他：Notion、Firecrawl、Jina Reader。后者是在线爬虫平台，可将html等页面数据转为规范等MD等格式，便于大模型读取。 分段模式 通用模式：按照自定义的规则将内容拆分为独立的分段。可用正则表达式。 父子模式：如一篇文章是父，其句子为子。 父为较大的文本单位（如段落），用于提供信息 子为较小的文本单位（如句子），用于精确检索 索引模式 索引方法： 高质量：即用Embedding模型将分段文本转为向量。Q&amp;A：对分段文本进行总结，生成Q&amp;A 匹配对，Dify采用的是「Q to Q」（问题匹配问题）策略。 当用户提问时，系统会找出与之最相似的问题，然后返回对应的分段作为答案。 问题生成的逻辑： Step 1：了解并总结这段文本的主要内容。 Step 2：这段文本提到了哪些关键信息或概念。 Step 3：可分解或结合多个信息与概念。 Step 4：将这些关键信息与概念生成 20 个问题与答案。 经济：每个区块内使用 10 个关键词进行检索，使用倒排索引。 检索方式： 高质量：向量检索、全文检索与混合检索设置。混合检索中可以设置两种检索方式的结果权重。 总的来说，效果可能不能保证的好。一些分段策略、索引策略，感觉也一般。尤其QA模式，感觉有很大的问题，有的文件直接没有生成或者生成的效果一般。用他的切分策略，比较固定，可能不如自己去做切分的处理，再导入。 1.2 应用 Agent 产品描述： 可使用内置工具、自定义工具、编排的工作流。 最多3个工具 支持多工具调用 简单流程：Agent流程分为三步。 用Query让大模型的Function Call去选择工具和参数。 调用工具 大模型再次处理工具返回的结果 稍复杂流程：LLM根据Query循环调用工具 总的来说，支持自定义和工作流，确实也可以实现一些稍微复杂的场景。 但对于用 Dify 平台实现某个具体业务，保持怀疑。需要二次开发或借鉴其思路自己做。 文本生成应用 专注某类文本生成，利用提示词可作为一个小工具来使用。可以导入excel批量处理。 这个工具在让大模型处理较多数据时，有一些用处。比如让大模型总结100篇科学文章。 功能本身并不复杂。这里算是提供了一个可视化的操作页面 工作流 面向自动化和批处理情景，适合高质量翻译、数据分析、内容生成、电子邮件自动化等应用程序。该类型应用无法对生成的结果进行多轮对话交互。 常见的交互路径：给出指令 → 生成内容 → 结束 节点类型丰富，有LLM路由、参数提取等一些好用的功能。 节点内的配置也比较自由，可以添加上下文、System字段、User字段 在“探索”中，有挺复杂的工作流，有些RAG编排的思路很不错。但如果在业务中，我还是更倾向于自己写代码实现某个工作流。 Chatflow 常见的交互路径：给出指令 → 生成内容 → 就内容进行多次讨论 → 重新生成结果 → 结束 同工作流，只是 十、RAG 文本切分策略 文本切分的两个基本参数：Chunk Size（块大小）、Overlap（重叠）。 模型选择与Chunk Size 根据Chunk Size的设置，需要考虑Embedding的Max Token限制、大模型Max sequence length。 Chunk Size 不能超过Embedding模型Max Token 大模型对话时，需考虑 Top k * Chunk Size和大模型的 Max sequence length。 Embedding Model 排行榜： https://huggingface.co/spaces/mteb/leaderboard 文本切分策略 CharacterTextSplitter 字符分块\t使用固定长度字符窗口拆分文本（如每512字符） RecursivelyCharacterTextSplitter 递归分块\t基于字符列表拆分文本。按层次化分隔符（ &gt; &gt; , &gt; ? &gt; !）递归拆分至目标长度。 解释：其中如果每个分割的大小较大，则会递归分割，直到分至目标长度。 Document Specific Splitting基于不同的文件类型使用不同的切分方法（如PDF、Python、Markdown）。 Semantic Splitting 语义分块\t基于滑动窗口的语义切分。利用嵌入向量相似性分段。 从前几个句子开始，生成一个嵌入。 移动到下一组句子，并生成另一个嵌入（例如，使用滑动窗口方法）。 比较嵌入以查找重大差异，这表明语义部分之间可能存在“中断点”。 总结：先用某个方式切分，然后做滑动窗口，比如现在的窗口是1-3块，那么就将1-3和1-4块计算余旋相似度距离。 我们会设置一个距离的阀值，如果满足就把4块加入到1-3中，那么现在就是1-4块为一块，继续做滑动窗口。 如果不满足，就从这里切分，1-3块为一块，下一个窗口是4块，类推用4和4-5比较… 如果使用LangChain LangChain 的分割逻辑分为两步： 按 separator 预分割：先用指定的分隔符（此处是 ）将文本拆分为多个段落 合并至 chunk_size：将相邻段落合并，直到字符数不超过 chunk_size，但若某段落本身已超过 chunk_size，则会强制保留完整段落 ps：LangChain提供了两种计数方式：字符切分、Token切分。但根据LangChain的分割逻辑2，某段Chunk Size仍有可能超过设置的长度。 样例代码 1234567891011121314151617181920212223242526272829303132333435# 1. CharacterTextSplitterdocument = &quot;COT是一种通过引导大语言模型（LLM）生成逐步推理过程来提升复杂任务解决能力的技术。其核心在于让模型模仿人类分步骤思考的思维链，将问题分解为多个中间推理环节，最终推导出答案。 我是人工智能应用工程师&quot;from langchain_text_splitters import CharacterTextSplittertext_splitter = CharacterTextSplitter( separator=&quot;&quot;, chunk_size=20, chunk_overlap=1, length_function=len, # 使用内置的 len 函数来计算字符长度 is_separator_regex=False, # 是否使用正则表达式来分割文本)texts = text_splitter.split_text(document)print(texts)# 可用from_tiktoken_encoder，用token计数from langchain_text_splitters import CharacterTextSplittertext_splitter = CharacterTextSplitter.from_tiktoken_encoder( separator=&quot;&quot;, encoding_name=&quot;cl100k_base&quot;, chunk_size=20, chunk_overlap=1,)texts = text_splitter.split_text(document)# 2. RecursivelyCharacterTextSplitterfrom langchain_text_splitters import RecursiveCharacterTextSplitterrecursive_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder( chunk_size=20, # token数 separators=[&quot; &quot;,&quot; &quot;,&quot;。&quot;, &quot;，&quot;], # 优先级递减 chunk_overlap=0)texts = recursive_splitter.split_text(document)print(texts) 查看Embedding模型MaxToken、统计Chunk的Token数量 123456789101112131415161718192021from sentence_transformers import SentenceTransformerimport matplotlib.pyplot as pltfrom transformers import AutoTokenizerimport pandas as pdEmbedding_model = &#x27;BAAI/bge-large-zh-v1.5&#x27;print(SentenceTransformer(Embedding_model).max_seq_length)print(f&quot;文本长度 &#123;len(texts[1])&#125;&quot;)tokenizer = AutoTokenizer.from_pretrained(Embedding_model)print(f&quot;Token数 &#123;len(tokenizer.encode(texts[1]))&#125;&quot;)# 展示该chunk文本中使用 Embedding_model 的Token数def plot_chunk(chunks, embedding_model): tokenizer = AutoTokenizer.from_pretrained(embedding_model) length = [len(tokenizer.encode(chunk)) for chunk in chunks] fig = pd.Series(length).hist() plt.show() plot_chunk(texts, Embedding_model) 语义切分 递归语义切分 直接语义切分有几个问题：每块长度不平均，单块太长会出现超出Max Token的风险。 一轮切分后，根据每块的长度判断是否需要再次切分。 ps：块数和字符数没有正比关系。比如第一块有3个，第二块有4个，但第一块仍有可能比第4块长很多。 RAG优化： 预检索阶段：这个阶段的核心是“打好基础”，主要是对数据进行整理和预处理，比如建立索引、优化查询方式，让后续的检索更高效。 检索阶段：这个阶段的重点是“精准搜索”，通过改进嵌入模型（embedding model）和利用元数据过滤，让向量搜索的结果更准确、更相关。 后检索阶段：这个阶段的任务是“去粗取精”，从检索到的文档中剔除无关信息，压缩提示内容，再把干净、简洁的上下文交给大模型（LLM），让它生成高质量的答案。 1. 预检索阶段 数据清洗、删掉那些无关紧要的细节。 给数据加点标签（元数据），检索的时候有效过滤。 父子：用一小段文本来计算嵌入，在元数据里保留更宽的上下文窗口。小块的文本能提高检索的准确性，而更大的上下文则能给LLM（大语言模型）提供更多的背景信息。 用整篇文本来计算嵌入，可能会引入太多噪音，或者文本里可能包含多个主题，这样一来嵌入的整体语义表示就会变差。 查询优化 查询路由：数据检索可从向量库、数据库、网络等途径获取数据。 所以，在检索前、使用提示词之前，用LLM针对Query做判断。相当于编程的 if 语句 查询重写：重新组织问题的表述，来更好地匹配我们索引里的信息。 释义：把用户的查询换个说法，但意思不变 同义词替换：把一些不太常用的词换成更常见的同义词，这样搜索范围就更广了 子查询：如果查询比较长，我们可以把它拆成几个更短、更聚焦的小查询。 假设文档嵌入（HyDE）：LLM对用户问题做一个假设性回答，这个回答会和原始查询一起，输入到检索阶段。 查询扩展：通过添加一些相关的术语或概念，来丰富问题的维度 转结构化：把非结构化的查询“翻译”成结构化的查询，LLM 从Query中识别出关键的实体、事件和关系。作为元数据的过滤条件。 ⚠️ 需要注意的是，数据索引和查询优化的预检索技术，都高度依赖于数据的类型、结构和来源。所以，跟其他数据处理流程一样，没有一种方法是万能的。每个用例都有它的特殊性和潜在的坑。优化预检索 RAG 层是一个实验性很强的工作。因此，多尝试几种方法（比如上面提到的这些），反复试验，找到最适合的方案，才是关键。 2. 检索阶段1. 混合搜索 结合向量搜索和关键字搜索的混合方法。 关键字搜索擅长找到包含特定关键词的文档。如果你的任务需要高精度，并且检索结果必须包含精确的关键词匹配，那么这种方法非常有用。 向量搜索虽然功能强大，但在精确匹配上可能稍显不足，不过它更擅长捕捉语义上的相似性。 通过把这两种方法结合起来，可以同时利用关键词匹配和语义相似性的优势。会用一个参数（比如叫 alpha）来控制两者的权重。具体来说，算法会分别进行两种独立的搜索，然后将结果标准化并合并。 2. 过滤向量搜索 利用元数据索引来筛选出符合特定关键词的文档。它和混合搜索的区别在于，只需要用向量索引检索一次数据，然后在向量搜索之前或之后，通过过滤步骤来缩小搜索范围。 3. 后检索阶段 检索后优化主要是对已经检索到的数据进行处理，减少一些数据对 LLM 的干扰。如上下文窗口有限或数据有噪声， RAT来源：https://www.cnblogs.com/quincyqiang/p/18652768 检索增强思维 (RAT) 是一种简单但有效的提示方法，它将思路链 (CoT) 提示与检索增强生成 (RAG) 相结合，以处理长窗口推理和生成问题。 RAT 流程 生成初始草稿： 使用 GPT-3.5-turbo 生成一个初始的草稿答案（draft）。 草稿答案是基于用户输入的问题生成的，可能包含一些错误或不完整的信息。 分割草稿： 将草稿答案分割成多个段落（draft_paragraphs），每个段落包含一个完整的思路。 分割的目的是为了逐段修正和优化答案。 逐段修正答案： 对每个段落，生成一个检索查询（query），用于从网络中检索相关信息。 根据检索到的内容，修正当前段落的答案。 重复这一过程，直到所有段落都修正完毕。 结构化输出： 最后，为修正后的答案添加标题和副标题，使其更具结构性。 返回结果： 返回初始草稿和修正后的最终答案。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354## 示例流程假设用户输入的问题是：“介绍爱因斯坦的生平和成就。”### 生成初始草稿：GPT-3.5-turbo 生成一个初始答案，可能包含一些不准确的信息。### 分割草稿：将初始答案分割成多个段落，例如：段落1：爱因斯坦的早期生活。段落2：爱因斯坦的科学成就。段落3：爱因斯坦的晚年生活。### 逐段修正：对每个段落生成检索查询，例如：查询1：“爱因斯坦的早期生活”。查询2：“爱因斯坦的科学成就”。查询3：“爱因斯坦的晚年生活”。根据检索结果修正每个段落的内容。### 结构化输出：为修正后的答案添加标题和副标题，例如：标题：爱因斯坦的生平和成就副标题1：早期生活副标题2：科学成就副标题3：晚年生活### 返回结果：返回初始草稿和修正后的最终答案。## 提示词prompt1 = &quot;&quot;&quot;尝试用逐步的思考来回答这个问题\\指令，并使答案更具结构化。使用 ` ` 来将答案分成几个段落。直接响应指令。除非被要求，否则不要在答案中添加额外的解释或介绍。&quot;&quot;&quot;prompt2 = &quot;&quot;&quot;我想验证给定问题的内容准确性，特别是最后几句话。请用相应的问题总结内容。这个总结将被用作必应搜索引擎的查询。查询应该简短，但需要足够具体，以确保必应能够找到相关知识或页面。您还可以使用搜索语法，使查询足够简短和清晰，以便搜索引擎能够找到相关的语言数据。尽量使查询与内容中的最后几句话尽可能相关。**重要**直接输出查询。除非被要求，否则不要在答案中添加额外的解释或介绍。&quot;&quot;&quot;prompt3 = &quot;&quot;&quot;我想根据在维基百科页面上学到的相关文本来修订答案。你需要检查答案是否正确。如果你在答案中发现了错误，请修订答案使其更好。如果你发现有些必要的细节被忽略了，请根据相关文本添加这些细节，以使答案更加可信。如果你发现答案是正确的且不需要添加更多细节，请直接输出原始答案。**重要**尽量保持修订后答案的结构（多个段落及其子标题），使其更具结构性以便理解。用 ` ` 字符分隔段落。直接输出修订后的答案。除非被要求，否则在修订后的答案中不要添加额外的解释或声明。&quot;&quot;&quot;","tags":["AI","大模型应用"],"categories":["技术","AI"]},{"title":"模型蒸馏","path":"/技术/AI/ai-model-still/","content":"前言DeepSeek公开了一套模型蒸馏的基本范式，同时公开了基于Qwen2.5、Llama3的蒸馏模型。 本文仅为简单介绍DeepSeep模型蒸馏范式的基本流程。 其中，Qwen1.5B的推理性能已经超过了GPT4o，而Qwen32B到推理性能可以达到GPTo1-mini的水平。 AIME2024pass@1：测试模型在高难度数学推理和问题解决中的一次性表现能力。 AIME2024cons@64：测试模型在复杂数学任务中的稳定性和一致性能力。 MATH500pass@1：测试模型在广泛数学知识和高难度数学问题中的一次性解决能力。 GPQADiamondpass@1：测试模型在跨学科通用知识和复杂问答任务中的一次性表现能力。 LiveCodeBenchpass@1：测试模型在编程任务中的代码生成和问题解决能力。 CodeForcesrating：测试模型在算法设计和编程竞赛中的综合表现能力。 模型蒸馏范式 模型厂家对某个模型一般会开源两个版本，Base和Chat。 Base：只经过了预训练，没有经过全量指令微调，对话可能会胡言乱语，但有更好的调教空间。 Chat：经过了全量指令微调，有对话能力。 DeepSeek R1提出的模型蒸馏路径： 选择某个Base模型。 DeepSeek开源的蒸馏模型都基于Base版本。 对Base模型进行全量指令微调，利用高质量的问答数据，数据量不用大，几千条数据。知道基本的对话范式，学会开符、终止符。 利用非常大量COT数据进行训练。训练后 会把思考连看成是回答用户内容的一部分，输出时携带思考内容。所以需要经过大量的数据进行微调。 经过COT数据微调之后，可能模型还有很多问答上的问题，需要再进行训练。 DeepSeek模型训练路径（简化版）","tags":["AI","DeepSeek","模型蒸馏"],"categories":["技术","AI"]},{"title":"大模型应用开发 - 智能体设计模式","path":"/技术/AI/ai-design-patterns/","content":"参考：https://www.anthropic.com/research/building-effective-agentsanthropic在24年12月发布了六种智能体设计模式，涵盖了常见了大模型应用在开发上的场景。 前言1. 什么是Agent“Agent”可以有多种定义。有些客户将代理定义为完全自主的系统，这些系统能够在较长时间内独立运作，并利用各种工具完成复杂任务。另一些人则将这一术语用来描述更具规定性的实现，这些实现遵循预定义的工作流程。 工作流（Workflows）：通过预定义的代码路径编排 LLM 和工具的系统。 Agents：LLM 动态指导自己的流程和工具使用，保持对他们完成任务方式的控制的系统。 2. Agent何时用&#x2F;不用在构建LLM应用时，我们建议尽可能找到最简单的解决方案，只有在必要时才增加复杂性。这可能意味着根本不需要构建Agent系统。Agent系统通常会以更高的延迟和成本来换取更好的任务表现，因此应该考虑何时这种权衡是合理的。 当更高的复杂性是必要时，工作流程对于定义明确的任务提供了可预测性和一致性，而当需要在规模上实现灵活性和基于模型的决策时，Agent则是更好的选择。然而，对于许多应用来说，通过检索和上下文示例优化单次LLM调用通常就足够了。 3. 何时以及如何使用框架 一些Agent框架： LangGraph from LangChain; Amazon Bedrock’s AI Agent framework; Rivet, a drag and drop GUI LLM workflow builder; Vellum, another GUI tool for building and testing complex workflows. 这些框架通过简化标准的低级任务，如调用LLM、定义和解析工具以及串联调用，帮助开发者轻松入门。然而，它们往往会创建额外的抽象层，这可能会掩盖底层的提示和响应，使其更难调试。它们还可能让人产生在不需要复杂的情况下，而增加了复杂度。 建议开发者直接使用LLM API：许多模式可以通过几行代码实现。如果你确实使用框架，请确保理解底层代码。对于底层实现的错误假设是客户常见的错误来源。 设计模式代码实现1. Chain将大模型串连，每个模型处理部分的任务，并将结果作为下一个模型的输入。 优点： 分布思考，提升质量：让 IA集中精力处理每个环节，每一步有明确的目标，结果会更专业、精准。一次性完成所有任务可能会导致逻辑混乱、细节粗糙。 更多的可控性：不满意某一部分时，不需要推倒重来。可以根据需求在某一步插入反馈或修改，灵活调整内容方向。 降低信息过载风险：一次性给太多人五，AI难以平衡所有需求，可能会导致质量下降。用分布处理来减少干扰，每次关注一个重点。","tags":["AI","大模型应用"],"categories":["技术","AI"]},{"title":"24年终总结","path":"/Essays/20250219年终总结/","content":"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 Hey, password is required here.","tags":["我"],"categories":["随笔"]},{"title":"Pytorch","path":"/技术/Pytorch/","content":"记录机器学习基础知识、Pytorch基础使用。这次去年6月份的笔记了，当时开始转战AI了。 Pytorch1. 基础 1.1 名词 特征 特征是数据中的各个属性或变量，它们用于描述数据的不同方面。在机器学习中，每个特征都是一个输入变量，可以是数值型、类别型、文本型等。 比如：对于一个房价预测模型，特征可能包括房屋面积、房间数量、地理位置等。 纬度 纬度是指数据集中特征的数量。每个特征代表一个维度。 比如：一个具有3个特征的数据集可以被视为在3维空间中，每个数据点都有3个坐标（即3个特征）。 纬度诅咒 特征向量很多的数据，会引发纬度诅咒。在高纬度空间中，会导致数据稀疏、计算复杂度增加、模型过拟合等。 例如，假设我们有1000个特征，数据在1000维空间中会非常稀疏，距离度量也变得不再有意义。 在高维空间中数据分析和建模面临的一系列问题和挑战。随着数据维度的增加，数据在高维空间中的稀疏性也增加，导致许多传统方法在高维空间中表现不佳。 根本问题：数据量（有特征的）少，导致在高纬空间稀疏性增加。 特征选择和降维 可以通过特征选择（去除不相关或冗余的特征）和降维技术（如主成分分析PCA）来降低纬度。 案例 数据集：鸢尾花数据集（Iris Dataset） 特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度。 纬度：4（因为有4个特征）。 在这个数据集中，每朵花的数据点位于一个4维空间中。假设我们使用这些特征来训练一个分类模型来区分不同种类的鸢尾花： 如果我们引入更多特征（如花的颜色、花朵数量等），纬度将增加。 通过特征选择，我们可以选择对分类效果影响较大的特征来简化模型。 如果特征数量过多，可能需要使用降维技术来减少纬度，同时保留数据的主要信息。 向量和坐标 在向量空间中，每个数据点可以被表示为一个向量。 一个向量的每一个分量对应数据点的一个特征。例如： 1.2 人工智能系统的演变 Rule-based systems（基于规则的系统）：基于规则，手动设计多个规则，输入可以根据规则来输出。 基于规则的系统是最早的人工智能方法之一，这种系统通过人工编写的规则来处理输入并生成输出。 工作流程： 输入：系统接收输入数据。 手工设计的程序：专家编写的规则程序处理输入。 输出：生成结果。 特点： 依赖专家知识：规则由领域专家编写。 缺乏适应性：难以应对复杂、多变的任务。 可解释性强：由于规则是手工编写的，系统的决策过程容易理解。 应用场景： 简单决策系统：如税务计算、简单的诊断系统。 Classic machine learning（经典机器学习）：手动从输入中提取特征（最终变成一个向量 ），把输入和输出建立一个映射函数，f(x)&#x3D;y的公式，最后输出 经典机器学习方法通过使用预定义的特征和算法从数据中学习模型。 工作流程： 输入：系统接收输入数据。 手工设计的特征：专家从数据中提取重要特征（feature engineering）。 特征映射：使用机器学习算法（如线性回归、决策树等）对特征进行映射，从而生成输出。 输出：生成结果。 特点： 特征工程：特征的选择和设计对模型性能影响很大。 依赖领域知识：特征设计需要专家知识。 灵活性较强：可应用于各种类型的数据和任务。 应用场景： 图像识别、文本分类、预测分析等。 Representation learning（表示学习）：把非结构化的输入，通过复杂的算法，提取出特征（向量）。然后根据映射函数得到输出。 通过自动学习特征表示，将输入映射到输出。 输入：系统接收输入数据。 初始特征提取：从输入数据中提取初始特征，这些特征可能是手工设计的，也可能是从数据中自动学习得到的。 特征转换：通过不同的方法（如降维、聚类、编码等）将初始特征转换为新的特征表示。 特征映射：使用这些新的特征表示进行映射，生成输出。 输出：生成结果。 Depping Learning（深度学习）：表征学习的一种实现方式，通过多层神经网络来学习数据的多层次表示，具有强大的特征提取和任务优化能力。 输入：系统接收输入数据。 简单特征：初始层提取简单特征。 更多抽象特征的附加层：通过多层神经网络提取 更加抽象和复杂的特征。 特征映射：最终使用这些抽象特征进行映射，生成输出。 输出：生成结果。 1.3 反向传播实际上就是求偏导数 用计算图表示，每一步都是原子计算。 从下到上求e，是前推的过程。 2. 线型模型 有一些数据集。 先用线性模型，y&#x3D;wx+b。权重w。 随机一个权重，得到一个线型模型。 根据随机的线型模型，用输入获取输出y’。计算真实输出和y’的距离。 也就是说，通过某个方法找到当前模型和真实数据之间的误差。 也就是Loss 计算均方差 。w&#x3D;3时 w=2时。 注意： 对所有的样本：平均平方误差：Mean Sequare Error（**MSE**） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import numpy as npimport matplotlib.pyplot as plt# 数据样本x_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]# 线型模型def forward(x): return x * w# 损失函数def loss(x, y): y_pred = forward(x) return (y_pred - y) * (y_pred - y)# 预测的权重w，作为图的x轴w_list = []# 每个权重w对应的损失值，作为图的y轴mse_list = []# 在某个范围内，穷举权重wfor w in np.arange(0.0, 4.1, 0.1): print(&#x27;w=&#x27;, w) l_sum = 0 # 遍历每个样本，计算损失值 for x_val, y_val in zip(x_data, y_data): # 预测值 y_pred_val = forward(x_val) # 损失值 loss_val = loss(x_val, y_val) # 累加损失值 l_sum += loss_val print(f&quot;\\t&#123;x_val&#125; &#123;y_val&#125; &#123;y_pred_val&#125; &#123;loss_val&#125;&quot;) # 三个样本的平均损失值 print(f&quot;MSE = &#123;l_sum / 3&#125;&quot;) w_list.append(w) mse_list.append(l_sum / 3)plt.plot(w_list, mse_list)plt.ylabel(&#x27;Loss&#x27;)plt.xlabel(&#x27;w&#x27;)plt.show() 加上常数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344import numpy as npimport matplotlib.pyplot as pltx_data = [1.0, 2.0, 3.0]y_data = [3.0, 5.0, 7.0]def forward(x): return x * w + bdef loss(x, y): y_pred = forward(x) return (y_pred - y) * (y_pred - y)w_list = []b_list = []mse_list = []for w in np.arange(0.0, 4.1, 0.1): for b in np.arange(0.0, 4.1, 0.1): print(&#x27;w&#x27;, w, &#x27;b&#x27;, b) l_sum = 0 for x_val, y_val in zip(x_data, y_data): y_pred_val = forward(x_val) loss_val = loss(x_val, y_val) l_sum += loss_val print(&#x27;\\t&#x27;, x_val, y_val, y_pred_val, loss_val) print(&#x27;MSE=&#x27;, l_sum / 3) w_list.append(w) b_list.append(b) mse_list.append((l_sum) / 3)fig = plt.figure()ax = fig.add_subplot(111, projection=&#x27;3d&#x27;)# 绘制线框图ax.plot(w_list, b_list, mse_list, &#x27;o-&#x27;)print(w_list)# 设置标签ax.set_xlabel(&#x27;w&#x27;)ax.set_ylabel(&#x27;b&#x27;)ax.set_zlabel(&#x27;Loss&#x27;)# 显示图形plt.show() 3. 梯度下降3.1 意义 从线型模型，大概了解到了数据集、模型、Loss之间的关系。 那么模型的权重w，怎么快速求得，是一个问题。根本问题：如何最小化损失函数 假设Loss是光滑凹凸曲线，在这个曲线上，对某个w求偏导，可以知道当前w的方向。（导数&gt;0,增函数；导数&lt;0,减函数），那么沿着这个方向不断的测试w，可以得到最小Loss的w。（理想状态下） 事实上，Loss曲线是不光滑的非凸函数，只能找到局部最优。 cost（cost function，损失函数） 学习率：相当于w移动的距离 每次迭代，都向着下降最快的方向走，典型的贪心。这是局部最优结果 鞍点：不能继续迭代的点（梯度是0 ，走不动了），在一个水平线 或 从一个面上看是最低从另一个面看最高 3.2 公式 1234567891011121314151617181920212223242526272829303132333435363738394041424344import numpy as npimport matplotlib.pyplot as pltx_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]w = 1# 学习率rate = 0.01def forward(x): return x * w# 损失函数def cost(xs, ys): cost = 0 for x, y in zip(xs, ys): y_pred = forward(x) cost += (y_pred - y) ** 2 return cost / len(xs)# 求梯度def gradient(xs, ys): grad = 0 for x, y in zip(xs, ys): grad += 2 * x * (x * w - y) return grad / len(xs)l_list = []for epoch in range(100): cost_val = cost(x_data, y_data) grad_val = gradient(x_data, y_data) w = w - grad_val * rate print(&#x27;Epoch:&#x27;, epoch, &#x27;w=&#x27;, w, &#x27;loss=&#x27;, cost_val) l_list.append(cost_val)plt.plot(range(100), l_list)plt.show() 3.3 随机梯度下降 Stochastic 梯度下降：cost，用平均损失作为梯度下降更新的依据。比如N个样本，就需要计算N样本的损失 随机梯度下降：从N个样本中随机选一个，就成了拿单个样本的损失作为梯度下降的更新依据。 随机梯度下降的好处 加入在鞍点的情况下。使用cost会停止不同。但是如果只用一个样本，样本都是有噪声的，也就有了一个随机噪声，这个噪声可能就会帮助向前推动，有可能就会跳过鞍点，找到最优值 全部样本都计算损失（样本独立算损失，不是想之前那个求平均） 123456789101112131415161718192021222324252627282930313233343536373839import numpy as npimport matplotlib.pyplot as pltx_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]w = 1# 学习率rate = 0.01def forward(x): return x * w# 损失函数def loss(x, y): return (forward(x) - y) ** 2# 求梯度def gradient(x, y): return 2 * x * (x * w - y)l_list = []for epoch in range(100): for x, y in zip(x_data, y_data): grad_val = gradient(x, y) w = w - grad_val * rate print(&#x27;grad:&#x27;, x, y, grad_val) loss_val = loss(x, y) print(&quot;Epoch: &quot;, epoch, &quot;w=&quot;, w, &quot;loss=&quot;, loss_val) l_list.append(loss_val)# 因为每个样本都做了一次，所以是100*3plt.plot(range(100), l_list)plt.show() 存在的问题： 梯度下降：cost一次计算时，样本之间的损失没有关联（最后是损失的和），可以并行计算。 随机梯度下降：样本之间的损失是有关系的，因为当前样本计算的权重w，依赖上一个样本的w。这时的计算是不能并行的 梯度下降：效率高、性能低 随机梯度下降：效率低、性能高（比梯度下降拿到的最优值更好） 3.4 Mini-Batch小批量梯度下降 一种常用的梯度下降优化算法，它结合了批量梯度下降（Batch Gradient Descent）和随机梯度下降（Stochastic Gradient Descent, SGD）的优点，提供了一种在速度和稳定性之间折中的方法。 每次不对全部的N个点求损失的均值，而对某些点M(M&lt;N) 注意：这里老师【刘二大人】和其他博主讲的是相反，其他博主是说梯度下降（即批量梯度下降）效率最慢，结果好。随机梯度下降是从N个点中选择一个点，效率最好，结果差（实际上刘二老师也说的是选一个，但是代码中，实际上还是都选了。。）。 这里等之后有时间或其他机会，再研究。 5. 反向传播 拿之前线性方程的举例。现在的X是N纬矩阵，W是M✖️N纬矩阵，H=W*X，是M纬矩阵。 H就是中间结果（隐藏层），H也是下一层的输入X’，再下一层H’&#x3D;W’ * X’，最后得到loss。这是一个前推的过程 得到loss之后，就需要求梯度、更新参数。 最终需要求的梯度是：loss对w对偏导（对于中间产生的H即X’, 也需要求loss对X’的偏导，因为他是中间结果，他的上一层，需要这个结果） loss对W对偏导，可以链式拆分：loss对H的偏导*H对W对偏导。 就这样逐层计算。当前层的链式计算表达式，其中可以用到后一层的结果，这是反向传播的过程 解决了下面的问题： 梯度计算: 问题: 神经网络中包含多个隐藏层，每一层都有大量的参数（权重和偏置）。要调整这些参数使得网络的输出与期望输出尽可能接近，需要计算损失函数关于每个参数的梯度。参数x是一个N纬矩阵，如果按照一纬线型的方式求loss、梯度下降，那么计算量很庞大。 解决: 反向传播算法使用链式法则（链式求导法则）来高效地计算损失函数关于每个参数的梯度。这些梯度用于更新参数，使得损失函数的值在训练过程中逐渐减小。 权重更新: 问题: 一旦计算了梯度，需要使用这些梯度来更新网络中的权重，以减少预测误差。 效率问题: 问题: 直接计算每个参数的梯度在深度神经网络中可能会非常耗时且复杂，特别是当网络层数较多时。 解决: 反向传播通过逐层计算梯度，利用前向传播时保存的中间结果，可以有效地减少计算量。具体来说，通过逐层计算误差的传播，从输出层到输入层反向传播误差，使得梯度计算更加高效。 反向传播的核心步骤 前向传播: 输入数据通过网络，从输入层经过各个隐藏层，到达输出层，计算出网络的预测值。 损失计算: 根据网络的预测值和真实值，计算损失函数值。 反向传播: 从输出层开始，逐层计算损失函数关于每个参数的梯度，反向传播到输入层。 权重更新: 使用梯度和优化算法（如梯度下降），更新每个参数的值。 前向传播目的是计算损失，反向传播目的是计算梯度来更新参数。 5. Pytorch Pytorch基础： Tensor存放数据，可以是标量、向量、矩阵、高阶矩阵。就说任何类似的数值都行 w是Tensor(张量类型)，Tensor中包含data和grad，data和grad也是Tensor。grad初始为None，调用l.backward()方法后w.grad为Tensor，故更新w.data时需使用w.grad.data 如果w需要计算梯度，那构建的计算图中，跟w相关的tensor都默认需要计算梯度。 123456789101112import osos.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;import torcha = torch.tensor([1.0])a.requires_grad = True # 或者 a.requires_grad_()print(a)print(a.data)print(a.type()) # a的类型是tensorprint(a.data.type()) # a.data的类型是tensorprint(a.grad)print(type(a.grad)) 反向传播主要体现在，l.backward()。调用该方法后w.grad由None更新为Tensor类型，且w.grad.data的值用于后续w.data的更新。 l.backward()会把计算图中所有需要梯度(grad)的地方都会求出来，然后把梯度都存在对应的待求的参数中，最终计算图被释放。 取tensor中的data是不会构建计算图的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import osos.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;import matplotlib.pyplot as pltimport torchx_data = [1.0, 2.0, 3.0]y_data = [2.0, 4.0, 6.0]w = torch.tensor([0.1])# 需要计算梯度w.requires_grad = True# 注意这里的w是一个tensor，所以x也要是一个tensor（如果不是，那么会自动转换类型）# 并且，这不是一个乘法，而代表一个计算图def forward(x): return x * w# 这也是一个计算图def loss(x, y): y_pred = forward(x) return (y_pred - y) ** 2l_list = []for epoch in range(100): for x, y in zip(x_data, y_data): l = loss(x, y) # 反向传播。backward自动根据计算图，把所有需要梯度的地方都求出来。梯度会存到w中 # 执行完毕，计算图会被释放。下次loss会创建一个新的计算图。 l.backward() print(&#x27;\\tgrad:&#x27;, x, y, w.grad.item()) # 这里我们需要的是值，所以用data。如果用w，那么会得到一个tensor，而不是一个值 w.data = w.data - 0.01 * w.grad.data w.grad.data.zero_() print(&quot;Epoch: &quot;, epoch, &quot;w=&quot;, w, &quot;loss=&quot;, l.data) l_list.append(l.data)# 因为每个样本都做了一次，所以是100*3plt.plot(range(100), l_list)plt.show() 6. 逻辑斯蒂回归6.1 二分类问题与sigmoid函数 二分类问题：假如手写字体识别的例子，判断数字是0-9的概率。实际上求的是P(y)&#x3D;1的概率（即手写数字是某个数字的概率）。由于我们求的是概率，那么我们的输出值，需要限定在[0,1]区间。使用下面这个函数，将结果带入 这种函数被称为：sigmoid函数 6.2 损失函数和交叉熵 前言：在线程回归中，我们计算损失是求y‘和y的距离，这是几何意义。但是在概率上就不能这样了，要计算的是两个概率分布的差距。 例如： 有两个分布D、T，用下面的公式可以计算两个分布之间的差距，越 大 越好 加负号之后就成了越小越好 在代码上，只需要修改y_pred的结果 和 损失 这个求损失的方法，就是交叉熵 1234567891011121314151617181920212223242526272829303132333435363738394041424344import torch# import torch.nn.functional as F# prepare datasetx_data = torch.Tensor([[1.0], [2.0], [3.0]])y_data = torch.Tensor([[0], [0], [1]])# design model using classclass LogisticRegressionModel(torch.nn.Module): def __init__(self): super(LogisticRegressionModel, self).__init__() self.linear = torch.nn.Linear(1, 1) def forward(self, x): # y_pred = F.sigmoid(self.linear(x)) y_pred = torch.sigmoid(self.linear(x)) return y_predmodel = LogisticRegressionModel()# construct loss and optimizer# 默认情况下，loss会基于element平均，如果size_average=False的话，loss会被累加。criterion = torch.nn.BCELoss(size_average=False)optimizer = torch.optim.SGD(model.parameters(), lr=0.01)# training cycle forward, backward, updatefor epoch in range(1000): y_pred = model(x_data) loss = criterion(y_pred, y_data) print(epoch, loss.item()) optimizer.zero_grad() loss.backward() optimizer.step()print(&#x27;w = &#x27;, model.linear.weight.item())print(&#x27;b = &#x27;, model.linear.bias.item())x_test = torch.Tensor([[4.0]])y_test = model(x_test)print(&#x27;y_pred = &#x27;, y_test.data) 7. 多维数据处理 用多层神经网络，神经网络共3层；第一层是8维到6维的非线性空间变换，第二层是6维到4维的非线性空间变换，第三层是4维到1维的非线性空间变换。 本算法中torch.nn.Sigmoid() 将其看作是网络的一层，而不是简单的函数使用博客：https://blog.csdn.net/bit452/article/details/109682078 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import numpy as npimport torchimport matplotlib.pyplot as plt # prepare datasetxy = np.loadtxt(&#x27;diabetes.csv&#x27;, delimiter=&#x27;,&#x27;, dtype=np.float32)x_data = torch.from_numpy(xy[:, :-1]) # 第一个‘：’是指读取所有行，第二个‘：’是指从第一列开始，最后一列不要y_data = torch.from_numpy(xy[:, [-1]]) # [-1] 最后得到的是个矩阵 # design model using class class Model(torch.nn.Module): def __init__(self): super(Model, self).__init__() self.linear1 = torch.nn.Linear(8, 6) # 输入数据x的特征是8维，x有8个特征 self.linear2 = torch.nn.Linear(6, 4) self.linear3 = torch.nn.Linear(4, 1) self.sigmoid = torch.nn.Sigmoid() # 将其看作是网络的一层，而不是简单的函数使用 def forward(self, x): x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) x = self.sigmoid(self.linear3(x)) # y hat return x model = Model() # construct loss and optimizer# criterion = torch.nn.BCELoss(size_average = True)criterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;) optimizer = torch.optim.SGD(model.parameters(), lr=0.1) epoch_list = []loss_list = []# training cycle forward, backward, updatefor epoch in range(100): y_pred = model(x_data) loss = criterion(y_pred, y_data) print(epoch, loss.item()) epoch_list.append(epoch) loss_list.append(loss.item()) optimizer.zero_grad() loss.backward() optimizer.step() plt.plot(epoch_list, loss_list)plt.ylabel(&#x27;loss&#x27;)plt.xlabel(&#x27;epoch&#x27;)plt.show() 8. 加载数据集 MiniBatch对数据集打乱、分组 自己定义 DataSet 是抽象类，不能实例化对象，主要是用于构造我们的数据集 DataLoader：数据加载器。能拿出Mini-Batch进行训练。它帮我们自动完成这些工作。DataLoader可实例化对象。 batch_size：批处理大小 shuffle：是否打乱，真正训练的时候都会打乱 num_workers：并行处理的个数 继承DataSet的类需要重写init，getitem,len魔法函数。分别是为了加载数据集，获取数据索引，获取数据总量。 定义数据类 迭代数据对象。每次epoch用某一批的数据来训练。 使用库中的数据集内置了手写字体识别的数据集，datasets可以直接获取相关的数据对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import torchimport numpy as npfrom torch.utils.data import Datasetfrom torch.utils.data import DataLoaderimport matplotlib.pyplot as plt# prepare datasetclass DiabetesDataset(Dataset): def __init__(self, filepath): xy = np.loadtxt(filepath, delimiter=&#x27;,&#x27;, dtype=np.float32) self.len = xy.shape[0] # shape(多少行，多少列) self.x_data = torch.from_numpy(xy[:, :-1]) self.y_data = torch.from_numpy(xy[:, [-1]]) def __getitem__(self, index): return self.x_data[index], self.y_data[index] def __len__(self): return self.lendataset = DiabetesDataset(&#x27;dataset/diabetes.csv&#x27;)train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=0) # num_workers 多线程# design model using classclass Model(torch.nn.Module): def __init__(self): super(Model, self).__init__() self.linear1 = torch.nn.Linear(8, 6) self.linear2 = torch.nn.Linear(6, 4) self.linear3 = torch.nn.Linear(4, 1) self.sigmoid = torch.nn.Sigmoid() def forward(self, x): x = self.sigmoid(self.linear1(x)) x = self.sigmoid(self.linear2(x)) x = self.sigmoid(self.linear3(x)) return xmodel = Model()# construct loss and optimizercriterion = torch.nn.BCELoss(reduction=&#x27;mean&#x27;)optimizer = torch.optim.SGD(model.parameters(), lr=0.01)# training cycle forward, backward, updateif __name__ == &#x27;__main__&#x27;: epoch_list = [] loss_list = [] for epoch in range(100): for i, data in enumerate(train_loader, 0): # train_loader 是先shuffle后mini_batch inputs, labels = data y_pred = model(inputs) loss = criterion(y_pred, labels) print(epoch, i, loss.item()) optimizer.zero_grad() loss.backward() optimizer.step() epoch_list.append(epoch) loss_list.append(loss.item()) plt.plot(epoch_list, loss_list) plt.ylabel(&#x27;loss&#x27;) plt.xlabel(&#x27;epoch&#x27;) plt.show() 9. 多分类问题9.1 Softmax 对每个分类求结果，如把看做求y1，把其他的分类都看做P(y)=0.那么求出结果，但是会造成，这些分类的结果相加不是1，比如P(y1) = 0.8,P(y2)=0.7 Softmax：重新得到一个值，然后求和，再求。即：a/a+b+c 交叉熵求损失 用CrossEntropyLoss，神经网络的最后一层不需要做激活 9.2 图像输入表示 一张黑白图的像素，可以用0-255的数值表示 图像的表示 将图像转为Tensor，分别是：通道、宽、高 全连接网络 最后一层不做激活 9.3 总结来自：https://blog.csdn.net/bit452/article/details/109686936 softmax的输入不需要再做非线性变换，也就是说softmax之前不再需要激活函数(relu)。softmax两个作用，如果在进行softmax前的input有负数，通过指数变换，得到正数。所有类的概率求和为1。 多分类问题，标签y的类型是LongTensor。比如说0-9分类问题，如果y &#x3D; torch.LongTensor([3])，对应的one-hot是[0,0,0,1,0,0,0,0,0,0].(这里要注意，如果使用了one-hot，标签y的类型是LongTensor，糖尿病数据集中的target的类型是FloatTensor) CrossEntropyLoss &lt;&#x3D;&#x3D;&gt; LogSoftmax + NLLLoss。也就是说使用CrossEntropyLoss最后一层(线性层)是不需要做其他变化的；使用NLLLoss之前，需要对最后一层(线性层)先进行SoftMax处理，再进行log操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import torchimport numpy as npfrom torchvision import datasetsfrom torch.utils.data import DataLoaderimport matplotlib.pyplot as pltfrom torchvision import transformsimport torch.nn.functional as Fbatch_size = 64transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])train_dataset = datasets.MNIST(root=&quot;/dataset/mnist&quot;, train=True, transform=transform, download=True )test_dataset = datasets.MNIST(root=&quot;/dataseet/mnist&quot;, train=True, transform=transform, download=True)train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)# design model using classclass Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.l1 = torch.nn.Linear(784, 512) self.l2 = torch.nn.Linear(512, 256) self.l3 = torch.nn.Linear(256, 128) self.l4 = torch.nn.Linear(128, 64) self.l5 = torch.nn.Linear(64, 10) def forward(self, x): x = x.view(-1, 784) x = F.relu(self.l1(x)) x = F.relu(self.l2(x)) x = F.relu(self.l3(x)) x = F.relu(self.l4(x)) return self.l5(x)model = Net()# construct loss and optimizercriterion = torch.nn.CrossEntropyLoss(reduction=&#x27;mean&#x27;)optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)epoch_list = []loss_list = []index_1 = 0def train(epoch): global index_1 running_loss = 0.0 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: epoch_list.append(index_1) index_1 += 1 loss_list.append(running_loss / 300) print(&quot;[%d,%5d] loss: %.3f&quot; % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0def test(): correct = 0 total = 0 with torch.no_grad(): for data in test_loader: images, labels = data output = model(images) _, predicted = torch.max(output.data, dim=1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f&quot;&#123;100 * correct / total&#125;&quot;)# training cycle forward, backward, updateif __name__ == &#x27;__main__&#x27;: for epoch in range(100): train(epoch) test() plt.plot(epoch_list, loss_list) plt.ylabel(&#x27;loss&#x27;) plt.xlabel(&#x27;epoch&#x27;) plt.show() 10. 卷积神经网络 假如一个RGB的图片，有三个通道，即C * W *H 的张量。卷积的过程：用卷积核转为一个通道（提取特征），生成新的C&#39;*W&#39;*H&#39; 的张量，最大池化层进一步减小，最后转为一个向量。 另一种情况，想要多个输出通道 10.1 padding weight.data，自己定义卷积核权重 10.2 stride 步长 10.3 下采样MaxPooling分成四块，选最大的设置kernel_size&#x3D;2，默认步长也是2 10.4 卷积神经网络过程 10.5 GPU运行用GPU 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114# This is a sample Python script.# Press Shift+F10 to execute it or replace it with your code.# Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.import torchfrom torchvision import datasetsfrom torch.utils.data import DataLoaderimport matplotlib.pyplot as pltfrom torchvision import transformsimport torch.nn.functional as Fbatch_size = 64transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])train_dataset = datasets.MNIST(root=&quot;./dataset/mnist&quot;, train=True, transform=transform, download=True )test_dataset = datasets.MNIST(root=&quot;./dataset/mnist&quot;, train=False, transform=transform, download=True)train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5) self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5) # self.pooling = torch.nn.MaxPool2d(2) self.pooling = torch.nn.MaxPool2d(2, return_indices=False) self.fc = torch.nn.Linear(320, 10) def forward(self, x): # x.size(0) 返回的是张量 x 在第一个维度上的大小。 # 对于大多数深度学习模型来说，输入数据的形状通常是 (batch_size, channels, height, width)。 batch_size = x.size(0) x = self.pooling(F.relu(self.conv1(x))) x = self.pooling(F.relu(self.conv2(x))) x = x.view(batch_size, -1) x = self.fc(x) return xmodel = Net()device = torch.device(&quot;npu:0&quot;)model.to(device)# construct loss and optimizercriterion = torch.nn.CrossEntropyLoss(reduction=&#x27;mean&#x27;)optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)# criterion.to(device)epoch_list = []loss_list = []index_1 = 0def train(epoch): global index_1 running_loss = 0.0 for batch_idx, data in enumerate(train_loader, 0): inputs, target = data # inputs, target = inputs.to(device), target.to(device) optimizer.zero_grad() outputs = model(inputs) loss = criterion(outputs, target) loss.backward() optimizer.step() running_loss += loss.item() if batch_idx % 300 == 299: epoch_list.append(index_1) index_1 += 1 loss_list.append(running_loss / 300) print(&quot;[%d,%5d] loss: %.3f&quot; % (epoch + 1, batch_idx + 1, running_loss / 300)) running_loss = 0.0def test(): correct = 0 total = 0 with torch.no_grad(): for data in test_loader: images, labels = data images, labels = images.to(device), labels.to(device) output = model(images) _, predicted = torch.max(output.data, dim=1) total += labels.size(0) correct += (predicted == labels).sum().item() print(f&quot;&#123;100 * correct / total&#125;&quot;)if __name__ == &#x27;__main__&#x27;: for epoch in range(10): train(epoch) test() plt.plot(epoch_list, loss_list) plt.ylabel(&#x27;loss&#x27;) plt.xlabel(&#x27;epoch&#x27;) plt.show() 11. RNN 循环神经网络 是一种用于处理序列数据的神经网络架构。它特别适合于处理时间序列、自然语言处理和其他顺序数据，因为它能够捕获数据的时间依赖性和动态信息。 内部实际上是线性层每次都有前一个输出也同时作为输入进入cell计算。注意，第一个cell的h，可以自定义成全0；也可以接入其他，比如卷积的数据，作为卷积神经网络和循环神经网络的一个链接作用。 多层RNN 训练代码，RNN内部已经实现了循环 交换batch_size和seq_len的位置，有时将batch_size放到第一个纬度可能在其他用处上更方便 11.1 RNN Cell代码 假设是训练 hello –&gt; e hlol 用独热向量来表示seq 定义模型这里用的是RNNCell，而不是整个RNN 11.2 RNN 11.3 使用embedding seq编码使用embedding 1PYTHONUNBUFFERED=1;LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/lib64:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/opskernel:/usr/local/Ascend/ascend-toolkit/latest/lib64/plugin/nnengine:$LD_LIBRARY_PATH;ASCEND_TOOLKIT_HOME=/usr/local/Ascend/ascend-toolkit/latest;PYTHONPATH=/usr/local/Ascend/ascend-toolkit/latest/python/site-packages:/usr/local/Ascend/ascend-toolkit/latest/opp/built-in/op_impl/ai_core/tbe:$PYTHONPATH;PATH=/usr/local/Ascend/ascend-toolkit/latest/bin:/usr/local/Ascend/ascend-toolkit/latest/compiler/ccec_compiler/bin:$PATH;ASCEND_AICPU_PATH=/usr/local/Ascend/ascend-toolkit/latest;ASCEND_OPP_PATH=/usr/local/Ascend/ascend-toolkit/latest/opp;TOOLCHAIN_HOME=/usr/local/Ascend/ascend-toolkit/latest/toolkit;ASCEND_HOME_PATH=/usr/local/Ascend/ascend-toolkit/latest","tags":["机器学习基础","AI"],"categories":["技术"]},{"title":"博客配置笔记","path":"/技术/hexo-stellar/","content":"我很希望能在这里吐心中之快、记心中之想。曾有过多次记录的念头，一直没有实施，这次终于部署了这个网站。 一、内容文档 1. 使用主题并修改主题文件本博客使用stellar主题，并修改&#x2F;增加了部分代码。那么如何用此主题并修改呢。 转为本地主题 在根目录创建文件夹themes，将主题依赖从node_modules/hexo-theme-stellar复制到themes，并修改文件名为stellar hexo的config.yml中的theme: stellar，不变。 修改方法例 网站底部信息可修改：footer.ejs 博客列表item所展示信息，可修改：post_list/post_card.ejs 比如这个文件中，可以发现可通过post获得当前item的信息，可以用console来输出查看其结构，比如我想展示标签的信息，可以用post.tags获得 themes/stellar/layout/_partial/main.├── article│ ├── article_footer.ejs│ ├── read_next.ejs│ └── related_posts.ejs├── footer.ejs├── navbar│ ├── article_banner.ejs│ ├── breadcrumb│ │ ├── blog.ejs│ │ ├── note.ejs│ │ ├── page.ejs│ │ └── wiki.ejs│ ├── dateinfo.ejs│ ├── ghinfo.ejs│ ├── nav_tabs_blog.ejs│ └── nav_tabs_wiki.ejs├── notebook│ ├── note_card.ejs│ ├── note_tags.ejs│ ├── notebook_card.ejs│ └── paginator.ejs└── post_list ├── paginator.ejs ├── post_card.ejs ├── topic_card.ejs └── wiki_card.ejs 2. 图片访问外链图片需添加： 1&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt; 3. 评论功能使用giscus，仓库BytePioneer-AI/LifeNotes。 12345678910111213141516171819comments: service: giscus # giscus # https://giscus.app/zh-CN giscus: src: https://giscus.app/client.js data-repo: BytePioneer-AI/LifeNotes # [在此输入仓库] data-repo-id: # [在此输入仓库 ID] data-category: Announcements # [在此输入分类名] data-category-id: data-mapping: pathname data-strict: 0 data-reactions-enabled: 1 data-emit-metadata: 0 data-input-position: top # top, bottom data-theme: preferred_color_scheme data-lang: zh-CN data-loading: lazy crossorigin: anonymous 4. html1234567891011121314---your front-matter---&#123;% raw %&#125;&lt;html&gt; &lt;head&gt; ... &lt;/head&gt; &lt;body&gt; .... &lt;/body&gt; &lt;/html&gt;&#123;% endraw %&#125; 5. 代码块[title] [lang:language] [url] [link text] [additional options]1code snippet 以 option:value 的格式指定额外选项，例如：line_number:false first_line:5。 额外选项 描述 默认值 line_number 显示行号 true line_threshold 只有代码块的行数超过该阈值，才显示行数 0 highlight 启用代码高亮 true first_line 指定第一个行号 1 mark 突出显示特定的行，每个值用逗号分隔。使用破折号指定数字范围。例如:mark:1,4-7,10 将标记第1、4至7和10行 - wrap 用 &lt;table&gt; 包裹代码块 true 示例普通的代码块 1alert(&#x27;Hello World!&#x27;); 指定语言 1[rectangle setX: 10 y: 10 width: 20 height: 20]; 在文章中插入代码。 描述1array.map(callback[, thisArg]) 附加说明和网址 描述1.js12_.compact([0, 1, false, 2, &#x27;&#x27;, 3]);=&gt; [1, 2, 3] 6. 评论指定本页所用的评论数据库 1234567giscus: data-repo: BytePioneer-AI/LifeNotes data-mapping: number data-term: 6 二、个性配置1. 文章卡新增字数统计 找到 \\themes\\stellar\\layout\\_partial\\main\\post_list\\post_card.ejs 文件 找到 //meta 处,代码修改后如下： 123456789themes\\stellar\\layout\\_partial\\main\\post_list\\post_card.ejs// metael += &#x27;&lt;div class=&quot;meta cap&quot;&gt;&#x27;;el += &#x27;&lt;span class=&quot;cap&quot; id=&quot;post-meta&quot;&gt;&#x27;;el += icon(&#x27;default: calendar&#x27;)// timeel += `&lt;time datetime=&quot;$&#123;date_xml(post.date)&#125;&quot;&gt;$&#123;date(post.date, config.date_format)&#125;&lt;/time&gt;`&lt;!-- 新增字数统计 新增一行--&gt;el += &#x27;&lt;span class=&quot;post-count&quot;&gt;&amp;nbsp;&#x27;+ wordcount(post.content) +&#x27; 字 &lt;/span&gt;&#x27;;el += &#x27;&lt;/span&gt;&#x27;; 2. 博客列表新增标签显示blog/node_modules/hexo-theme-stellar/layout/_partial/main/post_list/post_card.ejs blog/node_modules/hexo-theme-stellar/layout/_partial/main/post_list/post_card.ejs123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155&lt;%const poster = post.poster;var obj = &#123; image: post.cover&#125;;if (poster) &#123; obj.headline = poster.headline; obj.topic = poster.topic; obj.caption = poster.caption; obj.color = poster.color;&#125;function div_default() &#123; var el = &#x27;&#x27;; el += &#x27;&lt;article class=&quot;md-text&quot; &gt;&#x27;; // 封面 if (obj.image || theme.article.auto_cover) &#123; var cover_url; if (obj.image != undefined) &#123; if (obj.image.includes(&#x27;/&#x27;)) &#123; cover_url = obj.image; &#125; else &#123; cover_url = &#x27;https://source.unsplash.com/1280x640/?&#x27; + obj.image; &#125; &#125; else &#123; // 自动以 tags 作为关键词搜索封面 if (post.tags) &#123; var params = &#x27;&#x27;; post.tags.reverse().forEach((tag, i) =&gt; &#123; if (i &gt; 0) &#123; params += &#x27;,&#x27;; &#125; params += tag.name; &#125;); cover_url = &#x27;https://source.unsplash.com/1280x640/?&#x27; + params; &#125; else &#123; cover_url = &#x27;https://source.unsplash.com/random/1280x640&#x27;; &#125; &#125; if (cover_url) &#123; el += &#x27;&lt;div class=&quot;post-cover&quot;&gt;&#x27;; el += &#x27;&lt;img src=&quot;&#x27; + cover_url + &#x27;&quot;/&gt;&#x27;; el += &#x27;&lt;/div&gt;&#x27;; &#125; &#125; // 标题 el += &#x27;&lt;h2 class=&quot;post-title&quot;&gt;&#x27;; el += post.title ? post.title : date(post.date, config.date_format); el += &#x27;&lt;/h2&gt;&#x27;; // 摘要 el += &#x27;&lt;div class=&quot;excerpt&#x27;; if (theme.plugins.heti?.enable) &#123; el += &#x27; heti&#x27;; &#125; el += &#x27;&quot;&gt;&#x27;; el += &#x27;&lt;p&gt;&#x27;; if (post.excerpt) &#123; el += strip_html(post.excerpt); &#125; else if (post.description) &#123; el += post.description; &#125; else if (post.content &amp;&amp; theme.article.auto_excerpt &gt; 0) &#123; el += truncate(strip_html(post.content), &#123;length: theme.article.auto_excerpt&#125;); &#125; el += &#x27;&lt;/p&gt;&#x27;; el += &#x27;&lt;/div&gt;&#x27;; // meta el += &#x27;&lt;div class=&quot;meta cap&quot; &gt;&#x27;; el += &#x27;&lt;span class=&quot;cap&quot; id=&quot;post-meta&quot; style=&quot;font-size: 0.9rem;&quot;&gt; &#x27;; el += icon(&#x27;default:calendar&#x27;) // time el += `&lt;time datetime=&quot;$&#123;date_xml(post.date)&#125;&quot;&gt;$&#123;date(post.date, config.date_format)&#125;&lt;/time&gt;` el += &#x27;&lt;span class=&quot;post-count&quot;&gt;&amp;nbsp;&#x27;+ wordcount(post.content) +&#x27; 字 &lt;/span&gt;&#x27;; el += &#x27;&lt;/span&gt;&#x27;; // cat if (post.categories &amp;&amp; post.categories.length &gt; 0) &#123; if (post.layout === &#x27;post&#x27; &amp;&amp; post.categories &amp;&amp; post.categories.length &gt; 0) &#123; var cats = []; if (post.categories) &#123; post.categories.forEach((cat, i) =&gt; &#123; cats.push(cat.name); &#125;); &#125; if (cats.length &gt; 0) &#123; let cat = cats.shift(); // 获取原始样式并添加字体大小 let style = category_color(cat); // 删除最后一个字符 style = style.slice(0, -1); style += &#x27;;font-size: 0.9rem&quot;&#x27;; // 添加字体大小并加回引号 el += &#x27;&lt;span class=&quot;cap breadcrumb&quot; &#x27; + style + &#x27;&gt;&#x27;; el += icon(&#x27;default:category&#x27;) el += `&lt;span&gt;$&#123;cat&#125;&lt;/span&gt;` el += &#x27;&lt;/span&gt;&#x27;; &#125; &#125; &#125; // 新增：标签显示 // tags if (post.layout === &#x27;post&#x27; &amp;&amp; post.tags &amp;&amp; post.tags.length &gt; 0) &#123; post.tags.forEach((tag, i) =&gt; &#123; el += &#x27;&lt;span style=&quot;font-size: 0.9rem;margin-right: 4px; border-radius: 7px;&quot;&gt;&#x27;; el += &#x27;&lt;span style=&quot;color: #1eb4ef; margin-right: 2px;&quot;&gt;#&lt;/span&gt;&#x27;; el += &#x27;&lt;span style=&quot;color: #1eb4ef;&quot;&gt;&#x27; + tag.name + &#x27;&lt;/span&gt;&#x27;; el += &#x27;&lt;/span&gt;&#x27;; &#125;); &#125; if (post.sticky) &#123; el += `&lt;span class=&quot;pin&quot;&gt;$&#123;icon(&#x27;default:pin&#x27;)&#125;&lt;/span&gt;` &#125; el += &#x27;&lt;/div&gt;&#x27;; el += &#x27;&lt;/article&gt;&#x27;; return el;&#125;function div_photo() &#123; var el = &#x27;&#x27;; el += &#x27;&lt;div class=&quot;cover&quot;&gt;&#x27;; el += &#x27;&lt;img src=&quot;&#x27; + obj.image + &#x27;&quot;/&gt;&#x27;; if (obj.headline || obj.topic || obj.caption) &#123; el += &#x27;&lt;div class=&quot;cover-info&quot;&#x27;; if (obj.color) &#123; el += &#x27;style=&quot;color:&#x27; + obj.color + &#x27;&quot;&#x27;; &#125; if (obj.topic) &#123; el += &#x27;position=&quot;top&quot;&gt;&#x27;; &#125; else &#123; el += &#x27;position=&quot;bottom&quot;&gt;&#x27;; &#125; if (obj.topic) &#123; el += &#x27;&lt;div class=&quot;cap&quot;&gt;&#x27; + obj.topic + &#x27;&lt;/div&gt;&#x27;; &#125; if (obj.headline) &#123; el += &#x27;&lt;div class=&quot;title&quot;&gt;&#x27; + obj.headline + &#x27;&lt;/div&gt;&#x27;; &#125; if (obj.caption) &#123; el += &#x27;&lt;div class=&quot;cap&quot;&gt;&#x27; + obj.caption + &#x27;&lt;/div&gt;&#x27;; &#125; el += &#x27;&lt;/div&gt;&#x27;; &#125; el += &#x27;&lt;/div&gt;&#x27;; return el;&#125;function div() &#123; if (obj.image &amp;&amp; obj.image.length &gt; 0 &amp;&amp; obj.headline != undefined) &#123; return div_photo(); &#125; return div_default();&#125;%&gt;&lt;%- div() %&gt; 3. 文章底部添加字数统计 安装 hexo-wordcount 插件：npm i hexo-wordcount --save themes/stellar/layout/_partial/main/footer.ejs 文件中，找到//footer: 123456789101112131415161718192021222324252627282930313233343536373839&lt;%const content = theme.footer.content?.replace(&#x27;&#123;author.name&#125;&#x27;, (config.author || &#x27;Anonymity&#x27;))?.replace(&#x27;&#123;theme.name&#125;&#x27;, stellar_info(&#x27;name&#x27;))?.replace(&#x27;&#123;theme.version&#125;&#x27;, stellar_info(&#x27;version&#x27;))?.replace(&#x27;&#123;theme.tree&#125;&#x27;, stellar_info(&#x27;tree&#x27;))function layoutDiv() &#123; var el = &#x27;&#x27; el += `&lt;footer class=&quot;page-footer$&#123;scrollreveal(&#x27; &#x27;)&#125; footnote&quot;&gt;` el += &#x27;&lt;hr&gt;&#x27; // sitemap if (theme.footer.sitemap &amp;&amp; Object.keys(theme.footer.sitemap).length &gt; 0) &#123; el += &#x27;&lt;div class=&quot;sitemap&quot;&gt;&#x27; for (let group of Object.keys(theme.footer.sitemap)) &#123; let items = theme.footer.sitemap[group] if (items == undefined || items.length == 0) &#123; continue &#125; el += &#x27;&lt;div class=&quot;sitemap-group&quot;&gt;&#x27; el += &#x27;&lt;span class=&quot;fs15&quot;&gt;&#x27; + group + &#x27;&lt;/span&gt;&#x27; items.forEach((item, i) =&gt; &#123; el += &#x27;&lt;a href=&quot;&#x27; + url_for(md_link(item)) + &#x27;&quot;&gt;&#x27; el += __(md_text(item)) el += &#x27;&lt;/a&gt;&#x27; &#125;); el += &#x27;&lt;/div&gt;&#x27; &#125; el += &#x27;&lt;/div&gt;&#x27; &#125; // footer el += &#x27;&lt;div class=&quot;text&quot;&gt;&#x27; if (content) &#123; el += markdown(content) &#125; el += &#x27;&lt;div style=&quot;font-size: 1rem;text-align: center; margin: 1rem 0; color:var(--text-p4);&quot;&gt;&#x27; el += &#x27;发表了 &#x27; + site.posts.length + &#x27; 篇文章 🔸 总计 &#x27; + totalcount(site) + &#x27; 字&#x27; el += &#x27;&lt;/div&gt;&#x27; el += &#x27;&lt;/div&gt;&lt;/footer&gt;&#x27; return el&#125;%&gt;&lt;%- layoutDiv() %&gt; 4. 编辑本页功能在右侧添加编辑本页功能。 在config中添加配置，也可以不添加这个，直接写死到toc.ejs中 _config.stellar.yml123456edit_page: enable: true repo: BytePioneer-AI/blog branch: main base_path: source edit_text: 编辑本页 修改主题代码。新增的代码：突出显示特定的行 themes/stellar/layout/_partial/widgets/toc.ejs12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&lt;%function layoutTocBody() &#123; if (toc(page.content).length &gt; 0) &#123; return toc(page.content, &#123; list_number: item.list_number, min_depth: item.min_depth, max_depth: item.max_depth &#125;) &#125; return &#x27;&#x27;&#125;function layoutTocHeader(title) &#123; var el = &#x27;&#x27; el += `&lt;div class=&quot;widget-header dis-select&quot;&gt;` el += `&lt;span class=&quot;name&quot;&gt;$&#123;title || __(&quot;meta.toc&quot;)&#125;&lt;/span&gt;` el += `&lt;a class=&quot;cap-action&quot; onclick=&quot;sidebar.toggleTOC()&quot; &gt;$&#123;icon(&#x27;default:rightbar&#x27;)&#125;&lt;/a&gt;` el += `&lt;/div&gt;` return el&#125;function layoutToc(fallback) &#123; const tocBody = layoutTocBody() if (tocBody.length == 0) &#123; return &#x27;&#x27; &#125; var el = &#x27;&#x27; el += `&lt;widget class=&quot;widget-wrapper$&#123;scrollreveal(&#x27; &#x27;)&#125; toc&quot; id=&quot;data-toc&quot; collapse=&quot;$&#123;item.collapse&#125;&quot;&gt;` el += layoutTocHeader() el += `&lt;div class=&quot;widget-body&quot;&gt;` el += tocBody el += `&lt;/div&gt;` el += `&lt;/widget&gt;` return el&#125;function layoutDiv(fallback) &#123; console.log(page) const editBtn = partial(&#x27;components/edit&#x27;, &#123;map: item.edit_this_page&#125;) const tocBody = layoutTocBody() if (tocBody.trim().length == 0 &amp;&amp; editBtn.trim().length == 0) &#123; return &#x27;&#x27; &#125; var el = &#x27;&#x27; el += `&lt;widget class=&quot;widget-wrapper$&#123;scrollreveal(&#x27; &#x27;)&#125; toc&quot; id=&quot;data-toc&quot; collapse=&quot;$&#123;item.collapse&#125;&quot;&gt;` if (tocBody.length &gt; 0) &#123; el += layoutTocHeader() el += `&lt;div class=&quot;widget-body&quot;&gt;` el += tocBody el += `&lt;/div&gt;` &#125; el += `&lt;div class=&quot;widget-footer&quot;&gt;` el += editBtn el += `&lt;a class=&quot;top&quot; onclick=&quot;util.scrollTop()&quot;&gt;` el += icon(&#x27;default:upup&#x27;) el += `&lt;span&gt;$&#123;__(&#x27;btn.top&#x27;)&#125;&lt;/span&gt;` el += `&lt;/a&gt;` if (theme.comments.service &amp;&amp; theme.comments.service.length &gt; 0) &#123; if (page.comments == undefined || page.comments != false) &#123; el += `&lt;a class=&quot;buttom&quot; onclick=&quot;util.scrollComment()&quot;&gt;` el += icon(&#x27;default:tocomment&#x27;) el += `&lt;span&gt;$&#123;__(&#x27;btn.comments&#x27;)&#125;&lt;/span&gt;` el += `&lt;/a&gt;` &#125; &#125; if (theme.edit_page?.enable &amp;&amp; page.source) &#123; const repo = theme.edit_page.repo const branch = theme.edit_page.branch || &#x27;main&#x27; const basePath = theme.edit_page.base_path || &#x27;&#x27; const editUrl = `https://github.com/$&#123;repo&#125;/edit/$&#123;branch&#125;/$&#123;basePath&#125;/$&#123;page.source&#125;` el += `&lt;a href=&quot;$&#123;editUrl&#125;&quot; target=&quot;_blank&quot;&gt;` el += icon(&#x27;default:edit&#x27;) el += `&lt;span&gt;$&#123;theme.edit_page.edit_text || __(编辑本页)&#125;&lt;/span&gt;` el += `&lt;/a&gt;` &#125; el += `&lt;/div&gt;` el += `&lt;/widget&gt;` return el&#125;%&gt;&lt;%- layoutDiv() %&gt; 5. 代码块滚动条来自 在 themes\\stellar\\source\\js\\ 中新建 custom.js 1234567891011121314151617181920// 给超长代码块增加滚动条function adjustCodeBlockHeight() &#123; document.addEventListener(&quot;DOMContentLoaded&quot;, function () &#123; // 选择所有的.md-text元素 var codeBlocks = document.querySelectorAll(&#x27;.md-text&#x27;); // 遍历每个.md-text元素 codeBlocks.forEach(function (block) &#123; // 检查是否包含.highlight类的子元素，且父元素高度超过500px var highlightBlocks = block.querySelectorAll(&#x27;.highlight&#x27;); highlightBlocks.forEach(function (highlightBlock) &#123; if (highlightBlock.clientHeight &gt; 800) &#123; highlightBlock.style.maxHeight = &#x27;300px&#x27;; highlightBlock.style.overflow = &#x27;auto&#x27;; &#125; &#125;); &#125;); &#125;);&#125;adjustCodeBlockHeight() 在 _config.yml 文件中，最后一行加入以下指令： 12345inject: script: # 自定义js - &lt;script type=&quot;text/javascript&quot; src=&quot;/js/custom.js?1&quot;&gt;&lt;/script&gt; - &lt;script src=&quot;/js/custom.js?1&quot;&gt;&lt;/script&gt; 需要注意的是，Stellar 主题有 tabs 分栏容器，如果在容器中写入长代码，这段 js 是不生效的。因为这时候生成的 HTML 结构可能与原始代码块不同，导致 JavaScript 选择器无法正确找到目标元素。解决方法也很简单，可以直接在 Markdown 文件中使用内联样式来设置代码块的最大高度和滚动条。 1234567&lt;div style=&quot;max-height: 300px; max-width: 100%; overflow: auto;&quot;&gt; ```javascript // 这里是你的代码 function example() &#123; console.log(&quot;Hello, world!&quot;); &#125;&lt;/div&gt; 三、部署GitHub部署+绑定域名 1 双仓库策略 blog为私有仓库，存放本博客项目 LifeNotes为公开仓库，存放生产文件，即hexo的public文件夹 2 配置 GitHub Actions1. 配置 GitHub Actions 其中user.name、user.email请替换为自己的。 创建文件：.github&#x2F;workflows&#x2F;deploy.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253name: ChongWen&#x27;s Blog CI/CD # 脚本 workflow 名称on: push: branches: [main, master] # 当监测 main,master 的 push paths: # 监测所有 source 目录下的文件变动，所有 yml,json 后缀文件的变动。 - &#x27;*.json&#x27; - &#x27;**.yml&#x27; - &#x27;**/source/**&#x27;jobs: blog: # 任务名称 timeout-minutes: 30 # 设置 30 分钟超时 runs-on: ubuntu-latest # 指定最新 ubuntu 系统 steps: - uses: actions/checkout@v4 # 拉取仓库代码 - uses: actions/setup-node@v4 # 设置 node.js 环境 - name: Cache node_modules # 缓存 node_modules，提高编译速度，毕竟每月只有 2000 分钟。 uses: actions/cache@v4 # 亲测 Github 服务器编译速度比我自己电脑都快，如果每次构建按5分钟计算，我们每个月可以免费部署 400 次，Github yyds！！！ env: cache-name: cache-node-modules with: path: ~/.npm key: $&#123;&#123; runner.os &#125;&#125;-build-$&#123;&#123; env.cache-name &#125;&#125;-$&#123;&#123; hashFiles(&#x27;**/package-lock.json&#x27;) &#125;&#125; restore-keys: | $&#123;&#123; runner.os &#125;&#125;-build-$&#123;&#123; env.cache-name &#125;&#125;- $&#123;&#123; runner.os &#125;&#125;-build- $&#123;&#123; runner.os &#125;&#125;- - name: Init Node.js # 安装源代码所需插件 run: | npm install echo &quot;init node successful&quot; - name: Install Hexo-cli # 安装 Hexo run: | npm install -g hexo-cli --save echo &quot;install hexo successful&quot; - name: Build Blog # 编译创建静态博客文件 run: | hexo clean hexo generate # 确保 CNAME 文件存在 echo &quot;chongwenz.cn&quot; &gt; public/CNAME echo &quot;build blog successful&quot; - name: Deploy ChongWen&#x27;s Blog # 设置 git 信息并推送静态博客文件 run: | git config --global user.name &quot;BytePioneer-AI&quot; git config --global user.email &quot;28417416@qq.com&quot; hexo deploy - name: Verify Git Identity run: | echo &quot;Current Git user.name: $(git config --global user.name)&quot; echo &quot;Current Git user.email: $(git config --global user.email)&quot; - run: echo &quot;Deploy Successful!&quot; 2. 创建token、配置config 网址：https://github.com/settings/tokens/new。 选择权限：repo、workflow _config.yml12345678910111213deploy: \\- type: git​ repository:​ github: https://你的token@github.com/BytePioneer-AI/LifeNotes.git,main​ name:​ email: 3. 配置私有仓库 网址：https://github.com/用户名/仓库名/settings/actions Actions permissions：Allow all actions and reusable workflows Workflow permissions：Read and write permissions和Allow GitHub Actions to create and approve pull requests 4. 配置公共仓库 网址：https://github.com/用户名/仓库名/settings/pages 配置到这里，可以测试action情况、Github静态页面情况。将代码提交到私有仓库，可在Github上查看action情况，如果错误也可以根据log去修改。通过后，可查看公告仓库，是否有新的提交。然后可访问：https://BytePioneer-AI.github.io/LifeNotes 3. 域名绑定设置 DNS配置： 12# DNS记录CNAME @ → BytePioneer-AI.github.io Hexo配置： 123# _config.ymlurl: https://chongwenz.cnroot: / 12# source/CNAME 新建文件将我们的自定义域名填写进去。 GitHub设置： 进入 LifeNotes 仓库 Settings → Pages Custom domain 输入 chongwenz.cn 勾选 “Enforce HTTPS” 4. 验证部署123456# 本地测试hexo clean &amp;&amp; hexo g &amp;&amp; hexo s# 查看部署状态https://github.com/BytePioneer-AI/blog/actionshttps://chongwenz.cn","tags":["博客配置"],"categories":["技术"]},{"title":"初始篇","path":"/Essays/20250214初始篇/","content":"关于创建个人博客。关于自己。 关于博客日记的习惯 ​\t在初、高中时，我一直保持着写日记的习惯。在写日记时会产生很多的想法，引发思考。尤其在高三时，在高度的课程压力下，心中的想法更多，也没有人倾诉，恨不得将所有的事情都写到日记本上，做了什么、学了什么、想了什么，在日记本上一遍一遍的鼓励自己。上了大学，从几天一写到几周一写再到几个月都不写，也就没有再写下去了。可能是那时没有了以前的烦恼，也可能是交了女朋友有人可以诉说了。 ​\t也有几次捡起过写日记的习惯，但也没怎么坚持就放弃了。还是想去写一下的，到不是为了记录生活的见闻，主要是想把当时自己的想法记下来。经常有很多想法，但过段时间就忘，一些灵感、生活感悟也就在那一瞬间，不通过笔记来深度思考，也就忘了也就不去深度思考了。 个人博客的向往 ​\t前年我看到一位优秀学弟的博客网站，样式很不错，技术相关的内容也很好。不过那时还没有产生做自己博客的想法，如果发技术笔记，就直接在CSDN上了，CSDN上存了挺多笔记、题解的。再后来，陆陆续续看到了一些人的博客网站，有些向往在互联网上有一个自己的平台，可以记心中的想法，也可以记一些易忘的笔记。 ​\t直到最近，cursor到期了，再搜索新的白嫖方法时，看到了一个博客https://wmhwiki.cn 。感觉真的很好。后面就拉了这个作者开源的项目，他用的是VitePress，反复考虑后感觉这个博客和技术路线不太适合。后面就看到了xaoxuu的stelllar-hexo博客https://xaoxuu.com ，简洁明了。 ​\t开始实施 ​\t正好最近几天不工作，有想拥有个人博客的原因，也有消磨这几天时间的原因，就开始做了。花了几天时间，对stellar做了一些修改，也部署并托管到了GitHub，配置了Action。发现真是特别方便，也不需要自己去准备服务器，最后买域名，哈哈哈哈我直接买了10年，反正有GitHub托管着，也不会掉（除了未来Github封国内IP），不用担心未来的硬件、运维成本。 关于我对自己基础能力的思考 我父亲动手能力很强，大小电路、水管、各种工具、电焊、修东西都是他去做。但有时逻辑能力会跟不上，尤其这几年年龄增长。 我母亲商务能力很强，包括社交能力、逻辑能力，她总能和一些大大小小的人物通畅的聊天，在经济困难时也有抗压能力。但受限于学识，很多事情她有基础能力但没有相应的知识。她对下面的孩子，包括侄女侄子外甥什么的都是很好的，只是风格上比较强势。 不知是遗传还是生活上被他们影响，他们俩的优点缺点我都有，但优点是他们自身优点的二分之一。 我有一定的动手能力，我可以用比较快的速度学习一个知识点、完成一个工作，但是我也遇到过动手能力很强的人，他们比我更快，更不容易出错。 我也有一定的商务能力、逻辑能力，但和动手能力似的，我也是不及我母亲，我的逻辑能力会让我看清楚一些事情，但社交沟通能力有限，远没有控场能力。 但似乎比较好的是，虽然我的动手能力、逻辑能力、社交能力没有我父亲、母亲好，但同时也具备这些能力的部分，这是我的优势。有一定的逻辑能力能听懂领导的任务，有一定的动手能力能完成领导的安排。 对自己性格的思考 我是山东人，在时尚和传统之间，我比较传统。也喜欢在规则内行事，轻易不逾越。 大学以前心智不成熟，有些时候会感觉父母没有什么，和大多数人一样的比较普通。但在现在，毕业工作2年了，发现自己的很多地方确是远不及爸妈。 在感情上，大部分时候比较强势，可能也是受到了我母亲的影响。 我会发现自己身上有很多缺点，性格上也是。但同时，也会喜欢身上的某些性格特点。","tags":["我"],"categories":["随笔"]},{"title":"关于","path":"/about/index.html","content":"友链关于昵称简介 关于本站 本站刚建立，没有去其他站点留言，似乎也不会有小伙伴过来。如果真有小伙伴过来，可以在下面留言关于您的网站。"},{"title":"收藏","path":"/bookmark/index.html","content":"暂无"},{"title":"探索","path":"/explore/index.html","content":"暂无"},{"title":"友链","path":"/friends/index.html","content":"友链关于小伙伴们如果宇宙中真有什么终极的逻辑，那就是我们终有一天会在舰桥上重逢，直到生命终结。 本站刚建立，没有去其他站点留言，似乎也不会有小伙伴过来。如果真有小伙伴过来，可以在下面留言关于您的网站。"},{"title":"说说测试","path":"/life/index.html","content":""},{"path":"/llm-timeline/demo.html","content":"角色你是一个专门负责AI领域动态追踪和数据结构化的专家。你的任务是根据我提供的关于某个AI模型的背景信息（如官方公告、技术论文、社区评测等），严格按照下面的JSON规范，生成一个该模型的timeline数据条目。 输入信息源 已知信息：[之前提供的目标模型的背景信息、文章链接或总结] 生成任务请根据上述信息源，为模型生成一个JSON对象。 LLM 生成规范：timeline-data.json（单条目生成）本规范用于指导大模型一次仅生成“一个模型发布条目”的 JSON 对象。请严格遵循以下格式与约束，以确保页面可正确渲染与筛选。 1) 任务与产物 产物: 一个 JSON 对象（UTF-8、无注释、无多余字段、无尾随逗号）。 2) 严格输出要求（必须遵守） 仅输出合法 JSON 对象，不要输出任何解释性文字。 URL 使用 https:// 优先；如无官方链接，可留空字符串 &quot;&quot;。 3) 字段与约束（逐项） date 类型: string 格式: YYYY-MM-DD 或 YYYY-MM（零填充，例如 2025-07-05、2025-07） 用途: 尽量到日。 title 类型: string 规则: 普通文本；例如：&quot;OpenAI GPT-5&quot; text 类型: string 格式: Markdown 文本（支持标题、列表、加粗、行内代码、代码块） 说明: 注意转义 JSON 内部的引号与换行。 写作规范： 结构（推荐，按需取用）： 摘要：用一两句话概述模型定位与看点。 模型规格与架构 性能与实测表现 优势 &#x2F; 劣势（可选） 适用场景 &#x2F; 备注（可选） 列表：使用 - 或 * 作为项目符号，同一段内保持一致；二级列表缩进两个空格。 小节标题：可用加粗+全角冒号的样式（如 **模型规格与架构：**），或 ### 三级标题，两者择一保持统一。 专有名词与型号：用反引号包裹（如 gpt-5-main），便于阅读。 标点：使用中文全角标点（冒号、逗号、句号）；数字与单位之间不加空格（如 128K、1M）。 行文：客观、中性；主观评价请置于“优势&#x2F;劣势”或“备注”小节。 代码块：仅在展示配置&#x2F;指令&#x2F;示例时使用。若非代码&#x2F;数据，请用语言标记 text，避免误标为 json 造成歧义。 安全与兼容：不嵌入图片&#x2F;HTML 标签；避免未转义的双引号。 示例模板（可直接复用）：1234567891011121314151617181920**摘要：** 用一两句话概述模型定位与看点。**模型规格与架构：**- 参数量：...- 架构/范式：...- 上下文：...**性能与实测表现：**- 基准：...- 实测：...**优势：**- ...**劣势：**- ...**适用场景 / 备注：**- ... modelSize 类型: string 语法（主尺寸 + 可选补充）： 主尺寸（可多项，逗号+空格分隔）：&quot;120B&quot;、&quot;1.7B&quot;、&quot;120B, 20B&quot; 可在主尺寸后添加括号补充：&quot;120B (总计 117B, 激活 5.1B), 20B (总计 21B, 激活 3.6B)&quot; 若为框架或无参数量：用空字符串 &quot;&quot; modelType 类型: string 内容: 关键词或组合，使用 、 或 , 分隔，用于多选模糊筛选。 建议包含的受控关键词（可并列择一或多项）： 文档解析模型、多模态、语言、图像生成、视频生成、代码、其他（为空或不属于上述类时） openSource 类型: boolean | null 取值: true 表示开源，false 表示闭源，null。 contextWindow 类型: string 格式: 数值+单位；如 &quot;128K&quot;、&quot;1M&quot;、&quot;256K (可扩展至1M)&quot; officialDoc 类型: string 格式: URL，如无可填空字符串 &quot;&quot; evaluation 类型: string 内容: 简短评述或要点，允许 Markdown。 4) JSON Schema1234567891011121314151617&#123; &quot;$schema&quot;: &quot;http://json-schema.org/draft-07/schema#&quot;, &quot;type&quot;: &quot;object&quot;, &quot;required&quot;: [&quot;date&quot;, &quot;title&quot;, &quot;text&quot;], &quot;additionalProperties&quot;: false, &quot;properties&quot;: &#123; &quot;date&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;pattern&quot;: &quot;^\\\\d&#123;4&#125;-\\\\d&#123;2&#125;(-\\\\d&#123;2&#125;)?$&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;minLength&quot;: 1 &#125;, &quot;text&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;minLength&quot;: 1 &#125;, &quot;modelSize&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;modelType&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;openSource&quot;: &#123; &quot;type&quot;: [&quot;boolean&quot;, &quot;null&quot;] &#125;, &quot;contextWindow&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;officialDoc&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;evaluation&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125; &#125;&#125; 5) 生成步骤 收集并规范化 date（YYYY-MM-DD 或 YYYY-MM）。 用 Markdown 撰写 text；确保转义 JSON 字符与换行。 将一个或多个主尺寸写入 modelSize，用 &quot;, &quot; 分隔；括号内补充可选。 modelType 选择或组合受控关键词；可添加补充词汇。 openSource 取 true&#x2F;false&#x2F;null（未知用 null 或省略）。 仅输出该对象的 JSON；不要输出任何额外文字或数组包裹。 7) 最小可用示例1234567891011&#123; &quot;date&quot;: &quot;2025-08-08&quot;, &quot;title&quot;: &quot;OpenAI GPT-5&quot;, &quot;text&quot;: &quot;OpenAI 于 2025-08-08 发布...&quot;, &quot;modelSize&quot;: &quot;120B, 20B&quot;, &quot;modelType&quot;: &quot;多模态&quot;, &quot;openSource&quot;: false, &quot;contextWindow&quot;: &quot;400K&quot;, &quot;officialDoc&quot;: &quot;https://openai.com/gpt-5/&quot;, &quot;evaluation&quot;: &quot;&quot;&#125; 注意事项（必须严格遵守） 只输出JSON：绝对不要在JSON对象前后或内部添加任何解释性文字、评论或markdown格式符（如 json ... ）。 格式纯净：确保JSON内部无注释、无多余字段、无尾随逗号。 内容客观：text字段中，除“优势&#x2F;劣势”部分，其余描述应保持客观中立。"},{"title":"大模型发布时间轴","path":"/llm-timeline/index.html","content":"/* 隐藏右侧栏 */ .l_right { display: none !important; } .l_body { display: grid !important; grid-template-columns: auto 1fr !important; } .l_center { width: 100% !important; max-width: none !important; } /* 顶部发布时间节点图样式 */ .release-chart-wrapper { max-width: 1400px; margin: 1.2rem auto 0.5rem auto; padding: 0 2rem; } .release-chart { width: 100%; height: 140px; background: linear-gradient(180deg, #fbfdff, #f6f8ff); border-radius: 12px; box-shadow: 0 2px 10px rgba(86,152,195,0.12); border: 1px solid rgba(86, 152, 195, 0.2); position: relative; overflow: hidden; } .release-chart svg { width: 100%; height: 100%; display: block; } .release-chart .tooltip { position: absolute; pointer-events: none; background: rgba(33, 39, 55, 0.95); color: #fff; font-size: 12px; padding: 6px 8px; border-radius: 6px; transform: translate(-50%, -120%); white-space: nowrap; z-index: 10; display: none; } /* 内层可横向扩展画布 */ .release-chart .rc-inner { position: absolute; left: 0; top: 0; height: 100%; will-change: transform; } /* 左右浅色移动按钮 */ .release-chart .pan-btn { position: absolute; top: 0; bottom: 0; width: 42px; display: flex; align-items: center; justify-content: center; color: #2f6bd8; font-weight: 700; font-size: 18px; border: none; background: transparent; cursor: pointer; z-index: 11; transition: opacity 0.2s ease; } .release-chart .pan-btn::before { content: ''; position: absolute; top: 0; bottom: 0; left: 0; right: 0; background: linear-gradient(90deg, rgba(102,125,233,0.08), rgba(102,125,233,0)); pointer-events: none; } .release-chart .pan-left { left: 0; } .release-chart .pan-left::before { left: 0; right: auto; background: linear-gradient(90deg, rgba(102,125,233,0.12), rgba(102,125,233,0)); } .release-chart .pan-right { right: 0; } .release-chart .pan-right::before { left: auto; right: 0; background: linear-gradient(270deg, rgba(102,125,233,0.12), rgba(102,125,233,0)); } .release-chart .pan-btn:hover { opacity: 0.95; } .release-chart .pan-btn[disabled] { opacity: 0.35; cursor: default; } /* 按钮的箭头字符 */ .release-chart .pan-btn span { position: relative; z-index: 1; } /* 类型多选筛选 与 控制栏 */ .type-filter { display: flex; flex-wrap: wrap; gap: 8px; } .type-chip { display: inline-block; padding: 4px 10px; border: 1px solid rgba(86,152,195,0.35); border-radius: 999px; cursor: pointer; font-size: 12px; color: #3c6a93; background: #f8fbff; user-select: none; } .type-chip.selected { color: #fff; background: linear-gradient(135deg, #5698c3, #667eea); border-color: transparent; } .control-bar { display: flex; align-items: center; gap: 10px; flex-wrap: wrap; margin-bottom: 8px; } .control-bar .search-input { flex: 0 0 220px; max-width: 220px; height: 32px; padding: 0 10px; border: 1px solid rgba(86,152,195,0.35); border-radius: 8px; font-size: 14px; } .control-bar .clear-btn { height: 32px; padding: 0 10px; border: 1px solid rgba(86,152,195,0.35); border-radius: 8px; background: linear-gradient(180deg,#fbfdff,#f6f8ff); cursor: pointer; color: #3c6a93; } .control-bar .size-select { height: 32px; min-width: 140px; padding: 0 28px 0 10px; border: 1px solid rgba(86,152,195,0.35); border-radius: 8px; background-color: #fff; color: #365d7d; font-size: 13px; cursor: pointer; appearance: none; -webkit-appearance: none; -moz-appearance: none; background-image: url(\"data:image/svg+xml;utf8,\"); background-repeat: no-repeat; background-position: right 8px center; background-size: 12px; transition: border-color 0.2s ease, box-shadow 0.2s ease; } .control-bar .size-select:hover { border-color: rgba(86,152,195,0.6); } .control-bar .size-select:focus { outline: none; border-color: #5698c3; box-shadow: 0 0 0 3px rgba(86,152,195,0.18); } .control-bar .size-select option { color: #2b4a63; } .control-bar .type-filter { margin-left: 6px; } /* 自定义下拉 */ .size-select-custom { position: relative; min-width: 160px; height: 32px; line-height: 32px; padding: 0 28px 0 10px; border: 1px solid rgba(86,152,195,0.35); border-radius: 8px; background: #fff; color: #365d7d; font-size: 13px; cursor: pointer; } .size-select-custom::after { content: ''; position: absolute; right: 8px; top: 50%; transform: translateY(-50%); width: 12px; height: 12px; background-image: url(\"data:image/svg+xml;utf8,\"); background-size: 12px 12px; background-repeat: no-repeat; opacity: 0.85; } .size-select-custom.open { border-color: #5698c3; box-shadow: 0 0 0 3px rgba(86,152,195,0.18); } .size-dropdown { position: absolute; top: calc(100% + 6px); left: 0; right: 0; background: #fff; border: 1px solid rgba(86,152,195,0.35); border-radius: 8px; box-shadow: 0 6px 18px rgba(0,0,0,0.08); z-index: 20; padding: 4px; display: none; } .size-dropdown.open { display: block; } .size-option { padding: 0px 10px; border-radius: 6px; color: #2b4a63; font-size: 13px; } .size-option:hover { background: #f1f6ff; } .size-option.active { background: linear-gradient(135deg, #5698c3, #667eea); color: #fff; } .size-option:not(:last-child) { margin-bottom: 4px; } /* 自定义目录样式 */ .custom-toc { position: fixed; left: 20px; top: 200px; width: 250px; max-height: 500px; /* background: rgba(255, 255, 255, 0.95); */ backdrop-filter: blur(10px); border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); z-index: 1000; border: 1px solid rgba(255, 255, 255, 0.2); display: flex; flex-direction: column; overflow: hidden; } .custom-toc-header { flex-shrink: 0; padding: 1rem 1rem 0.5rem 1rem; background: transparent; } .custom-toc h3 { font-size: 1.1rem; font-weight: 600; color: #5698c3; margin: 0 0 0.5rem 0; padding-bottom: 0.3rem; border-bottom: 1px solid rgba(86, 152, 195, 0.3); } .custom-toc-content { flex: 1; overflow-y: auto; padding: 0 1rem 1rem 1rem; scrollbar-width: thin; scrollbar-color: rgba(86, 152, 195, 0.6) rgba(86, 152, 195, 0.1); } /* 自定义滚动条样式 - Webkit浏览器 */ .custom-toc-content::-webkit-scrollbar { width: 6px; } .custom-toc-content::-webkit-scrollbar-track { background: rgba(86, 152, 195, 0.1); border-radius: 3px; margin: 4px 0; } .custom-toc-content::-webkit-scrollbar-thumb { background: linear-gradient(180deg, #5698c3, #667eea); border-radius: 3px; transition: all 0.3s ease; } .custom-toc-content::-webkit-scrollbar-thumb:hover { background: linear-gradient(180deg, #667eea, #764ba2); transform: scaleX(1.2); } .custom-toc-content::-webkit-scrollbar-thumb:active { background: linear-gradient(180deg, #4a90e2, #5698c3); } .custom-toc ul { list-style: none; margin: 0; padding: 0; } .custom-toc li { margin-bottom: 0.3rem; } .custom-toc a { display: block; padding: 0.4rem 0.6rem; color: #666; text-decoration: none; border-radius: 8px; transition: all 0.3s ease; font-size: 0.95rem; line-height: 1.4; } .custom-toc a:hover { background: #f8f9fa; color: #5698c3; transform: translateX(3px); } .custom-toc a.active { background: linear-gradient(135deg, #5698c3, #667eea) !important; color: white !important; transform: translateX(3px) !important; font-size: 0.8rem !important; padding: 0.6rem 0.8rem !important; } /* 确保非活跃状态的样式重置 */ .custom-toc a:not(.active) { background: transparent !important; color: #666 !important; transform: translateX(0) !important; font-size: 0.8rem !important; padding: 0.4rem 0.6rem !important; } .custom-toc a:not(.active):hover { background: #f8f9fa !important; color: #5698c3 !important; transform: translateX(3px) !important; } /* 时间轴样式 */ .timeline-container { position: relative; max-width: 1400px; margin: 2rem auto; padding: 0 2rem; } /* 评价样式 */ .timeline-evaluation { background: linear-gradient(135deg, #f8f9ff, #f0f4ff); border-left: 4px solid #5698c3; padding: 1rem 1.2rem; margin: 1rem 0; border-radius: 8px; position: relative; box-shadow: 0 2px 4px rgba(86, 152, 195, 0.1); } .timeline-evaluation p { font-size:0.98rem; padding:0; margin:0; } .timeline-evaluation::before { position: absolute; top: 1rem; left: -12px; /* 将图标放在边框外侧 */ font-size: 1.2rem; background: white; padding: 0.2rem; border-radius: 50%; box-shadow: 0 1px 3px rgba(0,0,0,0.1); z-index: 1; } .timeline-evaluation-label { font-size: 1rem; font-weight: 600; color: #5698c3; text-transform: uppercase; letter-spacing: 0.5px; } .timeline-evaluation-text { color: #4a5568; font-style: italic; line-height: 1.6; margin: 0; font-size: 0.95rem; } /* Markdown 内容样式 */ .timeline-text code, .timeline-evaluation-text code { background: #f1f5f9; color: #e11d48; padding: 0.2rem 0.4rem; border-radius: 4px; font-size: 0.9em; font-family: 'Consolas', 'Monaco', 'Courier New', monospace; } .timeline-text strong, .timeline-evaluation-text strong { color: #1e293b; font-weight: 600; } .timeline-text em, .timeline-evaluation-text em { color: #64748b; font-style: italic; } .timeline-text a, .timeline-evaluation-text a { color: #5698c3; text-decoration: none; border-bottom: 1px solid rgba(86, 152, 195, 0.3); transition: all 0.3s ease; } .timeline-text a:hover, .timeline-evaluation-text a:hover { color: #667eea; border-bottom-color: #667eea; } .timeline-container::before { content: ''; position: absolute; left: 50%; top: 0; bottom: 0; width: 4px; background: linear-gradient(to bottom, #5698c3, #667eea); transform: translateX(-50%); border-radius: 2px; } .timeline-item { position: relative; margin-bottom: 4rem; width: 100%; } .timeline-item:nth-child(odd) .timeline-content { margin-left: 0; margin-right: calc(50% + 2rem); text-align: left; } .timeline-item:nth-child(even) .timeline-content { margin-left: calc(50% + 2rem); margin-right: 0; text-align: left; } .timeline-dot { position: absolute; left: 50%; top: 2rem; width: 20px; height: 20px; background: #5698c3; border: 4px solid white; border-radius: 50%; transform: translateX(-50%); z-index: 2; box-shadow: 0 0 0 4px rgba(86, 152, 195, 0.2); } .timeline-content { background: white; padding: 1.5rem; padding-left: 2rem; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); transition: all 0.3s ease; position: relative; } .timeline-content:hover { transform: translateY(-5px); box-shadow: 0 8px 25px rgba(0,0,0,0.15); } .timeline-content::before { content: ''; position: absolute; top: 2rem; width: 0; height: 0; border: 12px solid transparent; } .timeline-item:nth-child(odd) .timeline-content::before { right: -24px; border-left-color: white; } .timeline-item:nth-child(even) .timeline-content::before { left: -24px; border-right-color: white; } .timeline-date { display: block; /* color: #4f46e5; */ color: #5698c3; font-size: 1.1rem; font-weight: 800; margin-bottom: 0.1rem; padding: 0; background: none; } .timeline-title { font-size: 1.3rem; font-weight: 700; color: #333; padding:0; margin:0; margin-bottom: 0.1rem; display: flex; align-items: center; gap: 8px; } .badge { display: inline-block; padding: 2px 8px; border-radius: 999px; font-size: 12px; font-weight: 700; letter-spacing: 0.5px; line-height: 1.6; border: 1px solid transparent; } .badge-open { color: #146c2e; background: #e8f5e9; border-color: #b7e0c2; } .badge-closed { color: #7a2e2e; background: #fff0f0; border-color: #f4c7c7; } .timeline-text-container { margin-bottom: 1rem; } .timeline-text { color: #666; margin-bottom: 0; line-height: 1.7; font-size: 1rem; } .timeline-details { background: #f8f9fa; padding: 0.5rem; padding-left:1rem; border-radius: 8px; margin-bottom: 1.1rem; } .timeline-details ul { list-style: none; margin: 0; padding: 0; } .timeline-details li { margin-bottom: 0.5rem; font-size: 0.8rem; } .timeline-details strong { color: #5698c3; font-weight: 600; } .timeline-link { display: inline-block; background: linear-gradient(135deg, #5698c3, #667eea); color: white; padding: 0.25rem 0.7rem; border-radius: 25px; text-decoration: none; font-weight: 600; transition: all 0.3s ease; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin:0; font-size:1rem; } .timeline-link:hover { transform: translateY(-2px); box-shadow: 0 4px 8px rgba(0,0,0,0.2); color: white; text-decoration: none; } .expand-btn { background: none; border: none; color: #5698c3; cursor: pointer; font-size: 0.9rem; text-decoration: underline; margin-top: 0.5rem; padding: 0; } .expand-btn:hover { color: #667eea; } .text-truncated { display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; } @media (max-width: 768px) { .custom-toc { display: none; } .release-chart-wrapper { padding: 0 1rem; } .timeline-container { padding: 0 1rem; } .timeline-container::before { left: 2rem; } .timeline-item:nth-child(odd) .timeline-content, .timeline-item:nth-child(even) .timeline-content { margin-left: 4rem; margin-right: 0; text-align: left; } .timeline-dot { left: 2rem; } .timeline-item:nth-child(odd) .timeline-content::before, .timeline-item:nth-child(even) .timeline-content::before { left: -24px; right: auto; border-left-color: transparent; border-right-color: white; } } 时间轴导航 // 全局变量存储时间轴数据 let timelineData = []; let allTimelineData = []; let currentChartData = []; let currentFilterQuery = ''; let currentSelectedTypes = new Set(); let currentSelectedSize = null; // { type: 'lte'|'gt', value: number } 或 null 表示不限 // 配置 marked.js marked.setOptions({ breaks: true, // 支持换行 gfm: true, // 支持 GitHub Flavored Markdown sanitize: false, // 允许 HTML（谨慎使用） smartLists: true, // 智能列表 smartypants: true // 智能标点符号 }); // 从JSON文件加载时间轴数据 async function loadTimelineData() { try { const response = await fetch('./timeline-data.json'); if (!response.ok) { throw new Error(`HTTP error! status: ${response.status}`); } timelineData = await response.json(); timelineData = Array.isArray(timelineData) ? timelineData : []; allTimelineData = timelineData.map((d, i) => ({ ...d, __idx: i })); timelineData = allTimelineData; console.log('时间轴数据加载成功:', timelineData.length, '个项目'); return timelineData; } catch (error) { console.error('加载时间轴数据失败:', error); // 如果加载失败，使用备用数据 timelineData = [ { \"date\": \"2020-06\", \"title\": \"GPT-3 发布\", \"text\": \"GPT-3 是由 OpenAI 开发的大语言模型，拥有1750亿个参数。\", \"modelSize\": \"1750亿参数\", \"modelType\": \"自回归语言模型\", \"contextWindow\": \"4K\", \"officialDoc\": \"https://arxiv.org/abs/2005.14165\" } ]; allTimelineData = timelineData.map((d, i) => ({ ...d, __idx: i })); timelineData = allTimelineData; return timelineData; } } // 解析日期字符串，兼容 YYYY-MM 或 YYYY-MM-DD function parseDateToMs(dateStr) { if (!dateStr) return NaN; const trimmed = String(dateStr).trim(); // 如果只有年-月，补齐到当月第一天 const normalized = /^\\d{4}-\\d{2}$/.test(trimmed) ? `${trimmed}-01` : trimmed; const ms = Date.parse(normalized); return isNaN(ms) ? NaN : ms; } // 使用轻量 SVG 渲染顶部发布时间节点图 function renderReleaseTimelineChart(data) { const container = document.getElementById('release-chart'); if (!container) return; // 清空并创建结构：tooltip、可横向扩展的 inner、左右按钮 container.innerHTML = ''; const tooltip = document.createElement('div'); tooltip.className = 'tooltip'; tooltip.id = 'release-chart-tooltip'; container.appendChild(tooltip); const inner = document.createElement('div'); inner.className = 'rc-inner'; container.appendChild(inner); const btnLeft = document.createElement('button'); btnLeft.className = 'pan-btn pan-left'; btnLeft.setAttribute('aria-label', '向左移动'); btnLeft.innerHTML = '‹'; const btnRight = document.createElement('button'); btnRight.className = 'pan-btn pan-right'; btnRight.setAttribute('aria-label', '向右移动'); btnRight.innerHTML = '›'; container.appendChild(btnLeft); container.appendChild(btnRight); // 视口尺寸 const viewportW = container.clientWidth; const viewportH = container.clientHeight; // 140 const margin = { left: 40, right: 6, top: 16, bottom: 28 }; // 左右按钮护栏宽度，防止到边缘出现“空白”视觉（内容仍在按钮下方） const guard = 42; // 与按钮宽度一致 const visibleWidth = Math.max(0, viewportW - guard * 2); const innerViewportW = Math.max(0, visibleWidth - margin.left - margin.right); const innerH = Math.max(0, viewportH - margin.top - margin.bottom); // 数据清洗与排序 const items = (data || []) .map((d, idx) => ({ idx: (d && d.__idx != null ? d.__idx : idx), title: d.title || '', hasStar: (d.title || '').includes('⭐'), rawDate: d.date, t: parseDateToMs(d.date) })) .filter(d => !isNaN(d.t)) .sort((a, b) => a.t - b.t); if (items.length === 0) { const empty = document.createElement('div'); empty.style.cssText = 'position:absolute;inset:0;display:flex;align-items:center;justify-content:center;color:#8aa3c0;font-size:12px;'; empty.textContent = '暂无可用的发布时间数据'; container.appendChild(empty); return; } const minT = items[0].t; const maxT = items[items.length - 1].t; // 基于“有发布的月份”进行离散布局：仅包含有发布的月份 const monthBucketsMap = new Map(); items.forEach(d => { const dt = new Date(d.t); const y = dt.getFullYear(); const m = dt.getMonth() + 1; const key = `${y}-${String(m).padStart(2, '0')}`; const monthStartMs = Date.UTC(y, m - 1, 1); if (!monthBucketsMap.has(key)) { monthBucketsMap.set(key, { key, monthStartMs, items: [] }); } monthBucketsMap.get(key).items.push(d); }); const months = Array.from(monthBucketsMap.values()).sort((a, b) => a.monthStartMs - b.monthStartMs); // 同日分组用于上下错开显示（避免同一时间的节点重叠） const dayKey = (t) => { const d = new Date(t); return Date.UTC(d.getUTCFullYear(), d.getUTCMonth(), d.getUTCDate()); }; const dayGroups = new Map(); items.forEach(it => { const k = dayKey(it.t); let arr = dayGroups.get(k); if (!arr) { arr = []; dayGroups.set(k, arr); } it.groupIndex = arr.length; arr.push(it); }); dayGroups.forEach(arr => { const maxAbs = Math.ceil((arr.length - 1) / 2); arr.forEach(it => { const gi = it.groupIndex; const s = gi === 0 ? 0 : Math.ceil(gi / 2); const laneIdx = gi === 0 ? 0 : (gi % 2 === 1 ? s : -s); it.groupSize = arr.length; it.maxAbsLane = maxAbs; it.laneIndex = laneIdx; }); }); // 连续时间尺度：根据最小相邻时间差动态设置内容宽度 const totalSpanMs = Math.max(1, maxT - minT); const innerBase = innerViewportW; // 基线宽度 let minDeltaMs = Infinity; for (let i = 0; i < items.length - 1; i++) { const dt = items[i + 1].t - items[i].t; if (dt > 0 && dt < minDeltaMs) minDeltaMs = dt; } const desiredMinGap = 34; const maxScale = 12; let contentInnerW = innerBase; if (isFinite(minDeltaMs) && minDeltaMs > 0) { const candidate = Math.round((desiredMinGap * totalSpanMs) / minDeltaMs); contentInnerW = Math.max(innerBase, Math.min(innerBase * maxScale, candidate)); } const endCap = 24; // 小幅缓冲 const contentW = margin.left + margin.right + contentInnerW; inner.style.width = contentW + 'px'; // 内容不超出可视区时居中 if (contentW = 120; // 超过 ~4 个月按月刻度 let ticks = []; if (useMonthTicks) { const stepMonthsChoices = [1, 2, 3, 6, 12]; const dMin = new Date(minT); const dMax = new Date(maxT); const start = new Date(Date.UTC(dMin.getUTCFullYear(), dMin.getUTCMonth(), 1)); const end = new Date(Date.UTC(dMax.getUTCFullYear(), dMax.getUTCMonth(), 1)); const monthsDiff = (end.getUTCFullYear() - start.getUTCFullYear()) * 12 + (end.getUTCMonth() - start.getUTCMonth()); let bestStep = 1, bestDiff = Infinity; for (const s of stepMonthsChoices) { const cnt = Math.ceil(monthsDiff / s) + 1; const diff = Math.abs(cnt - targetTicks); if (diff < bestDiff) { bestDiff = diff; bestStep = s; } } let y = start.getUTCFullYear(); let m = start.getUTCMonth(); while (true) { const t = Date.UTC(y, m, 1); if (t > maxT) break; ticks.push(t); m += bestStep; while (m >= 12) { y++; m -= 12; } } } else { const allowedDays = [1, 2, 3, 5, 7, 10, 14, 21, 30, 60]; let bestStep = 7, bestDiff = Infinity; for (const s of allowedDays) { const cnt = Math.ceil(spanDays / s) + 1; const diff = Math.abs(cnt - targetTicks); if (diff < bestDiff) { bestDiff = diff; bestStep = s; } } const firstTick = Math.ceil(minT / oneDay) * oneDay; for (let t = firstTick; t margin.left，maxT -> margin.left + contentInnerW function getXForDate(t) { if (maxT === minT) return margin.left + contentInnerW / 2; const clamped = Math.max(minT, Math.min(maxT, t)); const ratio = (clamped - minT) / (maxT - minT); return margin.left + ratio * contentInnerW; } // 构建 SVG，宽度为可扩展内容宽度 const svgNS = 'http://www.w3.org/2000/svg'; const svg = document.createElementNS(svgNS, 'svg'); svg.setAttribute('width', contentW); svg.setAttribute('height', viewportH); // 基线 const baselineY = margin.top + innerH * 0.68; // 抬高基线，为上方多车道留更多空间 const axis = document.createElementNS(svgNS, 'line'); axis.setAttribute('x1', margin.left); axis.setAttribute('x2', margin.left + contentInnerW); // 轴线严格到内容末端，避免延伸到留白区域 axis.setAttribute('y1', baselineY); axis.setAttribute('y2', baselineY); axis.setAttribute('stroke', 'rgba(86,152,195,0.45)'); axis.setAttribute('stroke-width', '1'); svg.appendChild(axis); // 尺度函数：线性时间尺度 function scaleX(t) { return getXForDate(t); } // 刻度：基于连续时间的 ticks 数组渲染 ticks.forEach((t, idx) => { const x = getXForDate(t); const tick = document.createElementNS(svgNS, 'line'); tick.setAttribute('x1', x); tick.setAttribute('x2', x); tick.setAttribute('y1', baselineY - 8); tick.setAttribute('y2', baselineY + 8); tick.setAttribute('stroke', 'rgba(86,152,195,0.35)'); tick.setAttribute('stroke-width', '1'); svg.appendChild(tick); const label = document.createElementNS(svgNS, 'text'); label.setAttribute('x', x); label.setAttribute('y', baselineY - 12); if (idx === 0) label.setAttribute('text-anchor', 'start'); else if (idx === ticks.length - 1) label.setAttribute('text-anchor', 'end'); else label.setAttribute('text-anchor', 'middle'); label.setAttribute('font-size', '12'); label.setAttribute('fill', '#3c6a93'); const d = new Date(t); const y = d.getUTCFullYear(); const mm = String(d.getUTCMonth() + 1).padStart(2, '0'); if (spanDays >= 120) label.textContent = `${y}-${mm}`; else label.textContent = `${mm}-${String(d.getUTCDate()).padStart(2, '0')}`; svg.appendChild(label); }); // 散点与 Tooltip const rng = (seed => () => (seed = (seed * 9301 + 49297) % 233280) / 233280)(123456); const laneGap = Math.max(10, Math.round(innerH * 0.18)); // 相邻“车道”的垂直间距 const jitterAmp = Math.max(4, innerH * 0.15); items.forEach(d => { const x = getXForDate(d.t); const laneOffset = (d?.laneIndex || 0) * laneGap; const jitter = (rng() - 0.5) * 2 * jitterAmp; const y = baselineY - laneOffset - jitter * 0.25; let node; if (d.hasStar) { const star = document.createElementNS(svgNS, 'text'); star.setAttribute('x', x); star.setAttribute('y', y); star.setAttribute('text-anchor', 'middle'); star.setAttribute('dominant-baseline', 'middle'); star.setAttribute('font-size', '12'); star.textContent = '⭐'; node = star; } else { const circle = document.createElementNS(svgNS, 'circle'); circle.setAttribute('cx', x); circle.setAttribute('cy', y); circle.setAttribute('r', 4.5); circle.setAttribute('fill', '#2f6bd8'); circle.setAttribute('opacity', '0.95'); node = circle; } node.style.cursor = 'pointer'; node.addEventListener('mouseenter', (e) => { tooltip.style.display = 'block'; const rect = container.getBoundingClientRect(); tooltip.style.left = `${e.clientX - rect.left}px`; tooltip.style.top = `${e.clientY - rect.top - 8}px`; const dt = new Date(d.t); const y = dt.getFullYear(); const m = `${dt.getMonth() + 1}`.padStart(2, '0'); const day = `${dt.getDate()}`.padStart(2, '0'); tooltip.textContent = `${y}-${m}-${day} · ${d.title || '未命名'}`; }); node.addEventListener('mousemove', (e) => { const rect = container.getBoundingClientRect(); tooltip.style.left = `${e.clientX - rect.left}px`; tooltip.style.top = `${e.clientY - rect.top - 8}px`; }); node.addEventListener('mouseleave', () => { tooltip.style.display = 'none'; }); node.addEventListener('click', () => { tooltip.style.display = 'none'; const targetId = `timeline-item-${d.idx}`; if (typeof scrollToElement === 'function') { const el = document.getElementById(targetId); if (el) scrollToElement(targetId); else setTimeout(() => scrollToElement(targetId), 0); } else { const el = document.getElementById(targetId); el?.scrollIntoView({ behavior: 'smooth', block: 'center' }); } }); svg.appendChild(node); }); inner.appendChild(svg); // 平移控制 let offset = 0; // 当前左移偏移 // 为避免到最右仍显“空白”，允许最后一屏略微越界1px，改善视觉边缘 const maxOffset = Math.max(0, contentW - visibleWidth); // 与动态 endCap 对齐 function applyTransform() { inner.style.transform = `translateX(${-offset}px)`; // 按钮禁用状态 if (maxOffset panBy(-clickStep)); btnRight.addEventListener('click', () => panBy(clickStep)); function hold(btn, dir) { let raf = 0; let running = false; const speed = Math.max(6, Math.round(visibleWidth / 200)); const step = () => { panBy(dir * speed); raf = requestAnimationFrame(step); }; const start = () => { if (running) return; running = true; raf = requestAnimationFrame(step); }; const stop = () => { running = false; cancelAnimationFrame(raf); }; btn.addEventListener('mousedown', start); btn.addEventListener('mouseup', stop); btn.addEventListener('mouseleave', stop); btn.addEventListener('touchstart', (e) => { e.preventDefault(); start(); }, { passive: false }); btn.addEventListener('touchend', stop); btn.addEventListener('touchcancel', stop); } hold(btnLeft, -1); hold(btnRight, 1); // 支持滚轮/触控板左右移动 container.addEventListener('wheel', (e) => { if (maxOffset Math.abs(e.deltaY) ? e.deltaX : e.deltaY; if (delta !== 0) { e.preventDefault(); panBy(delta); } }, { passive: false }); // 初次渲染：如果内容超出可视区则展示最右侧，否则保持居中（不偏移） offset = contentW > visibleWidth ? maxOffset : 0; applyTransform(); } // 使用 marked.js 解析 Markdown function parseMarkdown(text) { if (!text) return ''; // 使用 marked.js 解析 Markdown let html = marked.parse(text); // 确保链接在新窗口打开 html = html.replace(/ 250; const truncatedText = isLongText ? item.text.substring(0, 250) + '...' : item.text; // 解析 Markdown 格式 const parsedText = parseMarkdown(item.text); const parsedTruncatedText = parseMarkdown(truncatedText); // 生成评价HTML（如果存在评价字段） const evaluationHTML = item.evaluation ? ` 评价 ${parseMarkdown(item.evaluation)} ` : ''; // 生成模型详情列表，只显示非空字段 const detailsItems = []; if (item.modelSize && item.modelSize.trim()) { detailsItems.push(`模型规模：${item.modelSize}`); } if (item.modelType && item.modelType.trim()) { detailsItems.push(`模型类型：${item.modelType}`); } if (item.contextWindow && item.contextWindow.trim()) { detailsItems.push(`上下文窗口：${item.contextWindow}`); } // 只有当有详情项时才显示详情区域 const detailsHTML = detailsItems.length > 0 ? ` ${detailsItems.join('')} ` : ''; // 只有当有官方文档链接时才显示链接 const officialLinkHTML = (item.officialDoc && item.officialDoc.trim()) ? `官方文档` : ''; timelineItem.innerHTML = ` ${item.title} ${typeof item.openSource === 'boolean' ? ` ${item.openSource ? '开源' : '闭源'} ` : ''} ${item.date} ${item.text ? ` ${isLongText ? parsedTruncatedText : parsedText} ${isLongText ? `显示更多` : ''} ` : ''} ${evaluationHTML} ${detailsHTML} ${officialLinkHTML} `; return timelineItem; } function createTocItem(item, index) { const tocItem = document.createElement('li'); const displayOrder = (item && item.__displayIndex != null) ? item.__displayIndex : index; const realIndex = index; tocItem.innerHTML = `${displayOrder + 1}. ${item.title}`; return tocItem; } function scrollToElement(targetId) { const targetElement = document.getElementById(targetId); if (targetElement) { targetElement.scrollIntoView({ behavior: 'smooth', block: 'center' }); updateActiveTocItem(targetId); } } function updateActiveTocItem(activeId) { const tocLinks = document.querySelectorAll('.custom-toc a'); let activeLink = null; tocLinks.forEach(link => { link.classList.remove('active'); if (link.getAttribute('data-target') === activeId) { link.classList.add('active'); activeLink = link; } }); // 如果找到了激活的链接，让目录滚动到该位置 if (activeLink) { scrollTocToActiveItem(activeLink); } } function scrollTocToActiveItem(activeLink) { const tocContent = document.querySelector('.custom-toc-content'); if (!tocContent || !activeLink) return; const tocRect = tocContent.getBoundingClientRect(); const linkRect = activeLink.getBoundingClientRect(); // 计算链接相对于目录容器的位置 const linkTop = activeLink.offsetTop; const linkHeight = activeLink.offsetHeight; const tocHeight = tocContent.clientHeight; const tocScrollTop = tocContent.scrollTop; // 计算目标滚动位置，让激活项显示在目录中间偏上的位置 const targetScrollTop = linkTop - tocHeight / 3; // 检查是否需要滚动 const linkVisibleTop = linkTop - tocScrollTop; const linkVisibleBottom = linkVisibleTop + linkHeight; // 如果链接不在可视区域内，或者接近边界，则滚动 if (linkVisibleTop < 0 || linkVisibleBottom > tocHeight || linkVisibleTop < tocHeight / 4 || linkVisibleBottom > tocHeight * 3/4) { tocContent.scrollTo({ top: Math.max(0, targetScrollTop), behavior: 'smooth' }); } } function toggleText(index) { const textElement = document.getElementById(`text-${index}`); const button = textElement.nextElementSibling; const item = timelineData[index]; if (textElement.classList.contains('text-truncated')) { textElement.innerHTML = parseMarkdown(item.text); textElement.classList.remove('text-truncated'); button.textContent = '收起'; } else { const truncatedText = item.text.substring(0, 250) + '...'; textElement.innerHTML = parseMarkdown(truncatedText); textElement.classList.add('text-truncated'); button.textContent = '显示更多'; } } function handleScroll() { const timelineItems = document.querySelectorAll('.timeline-item'); const scrollPosition = window.scrollY + window.innerHeight / 2; let activeItem = null; timelineItems.forEach(item => { const itemTop = item.offsetTop; const itemBottom = itemTop + item.offsetHeight; if (scrollPosition >= itemTop && scrollPosition { // 为目录编号使用 1..N 的显示序号 try { item.__displayIndex = i; } catch (_) {} // 使用原始索引用于元素 id 与跳转 const realIndex = (item && item.__idx != null) ? item.__idx : i; const timelineItem = createTimelineItem(item, realIndex); const tocItem = createTocItem(item, realIndex); timelineContainer.appendChild(timelineItem); tocList.appendChild(tocItem); }); document.querySelectorAll('.custom-toc a').forEach(link => { link.addEventListener('click', function(e) { e.preventDefault(); const targetId = this.getAttribute('data-target'); scrollToElement(targetId); }); }); } const TYPE_OPTIONS = [ { key: 'lang', label: '语言', match: ['语言', '语言模型', '文本', 'LLM', 'language'] }, { key: 'multi', label: '多模态', match: ['多模态', 'multimodal', '视频+图像+文本'] }, { key: 'img', label: '图像', match: ['图像生成', '文生图', 'image'] }, { key: 'video', label: '视频', match: ['视频生成', '文生视频', 'video'] }, { key: 'code', label: '代码', match: ['代码', 'code', '编程'] }, { key: 'code', label: '语音', match: ['语音生成'] }, { key: 'doc', label: '文档解析', match: ['文档', 'OCR', 'doc', '文档解析', '文档解析模型'] }, { key: 'other', label: '其他', match: [] } ]; function renderTypeChips() { const wrap = document.getElementById('type-filter'); if (!wrap) return; wrap.innerHTML = ''; TYPE_OPTIONS.forEach(opt => { const span = document.createElement('span'); span.className = 'type-chip'; span.textContent = opt.label; span.dataset.key = opt.key; span.addEventListener('click', () => { const k = span.dataset.key; if (currentSelectedTypes.has(k)) { currentSelectedTypes.delete(k); span.classList.remove('selected'); } else { currentSelectedTypes.add(k); span.classList.add('selected'); } applyFilters(); }); wrap.appendChild(span); }); } function normalizeStr(s) { return (s || '').toLowerCase(); } function itemMatchesTypes(item) { if (currentSelectedTypes.size === 0) return true; // 未选择类型，则不过滤 const mt = normalizeStr(item.modelType || ''); let belongs = false; // 是否命中已知类别 for (const opt of TYPE_OPTIONS) { if (!currentSelectedTypes.has(opt.key)) continue; if (opt.key === 'other') continue; // \"其他\"后面单独处理 if (opt.match.some(kw => mt.includes(normalizeStr(kw)))) { belongs = true; break; } } // 处理“其他” if (!belongs && currentSelectedTypes.has('other')) { const isKnown = TYPE_OPTIONS.some(opt => opt.key !== 'other' && opt.match.some(kw => mt.includes(normalizeStr(kw)))); if (!isKnown || mt.trim() === '') return true; } return belongs; } const SIZE_OPTIONS = [ { label: '≤3B', type: 'lte', value: 3 }, { label: '≤7B', type: 'lte', value: 7 }, { label: '≤32B', type: 'lte', value: 32 }, { label: '≤72B', type: 'lte', value: 72 }, { label: '≤120B', type: 'lte', value: 120 }, { label: '≤400B', type: 'lte', value: 400 }, { label: '>400B', type: 'gt', value: 400 } ]; // 移除旧的尺寸芯片容器渲染，改为下拉渲染 function renderSizeSelect() { const host = document.getElementById('size-select-custom'); if (!host) return; host.innerHTML = ''; const label = document.createElement('div'); label.textContent = currentSelectedSize ? SIZE_OPTIONS.find(o => o.type === currentSelectedSize.type && o.value === currentSelectedSize.value)?.label || '参数量（全部）' : '参数量（全部）'; host.appendChild(label); const drop = document.createElement('div'); drop.className = 'size-dropdown'; SIZE_OPTIONS.forEach(opt => { const optDom = document.createElement('div'); optDom.className = 'size-option' + (currentSelectedSize && currentSelectedSize.type === opt.type && currentSelectedSize.value === opt.value ? ' active' : ''); optDom.textContent = opt.label; optDom.addEventListener('click', (e) => { e.stopPropagation(); // 先关闭下拉，避免重渲染期间事件状态异常 closeDrop(); if (currentSelectedSize && currentSelectedSize.type === opt.type && currentSelectedSize.value === opt.value) { currentSelectedSize = null; } else { currentSelectedSize = { type: opt.type, value: opt.value }; } applyFilters(); // 重渲染选择器，更新标签文本与选中态 renderSizeSelect(); }); drop.appendChild(optDom); }); host.appendChild(drop); let onDocClick = null; function closeDrop() { host.classList.remove('open'); drop.classList.remove('open'); if (onDocClick) { document.removeEventListener('click', onDocClick, true); onDocClick = null; } } const toggle = (e) => { e.stopPropagation(); const willOpen = !host.classList.contains('open'); if (willOpen) { host.classList.add('open'); drop.classList.add('open'); onDocClick = (evt) => { if (!host.contains(evt.target)) closeDrop(); }; document.addEventListener('click', onDocClick, true); } else { closeDrop(); } }; host.onclick = null; host.onkeydown = null; host.onclick = toggle; host.setAttribute('role', 'button'); host.setAttribute('tabindex', '0'); host.onkeydown = (e) => { if (e.key === 'Enter' || e.key === ' ') { e.preventDefault(); toggle(e); } }; } function parseModelSizesToBList(modelSize) { // 提取如 \"0.5B, 1.8B, 4B, 7B\" 或 \"120B (..), 20B (..)\" 的前置主尺寸 // 规则：取逗号分隔的前段，每段取第一个 \"(数字(小数)?B)\"，单位统一为B（十进制），忽略括号中的总计/激活信息 if (!modelSize || typeof modelSize !== 'string') return []; const head = modelSize.split('(')[0]; // 只看括号前 const parts = head.split(','); const result = []; const re = /([0-9]+(?:\\.[0-9]+)?)\\s*B/i; parts.forEach(p => { const m = p.match(re); if (m) { const v = parseFloat(m[1]); if (!isNaN(v)) result.push(v); } }); return result; } function itemMatchesSize(item) { if (currentSelectedSize == null) return true; const sizes = parseModelSizesToBList(item.modelSize || ''); if (sizes.length === 0) return false; // 无法解析则不匹配 // 区间规则： // lte 档采用“上一个 lte 值, 当前值]（左开右闭）”，如 ≤7B => (3B, 7B] // 第一档 ≤3B 为 (-∞, 3B] // gt 档为 (value, +∞) if (currentSelectedSize.type === 'lte') { const idx = SIZE_OPTIONS.findIndex(o => o.type === 'lte' && o.value === currentSelectedSize.value); let lower = -Infinity; if (idx > 0) { for (let i = idx - 1; i >= 0; i--) { if (SIZE_OPTIONS[i].type === 'lte') { lower = SIZE_OPTIONS[i].value; break; } } } if (!isFinite(lower)) { return sizes.some(v => v v > lower && v v > currentSelectedSize.value); } return true; } // 修改 applyFilters 将尺寸条件纳入 function applyFilters() { const q = normalizeStr(currentFilterQuery); const filtered = allTimelineData.filter(d => { const titleOk = !q || normalizeStr(d.title).includes(q); const typeOk = itemMatchesTypes(d); const sizeOk = itemMatchesSize(d); return titleOk && typeOk && sizeOk; }); currentChartData = filtered; renderReleaseTimelineChart(currentChartData); clearTimelineAndToc(); renderTimelineAndToc(filtered); if (filtered.length > 0) { setTimeout(() => updateActiveTocItem(`timeline-item-${(filtered[0].__idx != null ? filtered[0].__idx : 0)}`), 200); } } function filterAndRenderByTitle(query) { currentFilterQuery = query; applyFilters(); } // 修复博客主题的运行时间脚本错误 window.runtime_span = window.runtime_span || { innerHTML: '' }; // 初始化页面 async function initTimeline() { try { // 加载时间轴数据 await loadTimelineData(); // 顶部发布时间节点图 currentChartData = timelineData; renderReleaseTimelineChart(currentChartData); // 监听窗口尺寸变化重绘 let resizeTimer = null; window.addEventListener('resize', () => { clearTimeout(resizeTimer); resizeTimer = setTimeout(() => renderReleaseTimelineChart(currentChartData), 150); }); // 渲染时间轴与目录（初次） clearTimelineAndToc(); renderTimelineAndToc(timelineData); // 渲染类型与尺寸筛选芯片 renderTypeChips(); renderSizeSelect(); // 搜索框交互 const input = document.getElementById('timeline-search'); if (input) { input.value = currentFilterQuery || ''; input.addEventListener('input', () => filterAndRenderByTitle(input.value)); input.addEventListener('keydown', (e) => { if (e.key === 'Escape') { input.value=''; filterAndRenderByTitle(''); } }); } const timelineContainer = document.getElementById('timeline'); const tocList = document.getElementById('toc-list'); if (!timelineContainer || !tocList) { console.warn('时间轴元素未找到'); return; } // 添加滚动监听 window.addEventListener('scroll', handleScroll); // 初始化第一个项目为活跃状态 setTimeout(() => { updateActiveTocItem('timeline-item-0'); }, 500); console.log('时间轴初始化成功'); } catch (error) { console.error('时间轴初始化失败:', error); } } // 页面加载完成后初始化 document.addEventListener('DOMContentLoaded', function() { initTimeline(); });","tags":[null,null,null],"categories":[null]},{"path":"/llm-timeline/timeline-data.json","content":"[{\"date\":\"2025-09-02\",\"title\":\"腾讯混元 Hunyuan-MT-7B\",\"text\":\"**摘要：** 腾讯开源的70亿参数轻量级翻译大模型，在WMT25国际机器翻译比赛中斩获30个语言方向的第一名，实现了“小参数量，大能量”的技术突破，并配套开源了业界首个翻译集成模型 `Hunyuan-MT-Chimera-7B`。 **模型规格与架构：** - **参数量：** 7B - **支持语言：** 支持33种语言互译，并对5种中国少数民族语言/方言（如藏语、维吾尔语等）进行了优化。 - **训练范式：** 采用创新的“预训练 → 跨语言预训练(CPT) → 监督微调 → 翻译强化 → 集成强化”五阶段训练流程，通过跨语言对齐机制提升了低资源语言的翻译质量。 - **配套模型：** 开源了业界首个翻译集成模型 `Hunyuan-MT-Chimera-7B`，可融合多个翻译模型（如 `Hunyuan-MT-7B`、`deepseek` 等）的结果，生成更优译文。 **性能与实测表现：** - **竞赛基准：** 在WMT25国际机器翻译比赛中，获得了全部31个语种中的30个第一名，处于绝对领先地位。 - **公开基准：** 在Flores200评测集上，BLEU评分平均达到42.3，表现优于同尺寸模型，且不逊于部分超大尺寸闭源模型。 - **实测效果：** 在俚语、古诗词、网络缩写等复杂场景下表现出色，翻译结果兼顾“信达雅”。 **优势：** - **轻量化高性能：** 以7B的较小参数量实现了与超大模型相媲美的性能，证明了精妙架构设计的有效性。 - **计算效率高：** 推理速度快，通过腾讯自研的 `AngelSlim` 压缩工具进行FP8量化后，推理性能可进一步提升30%，能在消费级GPU上流畅运行。 - **部署友好：** 对硬件要求低，部署、运行和维护成本相对更低，为中小企业降低了AI应用门槛。 - **开源生态完善：** 模型、技术报告以及配套的压缩工具均已开源，方便社区开发者使用和二次创新。 **适用场景 / 备注：** - 已在腾讯会议、企业微信、QQ浏览器等多个内部业务中落地。 - `Hunyuan-MT-Chimera-7B` 集成模型特别适用于对准确性要求极高的专业领域，如法律、医疗文本翻译。\",\"modelSize\":\"7B\",\"modelType\":\"语言\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/Tencent-Hunyuan/Hunyuan-MT/\"},{\"date\":\"2025-08-31\",\"title\":\"美团 LongCat-Flash-Chat\",\"text\":\"**摘要：** 美团于2025年8月31日开源的混合专家（MoE）大语言模型，以其创新的动态计算架构为核心，实现了极高的推理速度（>100 tokens/s）和极具竞争力的成本（$0.7/百万输出token），标志着业界向更实用、高效模型发展的又一重要里程碑。 **模型规格与架构：** - **参数量：** 总参数量为`5600亿`，根据上下文动态激活`186亿`至`313亿`（平均约`270亿`）。 - **架构/范式：** 采用创新的混合专家（MoE）架构，包含两大亮点： - **零计算专家 (Zero-computation Experts)：** 引入了256个不消耗算力的专家，让模型可以为简单的Token（如标点、连词）分配更少或零计算资源，实现按需计算。 - **快捷连接MoE (Shortcut-connected MoE, ScMoE)：** 通过跨层快捷连接，将前一层的计算与当前MoE层的通信并行执行，极大地提升了训练和推理的系统吞吐量。 - **上下文：** 训练时将上下文长度扩展至`128K`。 **性能与实测表现：** - **基准：** 作为一个非思考型模型，其综合性能与 `DeepSeek-V3.1` 和 `Kimi-K2` 等领先模型相当，尤其在智能体（Agent）工具使用方面经过专门优化，表现出色。 - **实测：** - **速度与成本：** 社区实测普遍证实其极快的响应速度和极低的首Token延迟，成本优势明显。 - **强项：** 指令遵循效果良好，代码生成能力表现不俗。 - **弱项：** 在需要深度背景知识的复杂推理任务上表现不佳（例如无法理解“但丁/丁真”的语言梗，或未能推理出“老鹰本身就会飞”），长数学题的解答过程可能被截断或末尾出错。 **优势：** - **极致的性能效率：** 推理速度极快，延迟极低，运营成本极具竞争力。 - **架构创新：** `零计算专家`和`ScMoE`为高效大模型的设计提供了有价值的新思路。 - **强大的系统优化：** 从训练到推理都进行了深度的系统级协同优化，保证了高稳定性和高效率。 **劣势：** - **复杂推理能力有限：** 与顶级的闭源模型相比，在知识深度和复杂逻辑推理链上仍有差距。 - **长文本生成稳定性：** 在处理超长或需要多步精确计算的生成任务时，输出的完整性和准确性有时会下降。\",\"modelSize\":\"560B (总计 560B, 激活 18.6B~31.3B)\",\"modelType\":\"语言, 代码\",\"openSource\":true,\"contextWindow\":\"128K\",\"officialDoc\":\"https://github.com/meituan-longcat/LongCat-Flash-Chat\"},{\"date\":\"2025-08-27\",\"title\":\"⭐Google Gemini 2.5 Flash Image (nano-banana)\",\"text\":\"**摘要：** Google发布的顶级图像生成与编辑模型，在LMArena盲测中以创纪录优势夺冠。该模型以其卓越的角色一致性、强大的提示编辑能力和极高的性价比著称，但在处理复杂任务时稳定性有待提高。 **模型规格与架构：** - 官方名称：`Gemini 2.5 Flash Image`，社区昵称 `nano-banana`。 - 知识截止：2025年6月。 - 性能：生成速度快，API每分钟最多可调用500次。 - 成本：定价极低，每张图片成本约0.039美元（人民币不到3毛钱），性价比极高。 **性能与实测表现：** - **基准测试**：在LMArena盲测竞技场中获得历史最高Elo分数领先优势，被广泛认为是当前最强的图像编辑模型。 - **角色一致性 **：核心优势。能够跨多张图片高度保持人物的面部、神态和穿着，效果自然，AI味少。偶有小瑕疵（如生成两副墨镜）。 - **图像编辑**：表现顶尖。可通过简单的自然语言提示完成精确的局部修改（如修复“六指图”）、无缝添加元素（如纹身），无需手动框选。 - **风格迁移**：对主流艺术风格（如油画、动漫）的迁移效果出色，但处理小众风格（如像素风）时表现较弱。 - **多元素融合与复杂编辑**：最主要的短板。当提示包含多个指令（如同时换装、换背景、改动作）时，稳定性急剧下降，成功率低，需要用户多次尝试。 **优势：** - SOTA级别的角色一致性与图像编辑能力，效果逼真自然。 - 极具竞争力的价格和快速的生成速度，性价比极高。 - 创意生成能力强，适合制作手办场景等复杂有趣的视觉内容。 - 在社区评测中，综合表现被认为优于 `GPT-4o` 等竞争对手。 **劣势：** - 稳定性不足，出图质量波动较大，完美结果需要多次生成（“roll图”）。 - 难以胜任复杂、多元素的编辑任务，指令越复杂，失败率越高。 **适用场景 / 备注：** - 适用于需要保持角色连贯性的故事叙述、营销内容创作和概念设计。 - 作为高效、低成本的P图工具，可用于快速修复或创意修改图片。 - 测评主要围绕其核心更新点“以图生图”和图片编辑展开。\",\"modelSize\":\"\",\"modelType\":\"图像生成, 多模态\",\"openSource\":false,\"contextWindow\":\"\",\"officialDoc\":\"https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image/\",\"evaluation\":\"又不需要PS了？ 实测后，确实🐂，图片修改比图片生成好。\"},{\"date\":\"2025-08-26\",\"title\":\"⭐面壁智能 MiniCPM-V 4.5\",\"text\":\"**摘要：** 面壁智能开源的8B端侧多模态旗舰模型，是行业首个具备“高刷”视频理解能力的模型，在多项评测中性能越级超越`Qwen2.5-VL 72B`等更大规模模型。 **模型规格与架构：** - **参数量：** `8B` - **架构/范式：** 基于`Qwen3-8B`和`SigLIP2-400M`构建，核心创新是`3D-Resampler`结构，可进行三维视频片段的高密度压缩。 **性能与实测表现：** - **基准：** 在`OpenCompass`、`MotionBench`、`FavorBench`、`LVBench`、`OmniDocBench`等多个图文、视频理解榜单上取得同级SOTA，并超越部分更大模型。 - **实测：** 视频处理可实现高达`10fps`的抽帧，在同等视觉Token开销下可接收6倍视频帧，视觉压缩率达96倍。在`Video-MME`评测上，推理时间开销仅为同级模型的1/10。 **优势：** - **高刷视频理解：** 行业首创，能更精细地捕捉动态细节，将视频理解从“看PPT”提升到“看动态画面”。 - **越级性能：** 以`8B`参数量在图片理解、视频理解、文档解析等核心任务上全面超越`72B`规模的模型，实现“以小博大”。 - **端侧友好：** 推理效率极高，显存占用低、速度快，是端侧AI应用的优选方案。 - **灵活推理：** 支持“常规模式”和“深度思考模式”，可根据任务复杂性平衡性能与响应速度。 **适用场景：** - 需要精细动态捕捉的视频分析、移动端实时多模态交互、复杂文档自动化处理等。\",\"modelSize\":\"8B\",\"modelType\":\"多模态, 文档解析模型\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://huggingface.co/openbmb/MiniCPM-V-4_5\",\"evaluation\":\"发现一个好现象：国内的AI‘六小龙’不再只卷通用大模型了，很多开始深耕特定领域，通过聚焦资源在特定赛道上构建核心竞争力。在我们的近期测试中，对于检验单的识别效果比Qwen-VL 72B效果要好。\"},{\"date\":\"2025-08-26\",\"title\":\"书生·InternVL 3.5\",\"text\":\"**摘要：** InternVL 3.5 是由上海人工智能实验室发布的开源多模态大模型系列，通过级联强化学习（Cascade RL）、视觉分辨率路由器（ViR）和解耦部署（DvD）等创新，显著提升了模型的推理能力、效率和多功能性。其旗舰模型在多个基准上达到了开源社区的领先水平，并缩小了与顶尖商业模型的性能差距。 **模型规格与架构：** - **模型系列：** 共发布9个模型，涵盖密集型（Dense）和专家混合（MoE）两种架构。 - **Dense模型：** `1B`、`2B`、`4B`、`8B`、`14B`、`38B` - **MoE模型：** `InternVL3.5-20B-A4B`、`InternVL3.5-30B-A3B`、`InternVL3.5-241B-A28B` - **架构/范式：** 延续了 `ViT–MLP–LLM` 范式，视觉编码器采用 `InternViT-300M` 和 `InternViT-6B`，语言模型基于 `Qwen3` 和 `GPT-OSS` 系列初始化。 - **高效变体：** 引入 `ViR` 机制的模型被称为 `InternVL3.5-Flash`，专为资源受限场景优化。 **性能与实测表现：** - **推理能力：** 相较于前代 `InternVL 3`，推理性能平均提升超过10个百分点，在 `MMMU` 和 `MathVista` 等复杂推理基准上进步显著。 - **综合性能：** 旗舰模型 `InternVL3.5-241B-A28B` 在通用多模态、推理、文本和代理任务的综合评测中，取得了开源模型的最佳结果，其通用多模态能力与 `GPT-5` 相当。 - **效率提升：** `InternVL3.5-Flash` 能在维持近100%性能的同时，将视觉令牌数量减少50%。`DvD` 部署策略使推理速度提升4.05倍。 - **新功能：** 扩展了对GUI交互、具身代理和SVG理解与生成等新能力的支持，并在 `OSWorld`、`WindowsAgentArena` 等基准上表现出色。 **优势：** - **级联强化学习 (Cascade RL)：** 结合离线与在线RL，稳定高效地提升了模型的复杂推理能力。 - **视觉分辨率路由器 (ViR)：** 动态调整图像压缩率，在不牺牲性能的前提下大幅降低了计算成本。 - **解耦视觉语言部署 (DvD)：** 将视觉和语言模块部署在不同硬件上并异步处理，解决了计算瓶颈，显著加快了推理速度。\",\"modelSize\":\"1B, 2B, 4B, 8B, 14B, 38B, 20B (激活4B), 30B (激活3B), 241B (激活28B)\",\"modelType\":\"多模态\",\"openSource\":true,\"contextWindow\":\"32K\",\"officialDoc\":\"https://arxiv.org/abs/2408.14352\"},{\"date\":\"2025-08-22\",\"title\":\"Mirage 2\",\"text\":\"**摘要：** 全球首款AI原生UGC游戏引擎`Mirage`的2.0版本，是一个可在线游玩的实时通用领域生成式世界引擎。它能将任何图像（照片、绘画、涂鸦等）或文本提示，转化为可实时互动的3D世界，被视为对标谷歌`Genie 3`的重要产品。 **模型规格与性能指标：** - **生成时长：** 可达10分钟以上。 **性能与实测表现：** - **实测体验：** 当前版本体验不佳，存在明显的操控延迟、视角切换卡顿、画面帧率低以及视觉稳定性不足（如快速场景转换引入意外细节）等问题。 **优势：** - **实时互动性强：** 用户可通过对话式文本提示，即时改变和重塑游戏世界。 - **输入源多样：** 支持从照片到儿童涂鸦等多种形式的图像输入，并转化为可玩世界。 - **低门槛运行：** 理论上可在消费级GPU上实现低延迟运行，潜力巨大。 **劣势：** - **体验待优化：** 实际操控的延迟感和画面流畅度与现代游戏标准有较大差距。 **适用场景 / 备注：** - 该模型展示了AI实时共同创作游戏的未来方向，让“世界模型”成为可在线游玩的产品。官方承认在动作控制精度和视觉稳定性方面仍存在前沿问题有待解决。\",\"modelSize\":\"\",\"modelType\":\"多模态, 视频生成, 世界模型\",\"openSource\":false,\"contextWindow\":\"\",\"officialDoc\":\"https://blog.dynamicslab.ai/\"},{\"date\":\"2025-08-21\",\"title\":\"书生 Intern-S1-mini\",\"text\":\"**摘要：** Intern-S1的80亿参数轻量化版本，旨在以极低的部署门槛提供强大的通用与专业科学能力，让更广泛的开发者和研究者能够轻松进行二次开发与应用。 **模型规格与架构：** - **基础架构**： - **语言模型**：基于8B参数的密集语言模型（`Qwen3`），提供强大的语言理解和生成能力。 - **视觉编码器**：结合0.3B参数的视觉编码器（`InternViT`），用在处理和理解图像数据。 - **设计理念**：延续 `Intern-S1` 的设计理念，覆盖文本、图像、分子式、蛋白质等多模态、多任务数据领域，实现了轻量级模型下多种能力的极致平衡。 **性能与实测表现：** - **通用能力**：在 `MMLU-Pro`、`AIME-2025`、`MMMU` 等多项权威基准上表现卓越，稳居同量级模型第一梯队。 - **科学能力**：在化学 (`SmolInstruct`, `ChemBench`)、材料 (`MatBench`) 等任务中表现尤为突出，显著领先同级模型；在物理、地球、生物等学科中也保持领先水平。 **优势：** - **轻量高效**：“减身材不减实力”，在参数规模与性能之间取得了良好平衡，大幅降低了对高端计算设备的依赖。 - **易于开发**：上手门槛极低，仅需一张24GB显存的GPU即可完成LoRA微调，并已得到 `LLaMA-Factory` 等主流框架的支持。 **适用场景 / 备注：** - 非常适合开展科学研究、在产品或应用中快速验证创意，以及在教学实践中让学生直观理解多模态大模型的原理与应用。\",\"modelSize\":\"8B\",\"modelType\":\"多模态, 语言\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://huggingface.co/internlm/Intern-S1-mini\"},{\"date\":\"2025-08-20\",\"title\":\"字节跳动 Seed-OSS\",\"text\":\"**摘要：** 字节跳动Seed团队发布的360亿参数开源大语言模型，以原生的512K超长上下文窗口和创新的“思考预算”控制机制为主要看点，在多个英文基准测试上刷新了SOTA记录。 **模型规格与架构：** - **参数量：** `36B`（稠密模型） - **架构：** Causal LM，采用`RoPE`位置编码、`GQA`注意力机制、`RMSNorm`归一化和`SwiGLU`激活函数。 - **上下文：** 原生支持 `512K`。 - **训练数据：** 12T Tokens，知识截止时间为2024年7月。 - **版本：** 提供 `Seed-OSS-36B-Base`（含合成数据）、`Seed-OSS-36B-Base-woSyn`（不含合成数据）和 `Seed-OSS-36B-Instruct`（指令微调）三个版本。 **性能与实测表现：** - **基准：** 在 `BBH` 推理基准上刷新了开源模型纪录。在 `MMLU-Pro`、`GSM8K`、`MATH`、`HumanEval` 等多个知识、数学、代码类基准上均表现出色，性能超越了Qwen2.5-32B等同级别模型。 - **实测：** 指令微调版在 `AIME24` 数学竞赛题上表现优异。模型在工具调用（Agent）任务上经过特别优化，表现突出。 **优势：** - **超长上下文：** 原生512K上下文长度，是发布时主流开源模型的4倍，无需插值扩展，适合处理海量信息场景。 - **思考预算（Thinking Budget）：** 允许用户灵活设定token预算来控制模型的思考深度，以平衡性能与推理成本，实用性强。 - **研究友好：** 提供了不含合成数据的“纯净”预训练版本，方便学术界进行后续研究。 - **性能优异：** 以相对较少（12T）的训练数据量，在多个领域达到了SOTA性能。 **劣势：** - **语言偏向性：** 模型主要针对英语进行了优化和评估，在中文等其他语言上的性能有限且未经严格测试，对于非英语场景应用价值受限。 **适用场景 / 备注：** - 适用于法律文档审查、长篇报告分析、复杂代码库理解等需要处理海量信息的专业场景。 - 使用 `vLLM` 框架进行推理时，需要安装指定版本。\",\"modelSize\":\"36B\",\"modelType\":\"语言\",\"openSource\":true,\"contextWindow\":\"512K\",\"officialDoc\":\"https://huggingface.co/collections/ByteDance-Seed/seed-oss-68a609f4201e788db05b5dcd\"},{\"date\":\"2025-08-20\",\"title\":\"⭐ DeepSeek V3.1\",\"text\":\"**摘要：** DeepSeek V3.1 是一款备受瞩目的混合推理（Hybrid Reasoning）MoE模型，以极高的性价比在编程和推理任务上展现出强大实力。然而，社区评测显示其表现“偏科”，在取得优异基准成绩的同时，也在物理模拟、视觉创意等特定领域暴露明显短板。其采用的 `UE8M0 FP8` 精度格式，被视为推动国产AI芯片软硬协同的关键一步，引发了市场广泛关注。 **模型规格与架构：** - **参数量：** 采用专家混合（MoE）架构，总参数量6710亿，激活参数量370亿。 - **架构/范式：** 混合推理模型，整合了“思考”（类似 `R1`）与“非思考”（类似 `V3`）两种模式。新增了用于原生搜索的 `` 和显式思维链的 `` 等特殊Token。 - **上下文：** 128K。 - **精度格式：** 采用了 `UE8M0 FP8 Scale` 参数精度，该格式能大幅节省内存带宽，旨在深度适配和优化国产AI芯片的性能。 **性能与实测表现：** - **基准：** 在 `Aider` 编程基准上得分71.6%，超越了 `Claude 3 Opus`，且成本仅为其1/68。 - **实测（综合社区评测）：** - **优势领域：** 在常规编程（如网页开发）、逻辑推理（表现不输于 `Gemini 2.5 Pro`）和工具调用（稳定性提升）方面表现出色。`非思考`模式在小说开篇等任务上甚至优于`思考`模式。 - **劣势领域：** 表现两极分化。在需要精确物理模拟（如p5.js小球弹跳）或特定审美（如网页设计）的编程任务中惨败。 - **稳定性：** 长文本生成时，网页端出现过突然中断、内容清空并“失忆”的Bug。`思考`模式在小说续写中也出现了前后矛盾。 **优势：** - **极高性价比：** 在其擅长的领域，提供了顶级的性能和极低的成本，对开发者极具吸引力。 - **软硬协同：** 率先采用 `UE8M0 FP8` 格式，主动适配国产芯片硬件，为国产AI生态建设提供了范例。 **劣势：** - **能力偏科严重：** 模型能力不均衡，是一个“偏科生”，在某些领域表现极佳，在另一些领域则完全不可用。 - **审美与物理理解欠缺：** 代码能力似乎停留在“知其然，不知其所以然”的层面，缺乏对物理规律和视觉美学的深入理解。 - **长上下文稳定性存疑：** 在长文本任务中暴露出稳定性问题，可能与Web端审查或缓存机制有关。\",\"modelSize\":\"671B (激活 37B)\",\"modelType\":\"语言\",\"openSource\":true,\"contextWindow\":\"128K\",\"officialDoc\":\"https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Base\",\"evaluation\":\"预期过高，但股市又涨了一波。\"},{\"date\":\"2025-08-19\",\"title\":\"Alibaba Ovis 2.5\",\"text\":\"**摘要：** 阿里巴巴发布的开源多模态大语言模型（MLLM），专为原生分辨率视觉感知和深度多模态推理而设计。其核心特点是采用了原生分辨率视觉变换器（NaViT）和可选的“思考模式”，在多个基准测试中达到了同规模模型的SOTA水平。 **模型规格与架构：** - **参数量：** `9B`、`2B` - **架构/范式：** 沿用`Ovis`架构（视觉分词器VT、视觉嵌入表VET、LLM），但进行了两大升级： - **视觉编码器：** 升级为原生分辨率的`NaViT`（基于`siglip2-so400m-patch16-512`初始化），可处理任意分辨率和宽高比的图像，无需裁剪或切片。 - **语言模型基座：** 升级为`Qwen3`，以增强深度推理能力。 **性能与实测表现：** - **综合基准：** 在OpenCompass多模态排行榜上，`Ovis2.5-9B`平均分达78.3，在40B参数以下的开源MLLM中排名第一；`Ovis2.5-2B`得分为73.9，在同级别中表现优异。 - **专项能力：** 在STEM推理（`MMMU`）、复杂图表分析（`ChartQA Pro`）、OCR（`OCRBench`）、视觉定位（`RefCOCO`）以及视频理解等多个领域均展示了顶尖或领先的性能。 **优势：** - **原生分辨率感知：** 无需破坏性的图像切片，能最大限度保留图像的精细细节和全局结构，特别适合处理文档和图表。 - **深度推理能力：** 可选的“思考模式”引入了反思和自我修正机制，允许模型在处理复杂问题时进行更深入的思考，以换取更高的准确性。 - **高效训练：** 通过数据打包和混合并行框架等技术优化，实现了3至4倍的端到端训练速度提升。 **适用场景/备注：** - 适用于对视觉细节要求高的场景，如复杂图表分析、科学文献理解、文档/表单OCR等。同时在需要严密逻辑推理的视觉问答任务中表现突出。 **与Qwen-VL系列对比：** - **定位差异：** `Ovis 2.5`更像是“技术探索先锋”，专注于攻克原生分辨率处理、深度反思推理等前沿难题；`Qwen-VL`系列则定位为“通用多模态基石”，追求在广泛任务上的均衡与极致性能。 - **视觉处理：** `Ovis 2.5`采用`NaViT`，可直接处理任意分辨率的原始图像，无损细节；`Qwen-VL`处理高清图则通常采用“切片（tiling）”策略。 - **推理机制：** `Ovis 2.5`引入了独特的“思考模式”，进行显式的自我检查与修正；`Qwen-VL`具备强大的通用推理能力，但没有此种特定的反思机制。 - **关系：** `Ovis`系列的技术探索成果未来可能会融入`Qwen`主系列，可以理解为“专才”与“全才”的关系。\",\"modelSize\":\"9B, 2B\",\"modelType\":\"多模态, 文档解析模型\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://arxiv.org/abs/2508.11737\"},{\"date\":\"2025-08-15\",\"title\":\"腾讯 HunyuanWorld-1.0-lite\",\"text\":\"**摘要：** 腾讯于8月15日正式发布 `HunyuanWorld-1.0` 的量化版本 `HunyuanWorld-1.0-lite`。该版本是继7月26日初始模型发布后的重大更新，通过量化技术显著降低了硬件门槛，首次实现了在 `4090` 等消费级GPU上运行，极大地提升了模型的可及性和实用性。 ![](https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0/raw/main/assets/teaser.png) **模型规格与架构：** - **核心架构：** 沿用 `HunyuanWorld 1.0` 的核心框架，即“全景代理生成 → 语义分层 → 层次化3D重建”。 ![](https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0/raw/main/assets/arch.jpg) - **Lite版关键优化：** 为突破显存瓶颈，Lite版本引入了关键的量化与缓存技术，用户可通过添加 `--fp8_gemm`、`--fp8_attention` 和 `--cache` 等参数来启用。 **性能与实测表现：** - **硬件兼容性：** 成功将模型部署在消费级显卡上，解决了初始版本对高端计算资源（>26GB显存）的依赖。 - **生成质量：** 在大幅降低资源消耗的同时，保持了与原版几乎无异的高质量3D世界生成效果。根据官方报告，模型在多项视觉质量和几何一致性指标上（如BRISQUE, NIQE, Q-Align, CLIP-T/I）均优于其他开源方法。 - **视觉效果：** ![](https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0/raw/main/assets/roaming_world.gif) **优势：** - **极高的可及性：** Lite版本的发布是该项目的里程碑，使广大个人开发者和小型团队也能轻松体验和使用前沿的3D世界生成技术。 - **完整的开源生态：** 提供从推理代码、模型权重到技术报告的全套资源，并配套了模型浏览器等工具。 - **强大的兼容性：** 生成的 `3D mesh` 格式可无缝接入游戏开发、物理仿真、VR/AR等现有计算机图形（CG）工作流。 **适用场景：** ![](https://github.com/Tencent-Hunyuan/Hunyu_anWorld-1.0/raw/main/assets/application.png) - 游戏开发 - 虚拟现实与增强现实 - 影视制作与广告 - 交互式内容创作\",\"modelSize\":\"PanoDiT-Text: 478MB, PanoDiT-Image: 478MB, PanoInpaint-Scene: 478MB, PanoInpaint-Sky: 120MB\",\"modelType\":\"多模态, 3D世界生成\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0\",\"evaluation\":\"Lite版本的发布是HunyuanWorld 1.0项目走向普及应用的关键一步。它不仅在技术上展示了SOTA的性能，更重要的是通过工程优化解决了实际部署中的核心痛点，使其成为目前对个人开发者最友好的开源3D世界生成模型之一。\"},{\"date\":\"2025-08-11\",\"title\":\"⭐ 智谱 GLM-4.5V\",\"text\":\"**摘要：** 智谱AI发布的旗舰级开源多模态模型，基于`GLM-4.5-Air`构建。它在42个公开基准中的41个上取得SOTA性能，并以其强大的原生视频理解、视觉定位（Grounding）和网页复刻能力在社区实测中获得高度评价。 **模型规格与架构：** - **参数量**：106B总参数，12B激活参数。 - **架构/范式**：采用`MoE`（专家混合）架构，延续`GLM-4.1V-Thinking`技术路线，文本基座为`GLM-4.5-Air-Base`。 - **其他特性**：新增“思考模式”开关，允许用户在追求速度和深度推理之间进行灵活切换。 **性能与实测表现：** - **基准**：官方宣称在42个公开多模态榜单中，41个达到SOTA，综合性能领先同级别开源模型。 - **实测**：在社区测试中，于专业读数（如游标卡尺）、复杂场景推理、网页复刻、原生视频内容分析、视觉定位等高级任务上表现出色且快速。 **优势：** - **原生视频理解**：具备真正的时空理解能力，能按时间戳分析视频画面内容，而非简单的音频转录。 - **强大的文档与代码能力**：在OCR、表格识别（可还原为HTML）、网页复刻等任务上表现顶尖。 - **精准的视觉定位（Grounding）**：能准确识别并框选图像中的指定元素，在特定任务中切换到Grounding模式可显著提升准确率。 **劣势：** - **高阶空间逻辑推理**：与其他多模态模型类似，在复杂的空间变换和逻辑推理任务上存在明显短板。 - **细粒度识别**：在区分度极低的场景（如高度相似的建筑内景）中可能出错。 - **部署门槛**：模型体量较大（106B），对本地部署有较高硬件要求。 ```json ## Role 你是一位有多年经验的OCR表格识别专家。 ## Goals 需要通过给定的图片，识别表格里的内容，并以html表格结果格式输出结果。 ## Constrains - 需要认识识别图片中的内容，将每个表格单元格中的内容完整的识别出来，并填入html表格结构中； - 图片中的表格单元格中可能存在一些占位符需要识别出来，例如\\\"-\\\"、\\\"—\\\"、\\\"/\\\"等； - 输出表格结构一定遵循图片中的结构，表格结构完全一致； - 特别注意图片中存在合并单元格的情况，结构不要出错； - 对于内容较多的图片，一定要输出完整的结果，不要断章取义，更不要随意编造； - 图片内容需要完整识别，不要遗漏，同时注意合并单元； - 最终输出结果需要是html格式的表格内容。 ## Initialization 请仔细思考后，输出html表格结果。 ``` 测试双栏检验单，慢思考模型下真的很不错。 **其他 - Grounding** **普通问法（可能得到文本回答）：** `\\\"图片中奔跑的人在第几行第几列？\\\"` `\\\"图里有几串烤串？\\\"` **Grounding问法（触发图片标记）：** `\\\"请**框选出**图片中奔跑的人。\\\"` `\\\"请帮我**圈出**图里所有的烧烤签子。\\\"` `\\\"**标记出**图里的郭帆导演。`\",\"modelSize\":\"106B (总计 106B, 激活 12B)\",\"modelType\":\"多模态、文档解析模型、代码\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/zai-org/GLM-V\",\"evaluation\":\"曾经的国产之光，智谱好像回来了。 赞美开源。\"},{\"date\":\"2025-08-11\",\"title\":\"Baichuan Baichuan-M2-32B\",\"text\":\"**摘要：** 百川智能发布的32B开源医疗增强推理模型，在权威医疗评测`HealthBench`上超越OpenAI的`gpt-oss-120b`登顶SOTA。该模型基于创新的“大型验证器系统”和“患者模拟器”，在保持通用能力的同时，大幅提升了医疗推理能力，并支持RTX 4090单卡部署，部署成本极低。 **模型规格与架构：** - **参数量：** `32B` - **基础模型：** 基于 `Qwen/Qwen2.5-32B` - **核心架构/范式：** - **大型验证器系统 (Large Verifier System)：** 结合医疗场景特点设计，包含“患者模拟器”和多维度验证机制，为强化学习提供高质量、动态的奖励信号。 - **医疗领域自适应增强：** 采用中期训练（Mid-Training）方式高效注入医疗知识，同时保持通用能力。 - **多阶段强化学习 (Multi-Stage RL)：** 采用改进的`GRPO`算法，分阶段培养模型的医学知识、推理和医患交互能力。 - **上下文：** `32K` **性能与实测表现：** - **医疗基准 (`HealthBench`)：** - 标准版得分 `60.1`，超越 `gpt-oss-120b`（57.6分）和 `Qwen3-235B`（55.2分）。 - 困难版 (`HealthBench-Hard`) 得分 `34.7`，远超 `gpt-oss-120b`（30分），与 `GPT-5` 是唯二超过32分的模型。 - **通用能力基准：** 在`AIME24/25`、`Arena-Hard-v2.0`、`WritingBench`等通用评测上，全面超越同量级的`Qwen3-32B`。 - **本土化实测：** 在中国临床诊疗场景（如肝癌治疗案例）中，其推荐方案比`gpt-oss`系列更贴合国内权威指南，本土化优势明显。 **优势：** - **性能卓越：** 以更小模型尺寸在医疗评测上实现SOTA，尤其在复杂、困难场景下表现突出。 - **成本极低：** 经过4-bit量化后支持单张消费级显卡（RTX 4090）部署，极大降低了私有化门槛。 - **技术创新：** 首创“患者模拟器”和大型验证器系统，为解决医疗领域AI训练难题提供了新范式。 - **能力均衡：** 在强化医疗能力的同时，通用核心能力不降反增。 **适用场景 / 备注：** - 适用于临床辅助诊断、智能问诊、医学知识问答与教育、健康咨询等场景。 - 官方强调，模型仅供研究和参考，不能替代专业的医疗诊断或治疗。\",\"modelSize\":\"32B\",\"modelType\":\"语言, 医疗\",\"openSource\":true,\"contextWindow\":\"32K\",\"officialDoc\":\"https://www.baichuan-ai.com/blog/baichuan-M2\",\"evaluation\":\"32B太香了，但具体效果如何，还得在实际业务中见真章。\"},{\"date\":\"2025-08-08\",\"title\":\"⭐OpenAI GPT-5\",\"text\":\"OpenAI于2025年8月8日正式发布其下一代旗舰模型GPT-5。该模型被定义为一个统一的集成系统，而非单一模型。 **核心架构与模型系列：** GPT-5系统整合并重命名了多个先前的模型，形成了一个统一的家族。其核心是“快思考”的`main`系列和“慢思考”的`thinking`系列，由一个智能路由器根据任务需求自动调用。详细的模型继承关系如下： * `GPT-4o` -> `gpt-5-main` * `GPT-4o-mini` -> `gpt-5-main-mini` * `OpenAI o3` -> `gpt-5-thinking` * `OpenAI o4-mini` -> `gpt-5-thinking-mini` * `GPT-4.1-nano` -> `gpt-5-thinking-nano` * `OpenAI o3 Pro` -> `gpt-5-thinking-pro` 此对应关系明确显示，`main`系列是GPT-4o的直接延续，而`thinking`系列则整合了之前独立的、推理能力更强的o3、o4等实验性模型分支。 **性能与实测表现：** * **基准测试**: 在数学、编程、多模态等多个基准测试中全面领先，成为大模型盲测竞技场的新榜首。同时，模型效率也得到提升，在完成复杂任务时输出的Token减少了50-80%。 * **减少幻觉与谄媚**: 大幅降低了事实性错误的发生率（`gpt-5-thinking`比o3少五倍以上），并减少了不必要的迎合，对话体验更像与真人交流。 * **编程能力 (高度好评)**: 被评为“一骑绝尘”，尤其在前端UI/UX设计、生产级代码的精准修改和高上下文精度方面表现惊人。实测中能从一句话生成复杂的可视化效果、可玩游戏，并完成了其他顶级模型失败的编码任务。 * **写作能力 (评价分裂)**: 受到部分用户，特别是重度写作者的批评，认为其文笔相较于已被移除的GPT-4.5有明显退步，风格变得蹩脚，指令遵循能力一般。 **定价与API：** * **价格**: API定价极具竞争力，输入为$1.25/百万token，输出为$10/百万token，低于主要竞争对手。 * **API升级**: API迎来了多项对开发者友好的新特性。\",\"modelSize\":\"\",\"modelType\":\"多模态\",\"openSource\":false,\"contextWindow\":\"400K\",\"officialDoc\":\"https://openai.com/gpt-5/\",\"evaluation\":\"\"},{\"date\":\"2025-08-07\",\"title\":\"MinerU2\",\"text\":\"上海人工智能实验室发布了全新架构的智能文档解析引擎MinerU2，基于 **“通专融合”** 技术路线，旨在将复杂文档（特别是科学文献）精准转化为高质量的“AI-Ready”数据。 ### 模型规格与性能 * **模型**: 端到端多模态文档解析大模型 * **参数量**: **0.9B** * **性能**: 解析准确率较前代提升 **22%**，速度提升 **6倍**。性能比肩72B大模型，可在消费级显卡上运行。在同级别开源模型综合评分中位列第一。 * **核心能力**: 除了高精度解析文本、布局、表格、公式外，新增了对化学分子式和化学反应的解析能力。 ### 主要功能更新 (客户端/网页端) * **化学解析 (MinerU.Chem)**: 新增化学论文解析能力，可提取化合物结构和化学反应，并支持交互式预览和导出。 * **多模式翻译**: 上线全文和划词翻译功能，支持GPT-4o-mini、DeepL、Google等多种翻译引擎。 * **知识管理**: 新增收藏、批注、反馈功能，提升用户交互和知识沉淀效率。 * **工作流集成**: 支持一键导出到Notion和Dify，并可为超长文档设置按页码范围解析。 ### 生态与部署 * 项目已在GitHub开源，并提供了桌面客户端、网页端、API及企业级服务等多种使用形态。\",\"modelSize\":\"0.9B\",\"modelType\":\"文档解析模型\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/opendatalab/MinerU\",\"evaluation\":\"实测下来不及预期，在医疗检验单场景下测试，发现以下主要问题： - **版面理解能力不足**：出现将文本标题错误识别为图片的情况。 - **表格解析准确率低**：表格内的数据提取错误率偏高。\"},{\"date\":\"2025-08-07\",\"title\":\"OpenAI GPT-OSS\",\"text\":\"OpenAI于2025年8月初发布了其自GPT-2以来的首个“开放权重”(open-weight)模型系列——GPT-OSS，包含gpt-oss-120b和gpt-oss-20b两个模型，采用Apache 2.0许可。这意味着模型权重公开，但训练代码和数据集不公开。 **模型规格与架构:** - **gpt-oss-120b**: 拥有1170亿总参数，采用混合专家（MoE）架构，每个token激活51亿参数。官方称其性能接近闭源的o4-mini，可在单张80GB GPU上运行。 - **gpt-oss-20b**: 拥有210亿总参数，激活36亿参数。性能接近o3-mini，可在16GB内存的消费级设备（笔记本、手机）上运行。 两个模型均采用Transformer架构，支持128k上下文窗口，使用了类似GPT-3的交替稀疏注意力模式、分组多查询注意力（GQA），并开源了其o200k_harmony分词器。后训练流程（SFT、RL）与o4-mini相似，并支持高、中、低三种推理级别。 **性能表现:** 官方基准测试显示，GPT-OSS在工具调用（搜索、代码执行）、思维链推理和特定基准（如HealthBench）上表现强劲，部分指标甚至超越了GPT-4o和o1。 然而，多方独立实测揭示了其优势与短板： - **优势**: 在结构化的数学和逻辑推理任务上表现非常出色，能够清晰地解决复杂的数学题。 - **劣势**: 在更泛化的任务上表现不佳。尤其在代码生成方面，无法完成稍复杂的项目，表现“一言难尽”，远不如Qwen3等竞品；在需要整合多条信息的复杂推理题（如七个小矮人）上会出错或卡死；在创意性写作和角色扮演方面也同样逊色。\",\"modelSize\":\"120B (总计 117B, 激活 5.1B), 20B (总计 21B,激活 3.6B)\",\"modelType\":\"语言大模型\",\"openSource\":true,\"contextWindow\":\"128k\",\"officialDoc\":\"https://huggingface.co/collections/openai/gpt-oss-68911959590a1634ba11c7a4\",\"evaluation\":\"官方数据惊艳，实测表现拉垮。擅长数学推理，但在编程和复杂通用任务上远不及预期，综合能力不如同级别的国产开源模型。\"},{\"date\":\"2024-08-06\",\"title\":\"小红书 dots.vlm1\",\"text\":\"**摘要：** 小红书发布的首个开源多模态大模型，核心是自研的1.2B `NaViT`视觉编码器和`DeepSeek V3`语言模型，在处理图表、文档等结构化图像方面表现出色。 **模型规格与架构：** - **核心组件：** - **视觉编码器：** 自研 `NaViT` (12亿参数)，从零开始训练，支持动态分辨率。 - **语言模型：** `DeepSeek V3 MoE` - **连接器：** `MLP` 适配器 - **上下文窗口：** `4K` (4096 tokens) **性能与实测表现：** - **基准评测：** 在 `MMMU`、`MathVision`、`OCR Reasoning` 等多个国际权威多模态评测集上表现优异，整体性能接近 `Gemini 1.5 Pro` 和 `Seed-VL 1.5` 等顶尖闭源模型。 - **核心能力：** 特别擅长处理复杂的图表推理、STEM数学问题和长尾特定场景识别。 **优势：** - **创新视觉编码器：** `NaViT` 编码器专为结构化图像优化，提升了模型对表格、图表、公式的理解能力。 - **强大的推理能力：** 结合 `DeepSeek V3`，在多模态综合推理任务上展现出强大实力。 - **完全开源：** 采用 `MIT` 许可证，对学术界和产业界友好，可商用。 **适用场景：** - 通用视觉问答与对话 - 复杂图表与文档内容理解 - OCR与版面分析 - STEM领域的多模态辅助\",\"modelSize\":\"视觉编码器 1.2B\",\"modelType\":\"多模态\",\"openSource\":true,\"contextWindow\":\"4K\",\"officialDoc\":\"https://github.com/rednote-hilab/dots.vlm1\"},{\"date\":\"2025-08-05\",\"title\":\"Qwen-Image\",\"text\":\"阿里千问团队发布的Qwen-Image是其首个图像生成基础模型，基于20B参数的MMDiT架构。该模型在文生图方面表现出色，尤其擅长中英文文本的精准渲染，能将文字与图像无缝融合。它支持通用图像编辑（如风格迁移、物体增删、姿态调整）、多种艺术风格生成，并能处理物体检测、语义分割等计算机视觉任务。Qwen-Image在多个公开基准测试中取得SOTA，是当前Artificial Analysis Image Arena上排名最高的开源模型。 **MMDiT**，全称为**多模态扩散变换器（Multimodal Diffusion Transformer）**，是当前AI图像生成领域一项前沿的核心技术架构。它是一种专门设计用来处理和融合多种不同类型数据（即“模态”），如文本描述和图像信息的神经网络模型。 这项技术是继“扩散模型（Diffusion Model）”和“视觉变换器（Vision Transformer, ViT）”之后的又一重要演进，通过其独特的结构，显著提升了AI模型根据复杂文字提示生成高质量、高相关性图像的能力。 **核心思想：为不同信息类型设立“专属通道”** 在传统的图像生成模型中，文本指令通常通过一个称为“交叉注意力（Cross-Attention）”的机制被注入到图像生成过程中。你可以把它想象成，在处理图像的同时，模型会时不时地“瞥一眼”文本指令来获取引导。 MMDiT则采用了更为精妙的方法。它的核心创新在于： 1. **分离处理**：MMDiT为文本信息和图像信息设立了两套独立的处理模块（或使用独立的权重）。这意味着文本和图像的特征（Tokens）在各自的“专属通道”中被分别处理，保留了各自模态的独特性和完整性。 2. **联合注意力**：在经过初步的独立处理后，两条通道中的信息会被**拼接（concatenate）**在一起，送入一个统一的注意力模块中进行联合处理。这使得文本和图像信息能够在更深层次上进行交互和对齐，模型可以更精确地理解“宇航员”、“骑着猪”、“穿着芭蕾舞裙”等不同概念应该如何组合在同一画面中。 简单来说，MMDiT架构就像一个拥有两个独立专业团队（一个文本专家团队，一个图像专家团队）的工作室。两个团队先分别消化自己的任务信息，然后在关键节点上进行高效的协同工作，共同完成最终的创作。\",\"modelSize\":\"20B (MMDiT)\",\"modelType\":\"图像生成、图像编辑\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://huggingface.co/Qwen/Qwen-Image\",\"evaluation\":\"左手“万相”拍视频，右手“千问”P图片，阿里这是要承包我的创意文件夹吗？\"},{\"date\":\"2025-08-04\",\"title\":\"小米 MiDashengLM-7B\",\"text\":\"**摘要：** 小米发布并开源的70亿参数多模态声音理解大模型，在速度与精度上取得双重突破，刷新了22个公开评测集SOTA，旨在赋能其“人车家全生态”战略。 **模型规格与架构：** - **参数量：** 7B - **架构/范式：** 采用双核设计，结合了小米自研的开源音频编码器`Xiaomi Dasheng`和`Qwen2.5-Omni-7B Thinker`作为自回归解码器。 - **训练方法：** 采用创新的“通用音频描述”（general audio caption）训练策略，能够统一处理和理解语音、环境音、音乐等多种音频信号。 **性能与实测表现：** - **基准：** 在22个公开评测集上刷新了多模态大模型的最佳成绩（SOTA）。 - **效率：** 推理效率极高，单样本首Token延迟（TTFT）仅为同类先进模型的1/4，数据吞吐效率提升20倍以上。 **适用场景 / 备注：** - 核心应用场景为小米的“人车家全生态”，如智能座舱、智能家居等。\",\"modelSize\":\"7B\",\"modelType\":\"多模态\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/xiaomi-research/dasheng-lm\"},{\"date\":\"2025-08-04\",\"title\":\"Hunyuan 腾讯混元小尺寸模型系列\",\"text\":\"### 核心发布：端侧开源小尺寸语言模型 腾讯于2025年8月4日宣布，正式开源四款专为**端侧设备**设计的小尺寸语言模型，旨在推动AI在消费电子、智能汽车等领域的应用。 同时​增强了Agent能力，在BFCL-v3、τ-Bench、C3-Bench等智能体基准测试中领先 ### 模型规格 该系列包含四个不同规模的模型，以满足不同场景的需求： * **0.5B (5亿参数)** * **1.8B (18亿参数)** * **4B (40亿参数)** * **7B (70亿参数)** ### 主要优势 * **高效运行**: 能够在笔记本、手机、智能座舱等低功耗设备上高效部署。 * **易于微调**: 支持在垂直领域进行低成本的定制化微调。 ### 其他近期开源 此次发布是腾讯近期密集开源动作的一部分，此前还开源了**混元3D世界模型1.0**（2025年7月）和**混元Hunyuan-A13B** MoE模型（2025年6月）。\",\"modelSize\":\"0.5B, 1.8B, 4B, 7B\",\"modelType\":\"语言大模型（快思考和慢思考）\",\"openSource\":true,\"contextWindow\":\"256K\",\"officialDoc\":\"https://huggingface.co/tencent-hunyuan\",\"evaluation\":\"小小杯、超小杯、超超小杯\"},{\"date\":\"2025-08-01\",\"title\":\"阶跃Step-3\",\"text\":\"#### 阶跃星辰最新开源的Step-3是一款SOTA级基础模型，其核心设计理念是 **“模型-Infra协同设计”** ，旨在实现极致的推理效率和性价比。它在MMMU等多个多模态榜单上取得了开源模型的新SOTA成绩。 ### 模型规格 * **架构**: MoE (混合专家) 架构，包含48个专家 * **参数量**: 总参数量 321B (316B语言 + 5B视觉)，激活参数量 38B * **性能**: 在Hopper GPU上解码速度高达 **4039 token/秒**，是DeepSeek-V3的174%（4K上下文、FP8、无MTP）。 * **成本**: 性价比极高，在特定硬件组合下，**百万Token解码成本不到4毛钱人民币**，在H20计算卡上解码成本仅为DeepSeek-V3的30%。 ### 技术亮点 * **模型-Infra协同设计**: 将模型架构、系统调度和硬件Infra作为一个整体进行优化。 * **MFA注意力机制**: 采用自研的MFA（多矩阵因子分解）注意力机制，从根源上压缩KV缓存，降低计算消耗，尤其适合长上下文场景。 * **AFD解耦系统**: 提出AFD（Attention-FFN Disaggregation）机制，将Attention和FFN计算任务拆分到各自最适合的GPU集群，通过自研的**StepMesh通信库**连接，实现整体吞吐效率最大化。 * **开源开放**: 模型及核心的StepMesh通信库均已开源。 ### 部署能力 * 可在8块48GB的GPU上运行，并处理高达80万个Token的上下文。\",\"modelSize\":\"321B (激活 38B)\",\"modelType\":\"多模态大模型\",\"openSource\":true,\"contextWindow\":\"64K\",\"officialDoc\":\"https://github.com/stepfun-ai/Step3\"},{\"date\":\"2025-07-30\",\"title\":\"⭐dots.ocr\",\"text\":\"dots.ocr是由小红书发布的、基于17亿参数大语言模型的多语言文档解析模型。它将版面检测与内容识别统一在单一的视觉语言模型中，在OmniDocBench等多个基准测试中，其文本、表格及阅读顺序解析能力均达到SOTA（业界最佳）水平，并对低资源语言有出色的支持。\",\"modelSize\":\"1.7B\",\"modelType\":\"文档多模态模型/文档解析\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/rednote-hilab/dots.ocr\",\"evaluation\":\"1.7B小钢炮，实测效果好于Mineru。开源SOTA级别，官方提供的评测结果中，遥遥领先于其他多款模型或工具。\"},{\"date\":\"2025-07-30\",\"title\":\"Qwen3-30B-A3B-Instruct-2507\",\"text\":\" - 显著提升了包括 指令执行、逻辑推理、文本理解、数学、科学、编码和工具使用 在内的通用能力。 - 大幅增加 了 多种语言 中的长尾知识覆盖范围。 - 显著更好地符合 用户在 主观和开放式任务 中的偏好，能够提供更有帮助的响应和更高质量的文本生成。\",\"modelSize\":\"30.5B(激活 3.3B)\",\"modelType\":\"\",\"openSource\":true,\"contextWindow\":\"256K\",\"officialDoc\":\"\"},{\"date\":\"2025-07-30\",\"title\":\"Qwen3-30B-A3B-Thinking-2507\",\"text\":\"- 在逻辑推理、数学、科学、编码和通常需要人类专业知识的学术基准等推理任务上显著提升的性能。 - 明显更好的通用能力，如指令执行、工具使用、文本生成以及与人类偏好的一致性。 - 增强的256K长上下文理解能力。 此版本的思考长度有所增加。建议在高度复杂的推理任务中使用它。\",\"modelSize\":\"30.5B(3.3B)\",\"modelType\":\"\",\"openSource\":true,\"contextWindow\":\"256K\",\"officialDoc\":\"\"},{\"date\":\"2025-07-28\",\"title\":\"⭐(智谱AI) GLM-4.5\",\"text\":\"智谱（Zhipu）发布的GLM-4.5是一款强大的多模态模型，拥有3550亿总参数和320亿激活参数。该模型在复杂推理和代码生成方面表现出色，是面向智能体应用的下一代基础模型。\",\"modelSize\":\"355B(激活 32B), 106B(激活 12B)。GLM-4.5: 总参数355B，激活参数32B；GLM-4.5-Air: 总参数106B，激活参数12B\",\"modelType\":\"多模态大模型\",\"openSource\":true,\"contextWindow\":\"128k\",\"officialDoc\":\"https://huggingface.co/ZhipuAI/GLM-4.5-32B-Code-Instruct\"},{\"date\":\"2025-07-28\",\"title\":\"通义万相2.2 (Tongyi Wanxiang 2.2)\",\"text\":\"通义万相2.2是阿里巴巴于2025年7月28日发布的、主打**视频生成**的新一代AI模型，其目标是实现“电影级”的创作水准。 ### 主要功能 * **文生视频 (Text-to-Video)**：根据文本描述生成高清视频。 * **图生视频 (Image-to-Video)**：将静态图片转化为内容和风格一致的动态视频。 * **统一视频模型**：发布了一款5B参数的统一模型，同时支持文生视频和图生视频，降低了部署门槛。 * **文生图**：系列中也包含了升级的文生图模型。 ### 技术亮点 * **首创MoE架构**: 业界首个在视频生成中采用混合专家（MoE）架构的模型，有效平衡了效果与计算效率。 * **电影美学控制系统**: 内置超过60个美学参数，允许用户精细控制光影、色彩、镜头语言等视觉风格。 * **强大的动态表现**: 在处理复杂运动、保持角色一致性和还原微表情等细节方面表现出色。\",\"modelSize\":\"27B (MoE, 激活14B), 5B\",\"modelType\":\"视频生成\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://modelscope.cn/organization/iic\"},{\"date\":\"2025-07-27\",\"title\":\"Qwen3-Coder-Plus\",\"text\":\"阿里巴巴（Alibaba）发布的Qwen3-Coder-Plus是Qwen3系列中专为代码生成和补全而优化的模型。它在多种编程语言和框架上都表现出色，能够显著提升开发效率。\",\"modelSize\":\"\",\"modelType\":\"文本 (代码)\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://huggingface.co/Qwen/Qwen3-Coder-72B-G-Instruct\"},{\"date\":\"2025-07-26\",\"title\":\"书生 Intern-S1\",\"text\":\"**摘要：** 上海人工智能实验室发布的全球领先开源科学多模态大模型，被誉为“全能高手+科学明星”，旨在通过深度融合通用与顶尖科学能力，重构科研生产力。 **模型规格与架构：** - 参数量：28B激活参数（总计241B）。 - 架构/范式：基于 `Qwen3-235B` 和 `InternViT-6B` 构建的混合专家（MoE）架构。 - 核心创新：首创“跨模态科学解析引擎”，并采用动态Tokenizer和时序信号编码器，原生支持化学分子式、蛋白质序列、地震波等多种复杂科学模态数据的深度融合。 **性能与实测表现：** - 多模态通用能力：综合能力在开源模型中排名第一，得分比肩国内外一流闭源模型。 - 科学专业能力：在化学、材料、地球科学等多个专业任务基准上，性能超越了 `Grok-4` 等顶尖闭源模型，树立了行业新标杆。 - 训练优化：通过系统与算法的联合优化，实现了大型多模态MoE模型在FP8精度下的高效强化学习，成本降低10倍。 **优势：** - **顶尖科学能力**：专为前沿科学研究设计，在处理和理解高度专业化的科学数据方面具有显著优势。 - **开源与生态**：模型及全链路工具链（微调、部署、评测）全面开源，支持免费商用，社区生态活跃。 **适用场景 / 备注：** - 旨在成为“科研搭档”而非简单的“对话助手”，适用于化合物合成路径预测、化学反应可行性判断、生物信息学分析等前沿科研任务。 - 其轻量级版本 `Intern-S1-mini` 于2025年8月21日发布。\",\"modelSize\":\"241B (激活 28B)\",\"modelType\":\"多模态, 语言, 科学计算\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"https://github.com/InternLM/Intern-S1\"},{\"date\":\"2025-07-25\",\"title\":\"阿里巴巴 Qwen3-235B-A22B-Thinking-2507\",\"text\":\"Qwen3-Thinking 是阿里巴巴Qwen团队推出的 MoE 模型，专注于复杂认知任务、多步推理和抽象思维，旨在处理高级逻辑和分析任务。\",\"modelSize\":\"235B(激活 22B)\",\"modelType\":\"语言模型 (MoE，推理强化)\",\"openSource\":true,\"contextWindow\":\"128K\",\"officialDoc\":\"https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507\"},{\"date\":\"2025-07-25\",\"title\":\"阿里巴巴 Qwen3-Coder-480B-A35B-Instruct\",\"text\":\"\",\"modelSize\":\"480B(激活 35B)\",\"modelType\":\"代码\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"\"},{\"date\":\"2025-07-25\",\"title\":\"Coze / Coze Loop\",\"text\":\"字节跳动（ByteDance）开源的Coze和Coze Loop是AI智能体开发平台，旨在简化和加速AI应用的开发和部署。这些平台提供了一系列工具和组件，帮助开发者快速构建和迭代AI智能体。\",\"modelSize\":\"N/A (框架)\",\"modelType\":\"框架\",\"openSource\":true,\"contextWindow\":\"N/A\",\"officialDoc\":\"https://www.coze.com/\"},{\"date\":\"2025-07-23\",\"title\":\"Qwen3-Coder\",\"text\":\"Qwen3-Coder 是通义千问最新开源的智能体代码模型，在智能体编程、智能体浏览和基础编程任务中表现出色。它具有高度智能体化特性，旨在大幅提升开发效率和代码质量，其性能可与Claude Sonnet媲美，并支持工具调用。\",\"modelSize\":\"450B(激活 35B)\",\"modelType\":\"代码生成 (智能体编程)\",\"openSource\":true,\"contextWindow\":\"256K (可扩展至1M)\",\"officialDoc\":\"https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct\"},{\"date\":\"2025-07-22\",\"title\":\"阿里巴巴 Qwen3-Coder-480B-A35B-Instruct\",\"text\":\"\",\"modelSize\":\"\",\"modelType\":\"代码\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"\"},{\"date\":\"2025-07-21\",\"title\":\"阿里巴巴 Qwen3-235B-A22B-Instruct-2507\",\"text\":\"\",\"modelSize\":\"\",\"modelType\":\"代码\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"\"},{\"date\":\"2025-07-14\",\"title\":\"RoboBrain 2.0 / RoboOS 2.0\",\"text\":\"智源研究院（BAAI）发布的RoboBrain 2.0和RoboOS 2.0是面向机器人的下一代操作系统和大脑。它们旨在为机器人提供更强的感知、决策和执行能力，推动机器人技术的发展。\",\"modelSize\":\"N/A (框架)\",\"modelType\":\"智能体框架\",\"openSource\":true,\"contextWindow\":\"N/A\",\"officialDoc\":\"\"},{\"date\":\"2025-07-11\",\"title\":\"KAT-V1-40B\",\"text\":\"快手（Kuaishou）发布的KAT-V1-40B是一款400亿参数的文本模型，旨在解决复杂推理中的“过度思考”问题。它通过优化推理路径，提升了模型的效率和准确性。\",\"modelSize\":\"40B\",\"modelType\":\"语言模型\",\"openSource\":true,\"contextWindow\":\"\",\"officialDoc\":\"\"},{\"date\":\"2025-07-11\",\"title\":\"⭐Kimi K2\",\"text\":\"月之暗面（Moonshot AI）发布的Kimi K2是一款万亿级参数的MoE模型，拥有320亿激活参数。它在长文本处理方面表现卓越，支持128k的上下文长度，并显著提升了中文能力。\",\"modelSize\":\"1T(激活 320B)\",\"modelType\":\"语言模型\",\"openSource\":true,\"contextWindow\":\"128k\",\"officialDoc\":\"https://huggingface.co/moonshot-ai/Kimi-K2-32B\"},{\"date\":\"2025-07-04\",\"title\":\"MOSS-TTSD-v0.5\",\"text\":\"复旦大学（Fudan University）发布的MOSS-TTSD-v0.5是一款基于Qwen3-1.7B-base的双语语音合成模型。它支持长达960秒的语音生成，并在音色、韵律和自然度方面表现出色。\",\"modelSize\":\"1.7B\",\"modelType\":\"多模态 (语音生成)\",\"openSource\":true,\"contextWindow\":\"960秒\",\"officialDoc\":\"https://huggingface.co/fnlp/MOSS-TTSD-v0.5\"}]"},{"title":"Page","path":"/page/index.html","content":"This is a page test."},{"title":"朋友文章","path":"/friends/rss/index.html","content":""}]